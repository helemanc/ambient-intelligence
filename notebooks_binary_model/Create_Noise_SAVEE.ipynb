{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e28a25-ebcd-43d0-be13-adee76d45747",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "NOTES: The warnings after the import are referred to the fact that Tensorflow 2.x versions are built to directly look for a GPU in the system. The warning can be forgot if you are not going to use the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcfa3cda-6ae1-490c-bcb2-31d45036a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source myenv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af52f43-e2f0-4485-88fd-6ba9bac11e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 10:04:10.810835: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-10 10:04:10.810858: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-09-10 10:04:11.672942: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-09-10 10:04:11.673505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-10 10:04:11.741795: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-09-10 10:04:11.741818: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import ipywidgets\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, AveragePooling1D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from livelossplot import PlotLossesKeras\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79db805-26e9-412a-8380-19c43b00b911",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c77ed-10a1-4012-8fcc-86afd6a95fe9",
   "metadata": {},
   "source": [
    "# Compute dataframes for datasets and split in Train, Val, Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cdff852-e096-4429-aad6-668fcbab7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/media/helemanc/OS/Users/i2CAT/Desktop/Datasets SER/'\n",
    "TESS = os.path.join(main_path, \"tess/TESS Toronto emotional speech set data/\") \n",
    "RAV = os.path.join(main_path, \"ravdess-emotional-speech-audio/audio_speech_actors_01-24\")\n",
    "SAVEE = os.path.join(main_path, \"savee/ALL/\")\n",
    "CREMA = os.path.join(main_path, \"creamd/AudioWAV/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e6ea3e-c59e-4111-b6fd-032eac81e478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     120\n",
       "sadness      60\n",
       "surprise     60\n",
       "happy        60\n",
       "disgust      60\n",
       "fear         60\n",
       "angry        60\n",
       "Name: emotion_label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data location for SAVEE\n",
    "dir_list = os.listdir(SAVEE)\n",
    "\n",
    "# parse the filename to get the emotions\n",
    "emotion=[]\n",
    "path = []\n",
    "actors = []\n",
    "gender = []\n",
    "for i in dir_list:\n",
    "    actors.append(i[:2])\n",
    "    if i[-8:-6]=='_a':\n",
    "        emotion.append('angry')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='_d':\n",
    "        emotion.append('disgust')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='_f':\n",
    "        emotion.append('fear')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='_h':\n",
    "        emotion.append('happy')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='_n':\n",
    "        emotion.append('neutral')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='sa':\n",
    "        emotion.append('sadness')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='su':\n",
    "        emotion.append('surprise')\n",
    "        gender.append('male') \n",
    "    else:\n",
    "        emotion.append('Unknown') \n",
    "    path.append(SAVEE + i)\n",
    "    \n",
    "# Now check out the label count distribution \n",
    "SAVEE_df = pd.DataFrame(emotion, columns = ['emotion_label'])\n",
    "                      \n",
    "SAVEE_df = pd.concat([SAVEE_df,\n",
    "                      pd.DataFrame(actors, columns = ['actors']),\n",
    "                      pd.DataFrame(gender, columns = ['gender']), \n",
    "                      pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
    "SAVEE_df.emotion_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042d03a6-ba58-491a-a887-a30d340b16fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>DC</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>KL</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>KL</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>KL</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sadness</td>\n",
       "      <td>KL</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion_label actors gender  \\\n",
       "0       neutral     DC   male   \n",
       "1       sadness     KL   male   \n",
       "2       sadness     KL   male   \n",
       "3       sadness     KL   male   \n",
       "4       sadness     KL   male   \n",
       "\n",
       "                                                path  \n",
       "0  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "1  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "3  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "4  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVEE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e46bb6-60d3-409c-9724-e1cb4c8b4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEE_train = []\n",
    "SAVEE_val = []\n",
    "SAVEE_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5da5d7-a364-40b3-ab2c-2bb684127f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 120, 120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DC, JE, JK, KL\n",
    "for index, row in SAVEE_df.iterrows(): \n",
    "    if row['actors'] == 'DC' or row ['actors'] == 'JE':\n",
    "        SAVEE_train.append(row)\n",
    "    elif row['actors'] == 'JK': \n",
    "        SAVEE_val.append(row)\n",
    "    else: \n",
    "        SAVEE_test.append(row)\n",
    "len(SAVEE_train), len(SAVEE_val), len(SAVEE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a1bd6d4-2bf6-4d86-99af-0ec027bd0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEE_train = pd.DataFrame(SAVEE_train)\n",
    "SAVEE_val = pd.DataFrame(SAVEE_val)\n",
    "SAVEE_test = pd.DataFrame(SAVEE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddcdd003-f646-4ac8-a9f6-1093316fca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEE_train = SAVEE_train.drop(['actors'], 1)\n",
    "SAVEE_val = SAVEE_val.drop(['actors'], 1)\n",
    "SAVEE_test = SAVEE_test.drop(['actors'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f8f7df-97b5-4b11-beb0-f47ebd083e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVEE_train = SAVEE_train.reset_index(drop=True) \n",
    "SAVEE_val = SAVEE_val.reset_index(drop=True) \n",
    "SAVEE_test = SAVEE_test.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86cd4964-069c-4b16-8224-b403a4de24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = SAVEE_train \n",
    "df_val = SAVEE_val \n",
    "df_test = SAVEE_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836151b6-f110-4ad2-b80c-8a63f8a6270b",
   "metadata": {},
   "source": [
    "# Create Noise Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "892a3946-4ac3-46ec-ac56-ed1015237804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import random \n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "\n",
    "def create_noise_files(df_train, df_val, df_test): \n",
    "    \n",
    "    '''\n",
    "    Apply noise only on training files, so double the number of training files and keep \n",
    "    validation and test the same\n",
    "    '''\n",
    "    path_noise_sound_1 = '/home/helemanc/Desktop/Binary_Model/noise_sounds/freight_train.wav'\n",
    "    path_noise_sound_2 = '/home/helemanc/Desktop/Binary_Model/noise_sounds/inside_train.wav'\n",
    "    path_noise_sound_3 = '/home/helemanc/Desktop/Binary_Model/noise_sounds/small_crowd.wav'\n",
    "    \n",
    "    path_noise_dataset_train = '/home/helemanc/Desktop/Binary_Model/noise_datasets/savee/train'\n",
    "    #path_noise_dataset_val = '/home/helemanc/Desktop/Binary_Model/noise_datasets/ravdess/val'\n",
    "    #path_noise_dataset_test = '/home/helemanc/Desktop/Binary_Model/noise_datasets/ravdess/test'\n",
    "    \n",
    "\n",
    "    #df_list = [df_train, df_val, df_test]\n",
    "    #count_df = 0 \n",
    "    \n",
    "    train_emotions = []\n",
    "    train_genders = []\n",
    "    train_paths = []\n",
    "    \n",
    "    #val_emotions = []\n",
    "    #val_genders = []\n",
    "    #val_paths = []\n",
    "    \n",
    "    #test_emotions = []\n",
    "    #test_genders = []\n",
    "    #test_paths = []\n",
    "    \n",
    "    #for df in df_list: \n",
    "        \n",
    "    for index, row in tqdm(df_train.iterrows()): \n",
    "        path = row['path']\n",
    "        sound1 = AudioSegment.from_file(path)\n",
    "        samples, sr = librosa.load(path, res_type='kaiser_fast', sr=16000)\n",
    "        duration = librosa.get_duration(y = samples, sr = sr)\n",
    "\n",
    "        # pick a noise sound file randomly \n",
    "        noise_list = [path_noise_sound_1, path_noise_sound_2, path_noise_sound_3]\n",
    "        random_noise = random.choice(noise_list) \n",
    "\n",
    "        lower_volume = 0 \n",
    "\n",
    "        # adjust volume to not cover the voice of the audio file \n",
    "        # warning: different levels of dB need to be calibrate for each dataset \n",
    "        '''\n",
    "        if random_noise == path_noise_sound_1: \n",
    "            lower_volume = 40\n",
    "        elif random_noise == path_noise_sound_2: \n",
    "            lower_volume = 25 \n",
    "        else: \n",
    "            lower_volume = 40\n",
    "        '''\n",
    "\n",
    "        # other strategy: \n",
    "        # compute db of both files, compute the difference, and lower the volume of the file to make it \n",
    "        # a bit lower than the original file -almost equal- \n",
    "\n",
    "        sound2 = AudioSegment.from_file(random_noise)\n",
    "\n",
    "        # make chunks of duration equal to the audio file \n",
    "        chunk_length_ms = duration*1000 #ms\n",
    "        chunks = make_chunks(sound2, chunk_length_ms) \n",
    "\n",
    "        # pick a random chunk \n",
    "        random_chunk = random.choice(chunks)\n",
    "        difference = random_chunk.dBFS - sound1.dBFS\n",
    "\n",
    "        abs_difference = abs(difference)\n",
    "\n",
    "        lower = random_chunk - abs_difference - 2\n",
    "\n",
    "        # lower the volume of the noise file to be overlayed with the voice_sound \n",
    "        #lower = random_chunk - lower_volume\n",
    "\n",
    "        combined = sound1.overlay(lower)\n",
    "\n",
    "        parts = path.split('/')\n",
    "        fname = parts[-1]\n",
    "        \n",
    "        new_path = path_noise_dataset_train + '/' + fname \n",
    "\n",
    "        train_emotions.append(row['emotion_label'])\n",
    "        train_genders.append(row['gender'])\n",
    "        train_paths.append(new_path)\n",
    "\n",
    "        '''\n",
    "        if count_df == 0: \n",
    "            new_path = path_noise_dataset_train + '/' + fname \n",
    "\n",
    "            train_emotions.append(row['emotion_label'])\n",
    "            train_genders.append(row['gender'])\n",
    "            train_paths.append(new_path)\n",
    "\n",
    "        elif count_df == 1: \n",
    "            new_path = path_noise_dataset_val + '/' + fname\n",
    "\n",
    "            val_emotions.append(row['emotion_label'])\n",
    "            val_genders.append(row['gender'])\n",
    "            val_paths.append(new_path)\n",
    "\n",
    "        elif count_df == 2:\n",
    "            new_path = path_noise_dataset_test + '/' + fname          \n",
    "\n",
    "            test_emotions.append(row['emotion_label'])\n",
    "            test_genders.append(row['gender'])\n",
    "            test_paths.append(new_path)\n",
    "        '''\n",
    "        combined.export(new_path, format= 'wav')\n",
    "\n",
    "    #count_df +=1\n",
    "\n",
    "    df_train_noise = pd.DataFrame([train_emotions, train_genders, train_paths]).T\n",
    "    df_train_noise.columns = ['emotion_label', 'gender', 'path']\n",
    "    \n",
    "    #df_val_noise = pd.DataFrame([val_emotions, val_genders, val_paths]).T\n",
    "    #df_val_noise.columns = ['emotion_label', 'gender', 'path']\n",
    "    \n",
    "    #df_test_noise = pd.DataFrame([test_emotions, test_genders, test_paths]).T\n",
    "    #df_test_noise.columns = ['emotion_label', 'gender', 'path']\n",
    "\n",
    "    df_train_combined = pd.concat([df_train, df_train_noise])\n",
    "    df_train_combined.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #df_val_combined = pd.concat([df_val, df_val_noise])\n",
    "    #df_val_combined.reset_index(drop=True, inplace=True)\n",
    "                                   \n",
    "    #df_test_combined = pd.concat([df_test, df_test_noise])\n",
    "    #df_test_combined.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_train_combined, df_val, df_test\n",
    "# have to save df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e71dc93b-bd3e-4467-9941-b39b56f2c889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [00:09, 26.58it/s]\n"
     ]
    }
   ],
   "source": [
    "new_df_train, new_df_val, new_df_test = create_noise_files(df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93876642-9ab6-473c-9212-159d9d3dcd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 3), (120, 3), (120, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_train.shape, new_df_val.shape, new_df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4b577-c14c-4538-a10e-502d064a9191",
   "metadata": {},
   "source": [
    "## Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df51adba-5ac9-4fbe-b880-12d334a10a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_path = \"/home/helemanc/Desktop/Binary_Model/df_csv_noise/savee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffc5b7b2-57a0-4134-a29f-7a09e62ea577",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train.to_csv(os.path.join(preprocess_path,\"df_train.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bae2745d-4299-414d-b822-1a75c8a9b059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df_val.to_csv(os.path.join(preprocess_path,\"df_val.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c08acf3-018c-4c3a-8880-44772d8859ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test.to_csv(os.path.join(preprocess_path,\"df_test.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
