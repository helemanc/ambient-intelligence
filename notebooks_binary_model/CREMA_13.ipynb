{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873702c2-2ec2-49af-9606-985b25eabc93",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configuration\n",
    "\n",
    "NOTES: The warnings after the import are referred to the fact that Tensorflow 2.x versions are built to directly look for a GPU in the system. The warning can be forgot if you are not going to use the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0f7084-d523-49d1-a344-e71e6517d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source myenv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ec6ec0-0f93-4194-88ff-5e645e42df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LENGTH_CHOSEN = 126520\n",
    "LENGTH_CHOSEN = 38532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ba6f69-f9cb-423a-81ff-3091658e4beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 11:21:04.447845: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 11:21:04.447869: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 11:21:05.342226: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 11:21:05.342855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 11:21:05.412271: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 11:21:05.412291: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import ipywidgets\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, AveragePooling1D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from livelossplot import PlotLossesKeras\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb3619-eba7-42cb-bcb5-f41ad2634be3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcac02c-82ef-4014-8add-10c97110dc97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_path = '/media/helemanc/OS/Users/i2CAT/Desktop/Datasets SER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a388ed-5c66-44e5-9f7a-3ab628f62d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA = os.path.join(main_path, \"creamd/AudioWAV/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac5ce70-87a6-4d24-a608-e5847139f40f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "males = [1,\n",
    "5,\n",
    "11,\n",
    "14,\n",
    "15,\n",
    "16,\n",
    "17,\n",
    "19,\n",
    "22,\n",
    "23,\n",
    "26,\n",
    "27,\n",
    "31,\n",
    "32,\n",
    "33,\n",
    "34,\n",
    "35,\n",
    "36,\n",
    "38,\n",
    "39,\n",
    "41,\n",
    "42,\n",
    "44,\n",
    "45,\n",
    "48,\n",
    "50,\n",
    "51,\n",
    "57,\n",
    "59, \n",
    "62, \n",
    "64,\n",
    "65, \n",
    "66,\n",
    "67,\n",
    "68,\n",
    "69,\n",
    "70,\n",
    "71,\n",
    "77, \n",
    "80, \n",
    "81, \n",
    "83, \n",
    "85, \n",
    "86, \n",
    "87,\n",
    "88, \n",
    "90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9726101e-6450-4b62-89a8-19594af78aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "females = [ 2,\n",
    "3,\n",
    "4,\n",
    "6,\n",
    "7,\n",
    "8,\n",
    "9,\n",
    "10,\n",
    "12,\n",
    "13,\n",
    "18,\n",
    "20,\n",
    "21,\n",
    "24,\n",
    "25,\n",
    "28,\n",
    "29,\n",
    "30,\n",
    "37,\n",
    "40,\n",
    "43,\n",
    "46,\n",
    "47,\n",
    "49,\n",
    "52,\n",
    "53,\n",
    "54,\n",
    "55,\n",
    "56, \n",
    "58, \n",
    "60,\n",
    "61,\n",
    "63,\n",
    "72, \n",
    "73, \n",
    "74, \n",
    "75, \n",
    "76, \n",
    "78, \n",
    "79, \n",
    "82, \n",
    "84, \n",
    "89, \n",
    "91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45cece7d-a052-4afc-b499-abff3481ded7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgust</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion_label actors  gender  \\\n",
       "0         happy     91  female   \n",
       "1       sadness     91  female   \n",
       "2         angry     91  female   \n",
       "3       disgust     91  female   \n",
       "4          fear     91  female   \n",
       "\n",
       "                                                path  \n",
       "0  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "1  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "3  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "4  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_directory_list = os.listdir(CREMA)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "actors = []\n",
    "gender = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in crema_directory_list:\n",
    "\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    \n",
    "    # use only high intensity files\n",
    "    if \"HI\" in part[3] :\n",
    "        actor = part[0][2:]\n",
    "        actors.append(actor)\n",
    "        if int(actor) in males:\n",
    "            gender.append('male')\n",
    "        else: \n",
    "            gender.append('female')\n",
    "    \n",
    "        # storing file paths\n",
    "        file_path.append(CREMA + file)\n",
    "        if part[2] == 'SAD':\n",
    "            file_emotion.append('sadness')\n",
    "        elif part[2] == 'ANG':\n",
    "            file_emotion.append('angry')\n",
    "        elif part[2] == 'DIS':\n",
    "            file_emotion.append('disgust')\n",
    "        elif part[2] == 'FEA':\n",
    "            file_emotion.append('fear')\n",
    "        elif part[2] == 'HAP':\n",
    "            file_emotion.append('happy')\n",
    "        elif part[2] == 'NEU':\n",
    "            file_emotion.append('neutral')\n",
    "        else:\n",
    "            file_emotion.append('Unknown')\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['emotion_label'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['path'])\n",
    "actors_df = pd.DataFrame(actors, columns=['actors'])\n",
    "gender_df = pd.DataFrame(gender, columns=['gender'])                      \n",
    "Crema_df = pd.concat([emotion_df, actors_df, gender_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93547c2a-6fdd-4db0-97b3-bba2c3d48e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crema_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09a82b5-bbb5-4086-8b78-f05e164c0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_files = {}\n",
    "\n",
    "for index, row in Crema_df.iterrows():\n",
    "    actor = row['actors']\n",
    "    if actor not in actor_files.keys(): \n",
    "        actor_files[actor] = 1\n",
    "    else: \n",
    "        actor_files[actor]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4f2a3c9-b120-4e33-9db7-98976e64424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'91': 5,\n",
       " '90': 5,\n",
       " '89': 5,\n",
       " '88': 5,\n",
       " '87': 5,\n",
       " '86': 5,\n",
       " '85': 5,\n",
       " '84': 5,\n",
       " '83': 5,\n",
       " '82': 5,\n",
       " '81': 5,\n",
       " '80': 5,\n",
       " '79': 5,\n",
       " '78': 5,\n",
       " '77': 5,\n",
       " '76': 5,\n",
       " '75': 5,\n",
       " '74': 5,\n",
       " '73': 5,\n",
       " '72': 5,\n",
       " '71': 5,\n",
       " '70': 5,\n",
       " '69': 5,\n",
       " '68': 5,\n",
       " '67': 5,\n",
       " '66': 5,\n",
       " '65': 5,\n",
       " '64': 5,\n",
       " '63': 5,\n",
       " '62': 5,\n",
       " '61': 5,\n",
       " '60': 5,\n",
       " '59': 5,\n",
       " '58': 5,\n",
       " '57': 5,\n",
       " '56': 5,\n",
       " '55': 5,\n",
       " '54': 5,\n",
       " '53': 5,\n",
       " '52': 5,\n",
       " '51': 5,\n",
       " '50': 5,\n",
       " '49': 5,\n",
       " '48': 5,\n",
       " '47': 5,\n",
       " '46': 5,\n",
       " '45': 5,\n",
       " '44': 5,\n",
       " '43': 5,\n",
       " '42': 5,\n",
       " '41': 5,\n",
       " '40': 5,\n",
       " '39': 5,\n",
       " '38': 5,\n",
       " '37': 5,\n",
       " '36': 5,\n",
       " '35': 5,\n",
       " '34': 5,\n",
       " '33': 5,\n",
       " '32': 5,\n",
       " '31': 5,\n",
       " '30': 5,\n",
       " '29': 5,\n",
       " '28': 5,\n",
       " '27': 5,\n",
       " '26': 5,\n",
       " '25': 5,\n",
       " '24': 5,\n",
       " '23': 5,\n",
       " '22': 5,\n",
       " '21': 5,\n",
       " '20': 5,\n",
       " '19': 5,\n",
       " '18': 5,\n",
       " '17': 5,\n",
       " '16': 5,\n",
       " '15': 5,\n",
       " '14': 5,\n",
       " '13': 5,\n",
       " '12': 5,\n",
       " '11': 5,\n",
       " '10': 5,\n",
       " '09': 5,\n",
       " '08': 5,\n",
       " '07': 5,\n",
       " '06': 5,\n",
       " '05': 5,\n",
       " '04': 5,\n",
       " '03': 5,\n",
       " '02': 5,\n",
       " '01': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "575097c6-4bb1-4268-99da-0e14f1b52e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_males = 0 \n",
    "count_females = 0 \n",
    "male_list = []\n",
    "for index, row in Crema_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if gender == 'male':\n",
    "        count_males +=1\n",
    "        if actor not in male_list: \n",
    "            male_list.append(actor)\n",
    "    else: \n",
    "        count_females +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3357d85c-b997-440f-bf87-f55e0760aacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 220)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_males, count_females"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31e6a9-1c3a-4c2b-ad0b-3c3d707c2117",
   "metadata": {},
   "source": [
    "Since there are more males than females we will remove randomly 3 male actors (since there are exactly 5 audio files per actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d21fa86-ad54-432a-a41d-ff9eb6d33ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17', '80', '88']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.seed(42)\n",
    "males_to_remove = random.sample(male_list, 3)\n",
    "males_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9858b72-160f-4b9d-a1ce-4704df6a6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = []\n",
    "for index, row in Crema_df.iterrows(): \n",
    "    if row['actors'] not in males_to_remove: \n",
    "        new_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0095d4e-bba4-4c58-bc73-a473e41c0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3e43eb-c058-40bc-9099-f1dca9ed15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in CREMA_df.iterrows(): \n",
    "    if row['actors'] == '17': \n",
    "        print(\"Elements not removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d2dc355-d534-492b-8c22-b68c5b435753",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_males = 0 \n",
    "count_females = 0 \n",
    "male_list = []\n",
    "female_list = []\n",
    "for index, row in CREMA_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if gender == 'male':\n",
    "        count_males +=1\n",
    "        if actor not in male_list: \n",
    "            male_list.append(actor)\n",
    "    else: \n",
    "        count_females +=1\n",
    "        if actor not in female_list: \n",
    "            female_list.append(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a984bad0-b2d5-47c0-82ae-22584312394b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 220)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_males, count_females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19eb1ee0-6522-4380-bb1a-646a37b21537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca6f056-abef-44d6-bcdd-3faef63c022b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b87fa85-5994-4f71-b8e2-b2a4a15ce74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_train = []\n",
    "CREMA_val = []\n",
    "CREMA_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea45b01a-b419-410f-8745-37609c082702",
   "metadata": {},
   "outputs": [],
   "source": [
    "females_train = random.sample(female_list, 32)\n",
    "males_train = random.sample(male_list, 32)\n",
    "\n",
    "# remove the elements assigned to train \n",
    "for element in females_train:\n",
    "    if element in female_list:\n",
    "        female_list.remove(element)\n",
    "        \n",
    "for element in males_train:\n",
    "    if element in male_list:\n",
    "        male_list.remove(element)\n",
    "\n",
    "         \n",
    "females_val = random.sample(female_list, 6) \n",
    "males_val = random.sample(male_list, 6) \n",
    "\n",
    "# remove the elements assigned to val\n",
    "for element in females_val:\n",
    "    if element in female_list:\n",
    "        female_list.remove(element)\n",
    "        \n",
    "for element in males_val:\n",
    "    if element in male_list:\n",
    "        male_list.remove(element)\n",
    "        \n",
    "females_test = random.sample(female_list, 6) \n",
    "males_test = random.sample(male_list, 6)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04f4e4f7-952c-49ee-af27-87ddf7f6b042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['54',\n",
       "  '56',\n",
       "  '58',\n",
       "  '74',\n",
       "  '76',\n",
       "  '13',\n",
       "  '78',\n",
       "  '29',\n",
       "  '84',\n",
       "  '89',\n",
       "  '09',\n",
       "  '60',\n",
       "  '04',\n",
       "  '55',\n",
       "  '52',\n",
       "  '91',\n",
       "  '02',\n",
       "  '07',\n",
       "  '46',\n",
       "  '49',\n",
       "  '37',\n",
       "  '10',\n",
       "  '20',\n",
       "  '75',\n",
       "  '21',\n",
       "  '53',\n",
       "  '06',\n",
       "  '28',\n",
       "  '18',\n",
       "  '63',\n",
       "  '30',\n",
       "  '03'],\n",
       " ['57',\n",
       "  '69',\n",
       "  '65',\n",
       "  '45',\n",
       "  '77',\n",
       "  '81',\n",
       "  '41',\n",
       "  '15',\n",
       "  '44',\n",
       "  '23',\n",
       "  '59',\n",
       "  '86',\n",
       "  '34',\n",
       "  '01',\n",
       "  '85',\n",
       "  '66',\n",
       "  '31',\n",
       "  '33',\n",
       "  '05',\n",
       "  '48',\n",
       "  '50',\n",
       "  '67',\n",
       "  '51',\n",
       "  '22',\n",
       "  '36',\n",
       "  '87',\n",
       "  '71',\n",
       "  '39',\n",
       "  '42',\n",
       "  '11',\n",
       "  '32',\n",
       "  '14'],\n",
       " ['43', '61', '40', '47', '73', '24'],\n",
       " ['62', '68', '64', '83', '70', '26'],\n",
       " ['08', '79', '12', '25', '72', '82'],\n",
       " ['16', '19', '38', '35', '27', '90'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "females_train, males_train, females_val, males_val, females_test, males_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3345e91-aaa1-45de-998e-32e86f8a2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = females_train + males_train \n",
    "val = females_val + males_val \n",
    "test = females_test + males_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a9b0aa8-fb4a-4b78-b143-a1dcca2f1325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in CREMA_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if actor in train: \n",
    "        CREMA_train.append(row)\n",
    "    elif actor in val: \n",
    "        CREMA_val.append(row)\n",
    "    else:\n",
    "        CREMA_test.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0bfc825-f2f5-4836-9b30-60fec748a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_train = pd.DataFrame(CREMA_train) \n",
    "CREMA_val = pd.DataFrame(CREMA_val) \n",
    "CREMA_test = pd.DataFrame(CREMA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32afcd75-341a-429d-a78d-76e2a8e327ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 4), (60, 4), (60, 4))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREMA_train.shape, CREMA_val.shape, CREMA_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d71b72-f0d2-4adf-8af0-3e2756218eef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgust</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion_label actors  gender  \\\n",
       "0         happy     91  female   \n",
       "1       sadness     91  female   \n",
       "2         angry     91  female   \n",
       "3       disgust     91  female   \n",
       "4          fear     91  female   \n",
       "\n",
       "                                                path  \n",
       "0  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "1  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "3  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "4  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREMA_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bf0a8cd-1ed4-4ae7-99fb-74ace48127ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = CREMA_train.reset_index(drop=True) \n",
    "df_val = CREMA_val.reset_index(drop=True) \n",
    "df_test = CREMA_test.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c435abe-684f-4061-96d3-92ffe8841c10",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6cfc766-bfbf-4ce7-ad81-7e819c980cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'sadness', 'angry', 'disgust', 'fear'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['emotion_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76b53d74-af0c-4aa2-aa91-b394b9219b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Emotions distribution')\n",
    "plt.hist(df_train['emotion_label'])\n",
    "# plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "381069cd-2dec-4aae-be85-ba1d1615f96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Emotions distribution')\n",
    "plt.hist(df_val['emotion_label'])\n",
    "# plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e36f521-f7ef-499c-9323-a881711d32f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Emotions distribution')\n",
    "plt.hist(df_test['emotion_label'])\n",
    "# plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a9071bb-7b0b-4215-9727-1137fe790c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3925ef-65c7-4715-8e18-851838260cb3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b7e3503-074d-4240-ba18-48ef4439ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(df):\n",
    "    X = []\n",
    "    for i in tqdm(df['path']): \n",
    "        X.append(librosa.load(i, res_type='kaiser_fast', sr=16000))\n",
    "    return X\n",
    "\n",
    "def extract_samples(X): \n",
    "    samples = []\n",
    "    for ind,i in enumerate(X):\n",
    "        samples.append(i[0])\n",
    "    return samples \n",
    "\n",
    "def extract_labels(df): \n",
    "    labels = df['emotion_label'].copy()\n",
    "    return labels \n",
    "\n",
    "def compute_lengths(samples): \n",
    "    lengths = [len(x) for x in samples]\n",
    "    return lengths \n",
    "\n",
    "def check_outliers(lengths):\n",
    "    # outliers\n",
    "    lengths = np.array(lengths)\n",
    "    print((lengths > 300000).sum())\n",
    "    new_lengths = lengths[lengths < 300000]\n",
    "    return new_lengths \n",
    "\n",
    "def compute_mean_length(lengths): \n",
    "    return lengths.mean()\n",
    "\n",
    "def cut_and_pad(samples, labels, length_chosen = LENGTH_CHOSEN): \n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    count = 0 \n",
    "    for ind,i in enumerate(samples):\n",
    "        if i.shape[0] < 300000:\n",
    "            if i.shape[0] > length_chosen:\n",
    "                new = i[:length_chosen]\n",
    "                X_new.append(new)\n",
    "            elif i.shape[0] < length_chosen:\n",
    "                new = np.pad(i,math.ceil((length_chosen-i.shape[0])/2), mode='median')\n",
    "                X_new.append(new)\n",
    "            else:\n",
    "                X_new.append(i)\n",
    "            y_new.append(labels[count])\n",
    "        count+=1\n",
    "    \n",
    "    return X_new, y_new\n",
    "\n",
    "# Data Augmentation \n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "# Data Augmentation \n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "    \n",
    "def compute_mfccs(samples): \n",
    "    mfccs = []\n",
    "    for i in tqdm(samples):\n",
    "        mfcc = librosa.feature.mfcc(y=i, sr=16000, n_mfcc=13)\n",
    "        mfcc = mfcc.T\n",
    "        mfcc = np.array(mfcc)\n",
    "        mfccs.append(mfcc[:, 1:])\n",
    "    mfccs = np.array(mfccs)\n",
    "    return mfccs\n",
    "\n",
    "def compute_mfccs_augmentation(samples, labels): \n",
    "    mfccs = []\n",
    "    counter = 0 \n",
    "    for i in tqdm(samples):\n",
    "\n",
    "       # Weiner Filtering on original noise \n",
    "        samples_weiner = scipy.signal.wiener(i)\n",
    "        is_fin = np.isfinite(samples_weiner).all()\n",
    "\n",
    "\n",
    "        # Data Augmentation - Noise \n",
    "        noise_audio = noise(samples_weiner)\n",
    "\n",
    "        # Data Augmentation - Pitch \n",
    "        pitch_audio = pitch(samples_weiner, sampling_rate=16000)\n",
    "\n",
    "\n",
    "        # Data Augmentation -  pitch + noise \n",
    "        pn = pitch(noise_audio, sampling_rate = 16000)\n",
    "\n",
    "\n",
    "        if is_fin: \n",
    "          # MFCC\n",
    "\n",
    "          mfcc = librosa.feature.mfcc(y=i, sr=16000, n_mfcc=13)\n",
    "          mfcc = mfcc.T\n",
    "          mfccs.append(mfcc[:, 1:])\n",
    "\n",
    "          mfcc_augmented = librosa.feature.mfcc(y=samples_weiner, sr=16000, n_mfcc=13)\n",
    "          mfcc_augmented = mfcc_augmented.T\n",
    "          mfccs.append(mfcc_augmented[:, 1:])\n",
    "\n",
    "          mfcc_augmented_pitch = librosa.feature.mfcc(y=noise_audio, sr=16000, n_mfcc=13)\n",
    "          mfcc_augmented_pitch = mfcc_augmented_pitch.T\n",
    "          mfccs.append(mfcc_augmented_pitch[:, 1:])\n",
    "\n",
    "          mfcc_augmented_p = librosa.feature.mfcc(y=pitch_audio, sr=16000, n_mfcc=13)\n",
    "          mfcc_augmented_p = mfcc_augmented_p.T\n",
    "          mfccs.append(mfcc_augmented_p[:, 1:]) \n",
    "\n",
    "          mfcc_augmented_pn = librosa.feature.mfcc(y=pn, sr=16000, n_mfcc=13)\n",
    "          mfcc_augmented_pn = mfcc_augmented_pn.T\n",
    "          mfccs.append(mfcc_augmented_pn[:, 1:]) \n",
    "    \n",
    "    mfccs = np.array(mfccs)\n",
    "    \n",
    "    # Copy labels \n",
    "    y_prov = []\n",
    "    y = labels \n",
    "    for i in range(len(y)): \n",
    "      y_prov.append(y[i])\n",
    "      y_prov.append(y[i])\n",
    "      y_prov.append(y[i])\n",
    "      y_prov.append(y[i])\n",
    "      y_prov.append(y[i])\n",
    "    y = np.asarray(y_prov)\n",
    "\n",
    "    return mfccs, y \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7bdb8f-497e-4fa3-8417-d8b7366bfa28",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7d288-e7bc-4520-a979-28683f591df7",
   "metadata": {},
   "source": [
    "### Load samples and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf16085f-886e-450b-85ea-98e38f836c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 320/320 [00:00<00:00, 2410.07it/s]\n"
     ]
    }
   ],
   "source": [
    "load_train = load_files(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e6be5f8-9dd0-4f2d-a3d4-4f0af0e1806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = extract_samples(load_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c89ef79-b990-4ba1-ba15-df3c95dc7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = extract_labels(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a51158-0ece-4bca-bccc-43ed5d1d4303",
   "metadata": {},
   "source": [
    "### Decide length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5889c68-1976-4372-98a8-e0e0430c3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = compute_lengths(samples_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5890405-52d1-4bff-8aca-be13fdb78433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "new_lengths = check_outliers(lengths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a61a9c5a-f602-4851-8fed-4d5e5a7bc34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_length = compute_mean_length(new_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d932eda-6bef-449a-a698-280b442b638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38532.509375"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440c22e-81a2-4411-9a7e-18f6bd1119b4",
   "metadata": {},
   "source": [
    "### Cut and Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "825dfe39-18d4-4451-9f57-c1c2188d3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train, labels_train = cut_and_pad(samples_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99504cc1-21be-4f89-a0bc-37f1de6350d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,) (320,)\n"
     ]
    }
   ],
   "source": [
    "samples_train = np.array(samples_train)\n",
    "labels_train = np.array(labels_train)\n",
    "print(samples_train.shape, labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af60c2-562c-4043-b78f-a19934a4afa2",
   "metadata": {},
   "source": [
    "### Feature Extraction - Without Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cac4e5ee-890e-44f5-982f-b791ec9bfde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 320/320 [00:03<00:00, 98.98it/s]\n"
     ]
    }
   ],
   "source": [
    "mfccs_train = compute_mfccs(samples_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7daffb5-69fd-4fd2-9d10-847eb9163a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 76, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79843adb-f98b-44d0-8c6d-41ad6b7d80f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcba64-52d4-4e40-8574-fc72dd9b1079",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26bd68f1-5129-4f92-b658-ba00075d8449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 60/60 [00:00<00:00, 2197.27it/s]\n"
     ]
    }
   ],
   "source": [
    "load_val = load_files(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d251140a-da07-49ea-a329-8ea4a2b50f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_val = extract_samples(load_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd0bb8ce-0620-40f2-8d0b-6225d32b1862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_val = extract_labels(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a17c7-fb65-4a82-89d6-402be00abb58",
   "metadata": {},
   "source": [
    "### Cut and Pad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98f2b991-7f6d-4ac3-9a55-1ab282c711d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_val, labels_val = cut_and_pad(samples_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ec60c3a-cceb-4da2-8953-c76df46896eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,) (60,)\n"
     ]
    }
   ],
   "source": [
    "samples_val = np.array(samples_val)\n",
    "labels_val = np.array(labels_val)\n",
    "print(samples_val.shape, labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25753f-aa80-4a53-8d0e-af789341f06b",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10435013-7bce-4b66-ba8b-906c980a98c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 60/60 [00:00<00:00, 117.73it/s]\n"
     ]
    }
   ],
   "source": [
    "mfccs_val = compute_mfccs(samples_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "476899cb-d09f-4bf6-aa97-aa960aad5b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 76, 12)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0929c3fa-4f11-40ec-be71-b4c56dcc9682",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c13737-07bd-400d-9f92-b14cb1450e05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9021731e-1ba0-4de6-a0ea-05c2128a28d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 60/60 [00:00<00:00, 1428.04it/s]\n"
     ]
    }
   ],
   "source": [
    "load_test = load_files(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5a34fcc-b447-456d-9537-10793c68c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_test = extract_samples(load_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0f9b99e-73db-46b3-bcba-8335ddd278bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_test = extract_labels(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598c755-06fe-41c8-af59-873dc9ec28cf",
   "metadata": {},
   "source": [
    "### Cut and Pad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63c5a00f-f200-4fde-9e1e-5a12a4090b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_test, labels_test = cut_and_pad(samples_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1588e5a7-e7e2-4d3f-a9db-ad391e9fd1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,) (60,)\n"
     ]
    }
   ],
   "source": [
    "samples_test = np.array(samples_test)\n",
    "labels_test = np.array(labels_test)\n",
    "print(samples_test.shape, labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5cf95-c714-4d73-88c9-83f8ad9ee3de",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70090428-482d-489f-a9e9-d98008962a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 60/60 [00:00<00:00, 118.93it/s]\n"
     ]
    }
   ],
   "source": [
    "mfccs_test = compute_mfccs(samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "191b2e4f-17b2-41fe-9daa-f5cde718a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 76, 12)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037f568-84b4-423d-bd97-989a4ff4c050",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Encode Labels - Binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "539dabac-5ed6-43c0-b227-aa6277d24559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_enc = {'fear':1, 'disgust':1, 'neutral':0, 'calm':0,  'happy':0, 'sadness':1, 'surprise':0, 'angry':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fbe6794d-9cc6-4541-b8c9-10dbcc62b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.Series(labels_train).replace(emotion_enc)\n",
    "#y_train_aug = pd.Series(labels_train_aug).map(emotion_enc)\n",
    "y_val = pd.Series(labels_val).map(emotion_enc)\n",
    "y_test = pd.Series(labels_test).map(emotion_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d759799-dd43-4646-84d9-26d4d4f2f9ed",
   "metadata": {},
   "source": [
    "# Train, Val, Test (X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c70362e-6f52-4628-8940-b11fa69d96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mfccs_train\n",
    "#X_train_aug = mfccs_train_aug \n",
    "X_val = mfccs_val\n",
    "X_test = mfccs_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b8e76-545a-4a33-9cba-c6dba383ec7d",
   "metadata": {},
   "source": [
    "# Standard Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871c438-7f45-4d5a-bf0f-1add02ffeccd",
   "metadata": {},
   "source": [
    "## Without Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6baf494b-3428-4532-be50-0ca5481b791e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1dff6-7bad-4ef9-b00d-631ac2940b33",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "346bae6e-994f-4113-abd4-ce6c07f34635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:54:04.141551: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-25 14:54:04.141878: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 248, 256)          21760     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 248, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 62, 128)           163968    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 308,737\n",
      "Trainable params: 308,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv1D(256, 7,padding='same',\n",
    "                 input_shape=(248,12), kernel_initializer=tf.keras.initializers.HeNormal(seed=0)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "model.add(layers.Dropout(0.6))\n",
    "\n",
    "model.add(layers.Conv1D(128, 5,padding='same', kernel_initializer=tf.keras.initializers.HeNormal(seed=0)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,  kernel_initializer=tf.keras.initializers.HeNormal(seed=0)))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa1149-c729-4e60-9974-8bd63ba4c173",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67e204-9023-4403-b02c-54de0661bfb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Without Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1454af2-bb08-4537-8c2d-a6fe1532e44b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7d454-3780-437c-a96f-d5461273045b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84d2b4b5-a8d1-4bb0-990f-3ba1ed91b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"/home/helemanc/Desktop/Binary_Model/weights/binary_model_l1l2.hdf5\"\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                                 factor=0.5, patience=4, \n",
    "                                                 verbose=1, mode='max', \n",
    "                                                 min_lr=0.00001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=45, \n",
    "                                              verbose=1)\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=weight_path, \n",
    "                                                      save_weights_only=True, \n",
    "                                                      monitor='val_accuracy', \n",
    "                                                      mode='max', \n",
    "                                                      save_best_only=True)\n",
    "# classweight \n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f1e1918-32d3-4b12-b0a8-6800455e1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a30ef-8dc3-4a81-be63-6c98e2703c74",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e5cf7439-75b5-4cf1-b924-d63034cb2acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:54:23.723125: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-25 14:54:23.741388: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 6.5920 - accuracy: 0.6174 - val_loss: 0.9007 - val_accuracy: 0.7167\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 1.7802 - accuracy: 0.6468 - val_loss: 0.6884 - val_accuracy: 0.5667\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 1.5292 - accuracy: 0.6131 - val_loss: 0.4243 - val_accuracy: 0.7833\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.1922 - accuracy: 0.6641 - val_loss: 0.4493 - val_accuracy: 0.8167\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.7189 - val_loss: 0.4593 - val_accuracy: 0.8000\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.7418 - val_loss: 0.4950 - val_accuracy: 0.7833\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7775 - val_loss: 0.4800 - val_accuracy: 0.8333\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7461 - val_loss: 0.7069 - val_accuracy: 0.5500\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.6874 - val_loss: 0.3835 - val_accuracy: 0.8667\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.8080 - val_loss: 0.5482 - val_accuracy: 0.6500\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.7290 - val_loss: 0.7065 - val_accuracy: 0.5500\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7376 - val_loss: 0.4285 - val_accuracy: 0.7833\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7572 - val_loss: 0.5083 - val_accuracy: 0.7833\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.7954 - val_loss: 0.4960 - val_accuracy: 0.7833\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.7851 - val_loss: 0.3757 - val_accuracy: 0.8500\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8415 - val_loss: 0.3539 - val_accuracy: 0.8667\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8363 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7892 - val_loss: 0.4154 - val_accuracy: 0.8167\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7763 - val_loss: 0.3986 - val_accuracy: 0.8000\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8288 - val_loss: 0.4581 - val_accuracy: 0.8167\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3284 - accuracy: 0.8061 - val_loss: 0.4175 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8131 - val_loss: 0.3728 - val_accuracy: 0.8500\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3068 - accuracy: 0.8637 - val_loss: 0.3671 - val_accuracy: 0.8167\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8494 - val_loss: 0.3705 - val_accuracy: 0.8333\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3140 - accuracy: 0.8624 - val_loss: 0.3773 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3557 - accuracy: 0.8492 - val_loss: 0.3655 - val_accuracy: 0.8333\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.8473 - val_loss: 0.3748 - val_accuracy: 0.8167\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8667 - val_loss: 0.3638 - val_accuracy: 0.8333\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8154 - val_loss: 0.3604 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8232 - val_loss: 0.3569 - val_accuracy: 0.8333\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2517 - accuracy: 0.8825 - val_loss: 0.3598 - val_accuracy: 0.8167\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2692 - accuracy: 0.8759 - val_loss: 0.3623 - val_accuracy: 0.8167\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2162 - accuracy: 0.8876 - val_loss: 0.3507 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.8592 - val_loss: 0.3590 - val_accuracy: 0.8167\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2918 - accuracy: 0.8685 - val_loss: 0.3537 - val_accuracy: 0.8167\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8172 - val_loss: 0.3541 - val_accuracy: 0.8167\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2811 - accuracy: 0.8739 - val_loss: 0.3519 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2357 - accuracy: 0.8975 - val_loss: 0.3465 - val_accuracy: 0.8500\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3015 - accuracy: 0.8576 - val_loss: 0.3495 - val_accuracy: 0.8167\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2664 - accuracy: 0.9134 - val_loss: 0.3494 - val_accuracy: 0.8167\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3014 - accuracy: 0.8320 - val_loss: 0.3509 - val_accuracy: 0.8167\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8389 - val_loss: 0.3524 - val_accuracy: 0.8167\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3589 - accuracy: 0.7973 - val_loss: 0.3536 - val_accuracy: 0.8167\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8534 - val_loss: 0.3496 - val_accuracy: 0.8167\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2537 - accuracy: 0.8864 - val_loss: 0.3475 - val_accuracy: 0.8167\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2906 - accuracy: 0.8735 - val_loss: 0.3455 - val_accuracy: 0.8333\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2462 - accuracy: 0.8687 - val_loss: 0.3452 - val_accuracy: 0.8167\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2837 - accuracy: 0.8780 - val_loss: 0.3446 - val_accuracy: 0.8167\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8927 - val_loss: 0.3509 - val_accuracy: 0.8000\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2380 - accuracy: 0.8493 - val_loss: 0.3428 - val_accuracy: 0.8333\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2523 - accuracy: 0.8801 - val_loss: 0.3389 - val_accuracy: 0.8333\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2380 - accuracy: 0.8683 - val_loss: 0.3338 - val_accuracy: 0.8333\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.8811 - val_loss: 0.3400 - val_accuracy: 0.8167\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.8752 - val_loss: 0.3384 - val_accuracy: 0.8333\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8089 - val_loss: 0.3425 - val_accuracy: 0.8167\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.8872 - val_loss: 0.3370 - val_accuracy: 0.8167\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2545 - accuracy: 0.8727 - val_loss: 0.3400 - val_accuracy: 0.8167\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9332 - val_loss: 0.3411 - val_accuracy: 0.8167\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8351 - val_loss: 0.3387 - val_accuracy: 0.8167\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2793 - accuracy: 0.8829 - val_loss: 0.3352 - val_accuracy: 0.8333\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2574 - accuracy: 0.8613 - val_loss: 0.3330 - val_accuracy: 0.8333\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2377 - accuracy: 0.9229 - val_loss: 0.3343 - val_accuracy: 0.8167\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.8806 - val_loss: 0.3380 - val_accuracy: 0.8167\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8386 - val_loss: 0.3414 - val_accuracy: 0.8167\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.8995 - val_loss: 0.3442 - val_accuracy: 0.8167\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3030 - accuracy: 0.8319 - val_loss: 0.3464 - val_accuracy: 0.8167\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2754 - accuracy: 0.8675 - val_loss: 0.3453 - val_accuracy: 0.8167\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2773 - accuracy: 0.8747 - val_loss: 0.3446 - val_accuracy: 0.8167\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.8901 - val_loss: 0.3423 - val_accuracy: 0.8167\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8556 - val_loss: 0.3389 - val_accuracy: 0.8167\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2558 - accuracy: 0.8768 - val_loss: 0.3425 - val_accuracy: 0.8167\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.8794 - val_loss: 0.3464 - val_accuracy: 0.8167\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.8810 - val_loss: 0.3445 - val_accuracy: 0.8167\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3011 - accuracy: 0.8695 - val_loss: 0.3419 - val_accuracy: 0.8167\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2572 - accuracy: 0.8537 - val_loss: 0.3366 - val_accuracy: 0.8167\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2451 - accuracy: 0.8930 - val_loss: 0.3383 - val_accuracy: 0.8167\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8951 - val_loss: 0.3391 - val_accuracy: 0.8167\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.8475 - val_loss: 0.3352 - val_accuracy: 0.8167\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1648 - accuracy: 0.9051 - val_loss: 0.3325 - val_accuracy: 0.8167\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8555 - val_loss: 0.3376 - val_accuracy: 0.8167\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2488 - accuracy: 0.8968 - val_loss: 0.3365 - val_accuracy: 0.8167\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2344 - accuracy: 0.8838 - val_loss: 0.3351 - val_accuracy: 0.8167\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2121 - accuracy: 0.9103 - val_loss: 0.3356 - val_accuracy: 0.8167\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.8886 - val_loss: 0.3332 - val_accuracy: 0.8167\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2391 - accuracy: 0.8677 - val_loss: 0.3321 - val_accuracy: 0.8167\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1998 - accuracy: 0.9074 - val_loss: 0.3321 - val_accuracy: 0.8167\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8863 - val_loss: 0.3335 - val_accuracy: 0.8167\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.8551 - val_loss: 0.3379 - val_accuracy: 0.8167\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2204 - accuracy: 0.9016 - val_loss: 0.3360 - val_accuracy: 0.8167\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.8824 - val_loss: 0.3272 - val_accuracy: 0.8167\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.8971 - val_loss: 0.3322 - val_accuracy: 0.8167\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2328 - accuracy: 0.9050 - val_loss: 0.3312 - val_accuracy: 0.8167\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8568 - val_loss: 0.3346 - val_accuracy: 0.8167\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.8382 - val_loss: 0.3287 - val_accuracy: 0.8167\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2510 - accuracy: 0.9104 - val_loss: 0.3301 - val_accuracy: 0.8167\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2800 - accuracy: 0.9060 - val_loss: 0.3291 - val_accuracy: 0.8167\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1954 - accuracy: 0.9162 - val_loss: 0.3255 - val_accuracy: 0.8167\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2391 - accuracy: 0.9202 - val_loss: 0.3275 - val_accuracy: 0.8167\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2069 - accuracy: 0.9081 - val_loss: 0.3255 - val_accuracy: 0.8167\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 0.8471 - val_loss: 0.3279 - val_accuracy: 0.8167\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2415 - accuracy: 0.8911 - val_loss: 0.3259 - val_accuracy: 0.8167\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8559 - val_loss: 0.3290 - val_accuracy: 0.8167\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9161 - val_loss: 0.3295 - val_accuracy: 0.8167\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9274 - val_loss: 0.3275 - val_accuracy: 0.8167\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8755 - val_loss: 0.3290 - val_accuracy: 0.8167\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.8932 - val_loss: 0.3318 - val_accuracy: 0.8000\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1939 - accuracy: 0.9263 - val_loss: 0.3272 - val_accuracy: 0.8000\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1896 - accuracy: 0.9212 - val_loss: 0.3290 - val_accuracy: 0.8000\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2130 - accuracy: 0.9316 - val_loss: 0.3270 - val_accuracy: 0.8000\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1953 - accuracy: 0.9155 - val_loss: 0.3271 - val_accuracy: 0.8000\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9054 - val_loss: 0.3238 - val_accuracy: 0.8000\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1800 - accuracy: 0.9051 - val_loss: 0.3223 - val_accuracy: 0.8167\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.8696 - val_loss: 0.3210 - val_accuracy: 0.8167\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8915 - val_loss: 0.3215 - val_accuracy: 0.8167\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3128 - accuracy: 0.8414 - val_loss: 0.3192 - val_accuracy: 0.8167\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2640 - accuracy: 0.8978 - val_loss: 0.3221 - val_accuracy: 0.8167\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.8809 - val_loss: 0.3182 - val_accuracy: 0.8333\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2627 - accuracy: 0.8971 - val_loss: 0.3230 - val_accuracy: 0.8333\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2284 - accuracy: 0.8952 - val_loss: 0.3207 - val_accuracy: 0.8333\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2079 - accuracy: 0.9063 - val_loss: 0.3233 - val_accuracy: 0.8333\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2968 - accuracy: 0.8737 - val_loss: 0.3200 - val_accuracy: 0.8333\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.8804 - val_loss: 0.3241 - val_accuracy: 0.8000\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.8824 - val_loss: 0.3262 - val_accuracy: 0.8000\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.8789 - val_loss: 0.3238 - val_accuracy: 0.8167\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2652 - accuracy: 0.8919 - val_loss: 0.3198 - val_accuracy: 0.8500\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.1883 - accuracy: 0.9196 - val_loss: 0.3200 - val_accuracy: 0.8333\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2811 - accuracy: 0.8836 - val_loss: 0.3213 - val_accuracy: 0.8333\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3145 - accuracy: 0.8748 - val_loss: 0.3232 - val_accuracy: 0.8333\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2229 - accuracy: 0.8944 - val_loss: 0.3223 - val_accuracy: 0.8333\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.9138 - val_loss: 0.3271 - val_accuracy: 0.8167\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2757 - accuracy: 0.8657 - val_loss: 0.3243 - val_accuracy: 0.8333\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2310 - accuracy: 0.8860 - val_loss: 0.3197 - val_accuracy: 0.8333\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2704 - accuracy: 0.8633 - val_loss: 0.3174 - val_accuracy: 0.8333\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2151 - accuracy: 0.9034 - val_loss: 0.3161 - val_accuracy: 0.8333\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1892 - accuracy: 0.9371 - val_loss: 0.3181 - val_accuracy: 0.8333\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2839 - accuracy: 0.8483 - val_loss: 0.3150 - val_accuracy: 0.8500\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.9326 - val_loss: 0.3144 - val_accuracy: 0.8667\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.9060 - val_loss: 0.3184 - val_accuracy: 0.8333\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.1997 - accuracy: 0.9309 - val_loss: 0.3167 - val_accuracy: 0.8333\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2028 - accuracy: 0.9208 - val_loss: 0.3178 - val_accuracy: 0.8333\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8816 - val_loss: 0.3208 - val_accuracy: 0.8167\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8889 - val_loss: 0.3244 - val_accuracy: 0.8000\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2352 - accuracy: 0.8864 - val_loss: 0.3208 - val_accuracy: 0.8167\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.8537 - val_loss: 0.3206 - val_accuracy: 0.8167\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2369 - accuracy: 0.9146 - val_loss: 0.3199 - val_accuracy: 0.8167\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.1938 - accuracy: 0.8764 - val_loss: 0.3124 - val_accuracy: 0.8333\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2444 - accuracy: 0.8838 - val_loss: 0.3149 - val_accuracy: 0.8167\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9140 - val_loss: 0.3149 - val_accuracy: 0.8167\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.8723 - val_loss: 0.3114 - val_accuracy: 0.8333\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.8862 - val_loss: 0.3089 - val_accuracy: 0.8500\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.8708 - val_loss: 0.3063 - val_accuracy: 0.8500\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1791 - accuracy: 0.9095 - val_loss: 0.3083 - val_accuracy: 0.8333\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.9032 - val_loss: 0.3082 - val_accuracy: 0.8500\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2211 - accuracy: 0.9148 - val_loss: 0.3074 - val_accuracy: 0.8500\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3032 - accuracy: 0.9047 - val_loss: 0.3124 - val_accuracy: 0.8167\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2091 - accuracy: 0.9139 - val_loss: 0.3165 - val_accuracy: 0.8000\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.8825 - val_loss: 0.3128 - val_accuracy: 0.8000\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2682 - accuracy: 0.8660 - val_loss: 0.3087 - val_accuracy: 0.8333\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2677 - accuracy: 0.8751 - val_loss: 0.3124 - val_accuracy: 0.8000\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2929 - accuracy: 0.9057 - val_loss: 0.3187 - val_accuracy: 0.8000\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.8997 - val_loss: 0.3163 - val_accuracy: 0.8000\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2368 - accuracy: 0.8614 - val_loss: 0.3127 - val_accuracy: 0.8000\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8686 - val_loss: 0.3155 - val_accuracy: 0.8000\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2340 - accuracy: 0.8714 - val_loss: 0.3130 - val_accuracy: 0.8000\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2661 - accuracy: 0.8510 - val_loss: 0.3183 - val_accuracy: 0.8000\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.8988 - val_loss: 0.3202 - val_accuracy: 0.8000\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1857 - accuracy: 0.9016 - val_loss: 0.3184 - val_accuracy: 0.8000\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.9070 - val_loss: 0.3191 - val_accuracy: 0.8000\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.8676 - val_loss: 0.3200 - val_accuracy: 0.8000\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8394 - val_loss: 0.3206 - val_accuracy: 0.8000\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2475 - accuracy: 0.8947 - val_loss: 0.3232 - val_accuracy: 0.8000\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2124 - accuracy: 0.8990 - val_loss: 0.3163 - val_accuracy: 0.8000\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2132 - accuracy: 0.9129 - val_loss: 0.3140 - val_accuracy: 0.8167\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2542 - accuracy: 0.9147 - val_loss: 0.3169 - val_accuracy: 0.8000\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2032 - accuracy: 0.9263 - val_loss: 0.3158 - val_accuracy: 0.8000\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9356 - val_loss: 0.3151 - val_accuracy: 0.8000\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9337 - val_loss: 0.3144 - val_accuracy: 0.8000\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.9361 - val_loss: 0.3146 - val_accuracy: 0.8000\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2625 - accuracy: 0.8947 - val_loss: 0.3176 - val_accuracy: 0.8000\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9146 - val_loss: 0.3125 - val_accuracy: 0.8167\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.9407 - val_loss: 0.3171 - val_accuracy: 0.8000\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1960 - accuracy: 0.9336 - val_loss: 0.3157 - val_accuracy: 0.8000\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2812 - accuracy: 0.9198 - val_loss: 0.3150 - val_accuracy: 0.8000\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.9178 - val_loss: 0.3124 - val_accuracy: 0.8167\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9191 - val_loss: 0.3131 - val_accuracy: 0.8167\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1563 - accuracy: 0.9117 - val_loss: 0.3106 - val_accuracy: 0.8167\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8774 - val_loss: 0.3143 - val_accuracy: 0.8333\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2034 - accuracy: 0.8852 - val_loss: 0.3105 - val_accuracy: 0.8333\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9015 - val_loss: 0.3094 - val_accuracy: 0.8333\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.9041 - val_loss: 0.3131 - val_accuracy: 0.8167\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2710 - accuracy: 0.8866 - val_loss: 0.3102 - val_accuracy: 0.8333\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2471 - accuracy: 0.8918 - val_loss: 0.3091 - val_accuracy: 0.8333\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9302 - val_loss: 0.3073 - val_accuracy: 0.8333\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1402 - accuracy: 0.9407 - val_loss: 0.3069 - val_accuracy: 0.8333\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2274 - accuracy: 0.9024 - val_loss: 0.3114 - val_accuracy: 0.8333\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1917 - accuracy: 0.9220 - val_loss: 0.3116 - val_accuracy: 0.8333\n",
      "Epoch 00196: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4, epochs=500, validation_data=(X_val, y_val),\n",
    "           callbacks=[reduce_lr, early_stop, model_checkpoint], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100a8a8-afab-4edf-b836-95826a33c9cf",
   "metadata": {},
   "source": [
    "### Plot Training Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3f996b68-15d9-472c-8717-44a81ea5d807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4IElEQVR4nO3dd3xUVf7/8df0Se8JLQECQUOkRJoUUZogZQEFUcGKrrquiF1ZXfeLK/bK/kSU1bUt6goaaWKjCtIDAqG3JJCE9Dr9/v64yUAggRCYJFw+z8cjj0zu3Dv3M3cm73vm3Dvn6hRFURBCCKFZ+sYuQAghhG9J0AshhMZJ0AshhMZJ0AshhMZJ0AshhMZJ0AshhMZJ0AsBPP3007z11lt1mnfgwIGsWbPmvB9HiIYiQS+EEBonQS+EEBonQS8uGgMHDmTOnDmMGjWKrl27Mm3aNHJzc7nnnntITk7mzjvvpKioyDv/L7/8wogRI+jevTu33XYb+/fv9963c+dOxo4dS3JyMlOnTsVut1db17Jlyxg9ejTdu3fn5ptvZteuXfWq+euvv2bIkCH07NmT+++/n+zsbAAURWHGjBn07t2bK6+8klGjRrFnzx4AVqxYwfDhw0lOTubqq6/m3//+d73WLYSXIsRFYsCAAcr48eOV48ePK1lZWcpVV12ljBkzRtmxY4dis9mU2267TZk5c6aiKIpy4MABpUuXLsrq1asVh8OhfPDBB8rgwYMVu92u2O125dprr1U+/vhjxeFwKEuWLFE6duyovPnmm4qiKMqOHTuUq666SklNTVVcLpcyf/58ZcCAAYrdbvfW8dtvv9VY41NPPeV9nDVr1ig9e/ZUtm/frtjtdmX69OnKrbfeqiiKoqxcuVIZO3asUlRUpHg8HmXfvn1Kdna2oiiK0rdvX2XDhg2KoihKYWGhsn37dt9tVHFJkBa9uKhMmjSJyMhIYmJi6N69O507d6Zjx45YLBaGDBnCzp07AVi8eDHXXHMNffv2xWQyMXnyZGw2G1u2bGHr1q04nU7uuOMOTCYTw4YNo1OnTt51fPXVV0yYMIEuXbpgMBgYO3YsJpOJ1NTUc6p1wYIF3HjjjSQlJWE2m3n00UdJTU0lIyMDo9FIWVkZBw4cQFEU2rVrR3R0NABGo5F9+/ZRWlpKSEgISUlJF2z7iUuTBL24qERGRnpvWyyWan9brVbKy8sByMnJoUWLFt779Ho9zZs3Jzs7m5ycHGJiYtDpdN77T5736NGjfPzxx3Tv3t37k5WVRU5OzjnVmpOTQ8uWLb1/BwQEEBoaSnZ2Nr1792bixIlMnz6d3r1789xzz1FaWgrAu+++y4oVKxgwYACTJk1iy5Yt57ReIU4lQS80KTo6mqNHj3r/VhSFY8eOERMTQ1RUFNnZ2SgnDdx68rzNmzfn/vvvZ+PGjd6frVu3MnLkyHOuITMz0/t3eXk5hYWFxMTEAHD77bczf/58Fi9ezKFDh5gzZw4AnTt3ZtasWaxZs4bBgwczderU+mwCIbwk6IUmXX/99axYsYK1a9fidDr56KOPMJvNJCcn07VrV4xGI59++ilOp5Mff/yRP/74w7vs+PHj+fLLL9m6dSuKolBeXs7y5cu9Le66GjlyJPPnzyctLQ2Hw8Gbb75J586dadWqFdu2bfN2Ifn5+WE2m9Hr9TgcDr7//ntKSkowmUwEBASg18u/qTg/xsYuQAhfiI+P57XXXuOFF14gOzubxMRE3n//fcxmMwAzZ87kueee4+233+aaa65hyJAh3mU7derECy+8wPTp0zl8+DBWq5Urr7yS7t27n1MNffr04eGHH+ahhx6iuLiY5ORk75epysrKmDFjBhkZGZjNZvr168fkyZMBSElJ4YUXXsDtdtO2bVtee+21C7RVxKVKpyhy4REhhNAy+UwohBAaJ0EvhBAaJ0EvhBAaJ0EvhBAa16TOuklNTcVisdRrWbvdXu9lfU1qqx+prX6ktvq5WGuz2+107dr1jMs3qaC3WCwkJibWa9m0tLR6L+trUlv9SG31I7XVz8VaW1pa2lmXl64bIYTQOAl6IYTQOAl6IYTQuCbVR18Tp9NJRkYGNpvtrPPVpa+qMdSlNqvVSqtWrTCZTA1UlRDiUtHkgz4jI4OgoCDatGlTbVjZU1VUVODn59eAldXd2WpTFIW8vDwyMjJo27ZtA1YmhLgUNPmuG5vNRkRExBlD/mKn0+mIiIg466cWIYSojyYf9ICmQ77KpfAchRCNo8l33dRFcYUTnUcG4RRCiJpcFC36s0kvKKfQ5vbJYxcXF/PFF1+c83L33nsvxcXFPqhICCHOjSaCHgV8Nap+cXExc+fOPW26y+U643IffvghwcHBvilKCCHOgSa6bvBh9/Ybb7zBkSNHGD16NEajEYvFQnBwMAcPHmTp0qX85S9/ISsrC7vdzu23386ECRMAGDhwIN988w3l5eXcc889dO/enS1bthATE8N7772H1Wr1XdFCCHGSiyro523K4OuN6adNL3e4MOh0WEyGc37Mm7rHcmO3VrXe/9hjj7F3715SUlJYt24d9913HwsWLCA2NhaAGTNmEBoais1mY9y4cVx33XWEhYVVe4wjR47w1ltv8c9//pOHH36YpUuXMnr06HOuVQgh6uOiCvraNdwZK506dfKGPMBnn33GTz/9BMCxY8c4fPjwaUHfokUL74BESUlJZGZmNli9QghxUQX9jd1a1dj6TjtWjL9RR+uoIJ/X4O/v7729bt061qxZw1dffYWfnx+33XYbdrv9tGWqLkgNYDAYapxHCCF8RRsHYwFfnVwZEBBAWVlZjfeVlJQQEhKCn58f+/fvJzU11UdVCCFE/V1ULfra+LLjJiwsjCuvvJKRI0disViIjIz03te/f3++/PJLrr/+etq2bXvWwf+FEKIxaCLo0fmuRQ/qmTc1MZvNzJkzp8b7fv31VwDCw8OZN2+ed/rkyZMvfIFCCHEGmui60fk66YUQ4iLm0xb9wIEDCQgIQK/XYzAYmD9/vs/WJTkvhBA183nXzSeffEJ4eLhP16GOByZRL4QQNdFI143EvBBC1EanKL4aJUbtugkJCUGn0zFhwgTv8AC1SU1NxWKxVJvmdDpJSEg443LpRU70OmgZ3DSvzqQoSp2GId67d2+DX2HKZrM12eEYpLb6kdrq52KureoLmbXxadfN3LlziYmJIS8vj7vuuov4+Hh69OhR6/wWi+W0gtPS0s565Sh9iRsUz0V7hakqJpPprC/YhZaWltbg66wrqa1+pLb6uVhrq8slVH3adRMTEwNAREQEQ4YMYdu2bb5cXZOQnJzc2CUIIUQ1Pgv68vJySktLvbd/++23s3bB1Jdcm0kIIWrns66bvLw8HnzwQQDcbjcjR46kf//+vlmZznfj0b/++us0b96ciRMnAjBz5kwMBgPr1q2juLgYl8vFww8/zODBg31TgBBCnCefBX1sbCzff//9hX3Q1Lmw5fPTJrdwulEUBcz1eDrJk6DrLbXePXz4cGbMmOEN+iVLlvDvf/+b22+/ncDAQPLz85kwYQKDBg2S674KIZokbQyB4EMdO3YkLy+P7OxsCgoKCA4OJjIykpdeeokNGzag1+vJzs4mNzeXqKioxi5XCCFOc3EFfddbamx9Z+WW4XS56dDMN5fuGzZsGEuXLiU3N5fhw4ezYMEC8vPzmT9/PiaTiYEDB8rQw0KIJku+MFUHw4cPZ/HixSxdupRhw4ZRUlJCREQEJpOJ33//XS4kIoRo0jQR9IBPkz4hIYGysjKio6OJjo5m1KhRbN++nVGjRpGSkkJ8fLzvVi6EEOfp4uq6qYVOB4qPB0FYsGCB93Z4eDhfffVVjfNt2bLFp3UIIcS50k6LXgghRI00EfQ6+cqUEELU6qII+rONu6bz4RemGooPx5YTQlzimnzQW61W8vLyNB2EiqKQl5fXZEfOE0Jc3Jr8wdhWrVqRkZHB8ePHa52noNyBzeGGoqY5eqXT6Tzr8MNWq5VWrVo1UEVCiEtJkw96k8lE27ZtzzjPM/O38cMfOWx5flgDVXVumvLwp0II7WvyXTd1odfp8Gi4a0cIIc6HJoLeoNfhkZwXQogaaSfoPY1dhRBCNE3aCHqdDrd03QghRI20EfTSdSOEELXSRNDr9XIwVgghaqOJoDfopEUvhBC10UTQ6yu7brT87VkhhKgvTQS9ofJardKqF0KI02ki6I0GNehdco6lEEKcRhNBr69q0UvOCyHEaTQR9IbKZyHn0gshxOk0EfRVLXq3dNILIcRpNBH0Bn1V140EvRBCnEpTQS9dN0IIcTpNBP2Jg7ES9EIIcSpNBL1RX3V6pQS9EEKcShNBr9fLwVghhKiNz4Pe7XYzZswY7rvvPp+t48Q3YyXohRDiVD4P+k8//ZR27dr5dB0GadELIUStfBr0WVlZLF++nHHjxvlyNd6uG2nRCyHE6Xwa9DNmzOCJJ55Ar/ftBweD9wtTPl2NEEJclIy+euBly5YRHh7OFVdcwbp16+q0jN1uJy0t7ZzXdexoGQD79u/HU2A55+V9zWaz1et5NQSprX6ktvqR2urnfGvzWdBv3ryZX3/9lZUrV2K32yktLeXxxx/n9ddfr3UZi8VCYmLiOa8rQ8kGsolr3ZbEViHnUbVvpKWl1et5NQSprX6ktvqR2urnTLXVZQfgs6B/7LHHeOyxxwBYt24dH3300RlD/nzIoGZCCFE7bZxHL4OaCSFErXzWoj9Zr1696NWrl88e3yBn3QghRK000aI3SIteCCFqpYmg18swxUIIUStNBL1RhikWQohaaSLo9TJ6pRBC1EoTQW+Q8eiFEKJW2gh6GdRMCCFqpYmg18swxUIIUStNBP2JFn0jFyKEEE2QRoJe/S1n3QghxOk0EvTq03B7pEkvhBCn0kbQy3j0QghRK00EfdV1TeT0SiGEOJ0mgt4g34wVQohaaSPoZVAzIYSolSaCXi4OLoQQtdNE0EuLXgghaqeNoDdI0AshRG20EfTSohdCiFppI+jlrBshhKiVJoJeL8MUCyFErTQR9DKomRBC1E4TQV+Z89J1I4QQNdBE0Ot0OvQ66boRQoiaaCLoQW3VyzVjhRDidJoJeoNOJ9+MFUKIGmgm6PU6OY9eCCFqoqGg10nQCyFEDbQT9HoZ1EwIIWqinaCXrhshhKiRhoJeDsYKIURNjL56YLvdzsSJE3E4HLjdboYOHcqUKVN8tToMOnC5JeiFEOJUPgt6s9nMJ598QkBAAE6nk1tvvZX+/fvTtWtXn6xPr9PJN2OFEKIGPuu60el0BAQEAOByuXC5XOgqBx/zBflmrBBC1EynKL5rBrvdbm644QaOHDnCrbfeyhNPPHHG+VNTU7FYLPVa193zDtMh0srT18TUa3lfstlsWK3Wxi6jRlJb/Uht9SO11c/ZaktMTDzj8j7rugEwGAykpKRQXFzMgw8+yJ49e+jQoUOt81sslrMWXBujIZ3AoOB6L+9LaWlpTbIukNrqS2qrH6mtfs5UW1pa2lmXb5CzboKDg+nVqxerVq3y2Trk9EohhKhZnYL+k08+obS0FEVRmDZtGmPHjmX16tVnXCY/P5/i4mJA/dixZs0a4uPjz7/iWhh0OhnUTAghalCnoJ83bx6BgYGsXr2a4uJiXn31Vd54440zLpOTk8Ptt9/OqFGjGDduHH369GHAgAEXpOia6HXyzVghhKhJnfroq47XrlixgtGjR5OQkMDZjuFefvnlfPfdd+ddYF3JWDdCCFGzOrXor7jiCu6++25WrlxJv379KC0tRa9vWl+qlbFuhBCiZnVq0b/44oukpaURGxuLn58fhYWFzJgxw9e1nRM5GCuEEDWrU7N8y5YttG3bluDgYFJSUpg1axZBQUG+ru2cSNeNEELUrE5B/49//AM/Pz927drFxx9/TFxcHE899ZSvazsnBjkYK4QQNapT0BuNRnQ6HT///DMTJ05k4sSJlJWV+bq2c6KX0yuFEKJGdQr6gIAAZs+ezffff8+1116Lx+PB5XL5urZzYtDLWDdCCFGTOgX9W2+9hdlsZsaMGURFRZGVlcXkyZN9Xds5kdErhRCiZnUK+qioKEaNGkVJSQnLli3DYrEwZswYH5d2btSzbhq7CiGEaHrqFPSLFy9m/Pjx/PDDDyxZssR7uymRYYqFEKJmdTqP/v333+ebb74hIiICUMexufPOOxk2bJhPizsX0nUjhBA1q1OLXlEUb8gDhIaGnnUIhIYmLXohhKhZnVr0/fr1Y/LkyYwYMQJQu3L69+/v08LOlUGvw+WRTnohhDhVnYL+qaeeYunSpWzevBmACRMmMGTIEJ8Wdq5kCAQhhKhZna8wNXToUIYOHerLWs6LDFMshBA1O2PQJycn13hBb0VR0Ol03hZ+U2CQsW6EEKJGZwz6LVu2NFQd501a9EIIUbOmNaj8eZDRK4UQomYaCno5GCuEEDXRTNAb9NKiF0KImmgm6PU65JuxQghRA00FvXxfSgghTqehoJexboQQoiYaCno5GCuEEDXRTNAbKr/YJQObCSFEdZoJen3lF3il+0YIIarTTNAbKpNeum+EEKI6zQS9t0UvQS+EENVoL+il60YIIarRUNDLwVghhKhJncejP1fHjh3jySefJC8vD51Ox0033cQdd9zhq9VJ140QQtTCZ0FvMBh4+umnSUpKorS0lBtvvJG+ffvSvn17n6yvqkUvXTdCCFGdz7puoqOjSUpKAiAwMJD4+Hiys7N9tTrMBjXobQ4ZB0EIIU7msxb9yTIyMkhLS6NLly5nnM9ut5OWllavdQQa3QCs376bsmhrvR7DV2w2W72fl69JbfUjtdWP1FY/51ubz4O+rKyMKVOmMG3aNAIDA884r8ViITExsV7rOZifCoBfWDMSE5vX6zF8JS0trd7Py9ektvqR2upHaqufM9VWlx2AT8+6cTqdTJkyhVGjRnHdddf5clVE+Kv7rKxim0/XI4QQFxufBb2iKPztb38jPj6eu+66y1er8Qqy6DEb9WRL0AshRDU+C/pNmzaRkpLC77//zujRoxk9ejQrVqzw1erQ6XTEBFsk6IUQ4hQ+66Pv3r07u3fv9tXD16hZsJWsIgl6IYQ4mWa+GQsQE2yVFr0QQpxCg0FvR5EvTQkhhJemgr5ZsJUKp5tim6uxSxFCiCZDU0EfHWwBIEe6b4QQwktTQd8sWP1GrJxLL4QQJ2gr6EMqg17OvBFCCC9NBX1MZYs+p8TeyJUIIUTToamgt5oMhPiZpEUvhBAn0VTQA0QHWcgpkaAXQogqmgv6MH8zRRXOxi5DCCGaDM0FfbCficJyCXohhKiiuaAP9TdRLC16IYTw0lzQh/iZKJSgF0IIL80FfaifiXKHG4dLrh0rhBCgxaD3NwHIAVkhhKikuaAP9qsKekcjVyKEEE2D5oI+1N8MIGfeCCFEJc0FfYifdN0IIcTJNBf0oZVBLy16IYRQaS/o5WCsEEJUo7mgD7JWtugl6IUQAtBg0Bv0OoKtRorK5awbIYQADQY9QIi/SbpuhBCikiaDPtTPLF03QghRSZtBLy16IYTw0mTQB/uZKJLTK4UQAtBo0IfKCJZCCOGlzaCv7LpRFKWxSxFCiEanyaAP8TPh9iiU2l2NXYoQQjQ6nwX9M888Q+/evRk5cqSvVlGrUD8Z2EwIIar4LOhvuOEG5syZ46uHP6NgGdhMCCG8fBb0PXr0ICQkxFcPf0bNQ6wAZBRUNMr6hRCiKTE2dgEns9vtpKWl1WtZm83mXdblVC8juHbHAVobCi5YffV1cm1NjdRWP1Jb/Uht9XO+tTWpoLdYLCQmJtZr2bS0tGrLtliURZHiV+/Hu5BOra0pkdrqR2qrH6mtfs5UW112AJo86wagfUwQ+46XNnYZQgjR6LQR9AsfIfDo6mqT2kcFsi+nFI9HzqUXQlzafBb0jz76KDfffDMHDx6kf//+/O9///PVquDAckIOLqo2KSEmEJvTQ2ahHJAVQlzafNZH/+abb/rqoU/XrDPWwxuqTUqIDgRgX04pseH+DVeLEEI0MdroumneGXNZJlQUeie1rwz6vTkljVSUEEI0DdoI+mZd1N9Zf3gnhfqbiQy0sC9HDsgKIS5t2gj65p3V31nbqk1OiA5kV5a06IUQlzZtBH1gNE5rJBzbWm1yj7bhbM8skrHphRCXNG0EPWALuwyOVW/R90+IxKPAmv25Jybu+xnK80/87bLDrupn7AghhJZoJujtYR0gdzc4T5xO2SU2lECLkVX7KoO+LBc+HwcbThpsbfOn8OWtkL2jgSsWQoiGoZmgt4W2B8UDuXu900wGPb3bRbBq73F1QvZ2QIH8gycWPLhS/Z27p+GKFUKIBqSZoHcExak3TgnsqxMiSc+v4HBe2YlWe+Fh9bfHA4cqv1Gbt6+BKhVCiIalnaAPjAV0pwX2NR2iAJi3OfOkoD+i/s7ZCRWV/fV5BxqoUiGEaFiaCXrFaIXQuNNa9K0jAhiaFMPHqw/iPqaeZ68UZzL5ozW4DlR224THS4teCKFZmgl6ACITauxrnzq4A+V2O0rOLvCPRKd42LN3F7l//AxhbXC1vlqCXgihWRoL+g6Qt1/tez9JYvNg7ujgxKg4yG5+LQBxuhwCs9ezz78rr25wQUU+rtI8bE53IxQuhBC+o62gj2gPznIozjwxTVHg8BoeapMBwAt72gDw1+Z7CPSU8P7hluSaYwF45KU32f3PHmR8cs9pX74iJw0cZQ3xLIQQ4oLSVtBHdlB/V3XfuOww/174+HrCVv4dt87IL86OeNDTq/QXAHZYuvDcHaMAeMXvczrqDhN6cCHuz24Et0t9HFsRfHAtLHykgZ+QEEKcP20G/e4lMP8+eKcL/PE/6P8E9HsUrn2GcVddhiuwBXp7IWWBrXlj8vWEtewAOj3+rkJKk+/lGfcDGMqPo1Sderl/GbhssO1ryN6pTju4Cv7V88R5+EII0UQ1qWvGnrfAaLAEw4YPwRIC7QdC55vhsmEAGIAXAD5uA6UZBFw2gI4tgtVlQ+OgLJewwU/QIyyH0l/eI3/V58S1uxb2/qQ+HgrOH5/n46gnmZg6mQBbNnxxE9z6FcRf0yhPWQghzkZbQa/TQY97wFYIA/4GAZE1zxcaB4eBNlefmHbNU2AwQ0AEt/YNY9XqXlx5aAml5eUE7P2RI+G92epsxZ/2z+H2fcsw4uYfQc/zrPVrjHNvgTsWQKtuDfEshRDinGgr6AEGP3/2eSLiAR206XdiWtdbvTeNBj1x/ScR8vMKfnzrVq5z5vB2QVvWBw4ip0VrbjatYH9IT/67OZHS+P/jNdcT8MU4dJ3GgzUYSnPUs38cpShtrqZZTiZsKoZWPaFZJ3UHFBAJepO6U7IVgdEKzbuCxwml2RDUAozmC711hBCXIO0FfV30uBda94WgZrXO0u6qMeSmzeW6zF/xKDquHDiONwd1Q6cbAkwhCXgi8gAvLk6jpPmz3Fv2GkkbPsOqVKDzD4fwdriM/rD2Pfz1FohoDfteAs5wsXJzkHrWkOIGdCjmAJwYMJmt6PzCILiler+jFDxucDvVHYPTBq4K9bRSvzDwD1d/G63qzsJgAb0R7MVQcEh93jFXQEgrAos94JenTndWqPOVVw4CFxKn1mIvVdepN4LJD8wBYPJXf8z+4HGpI4JW5ENFAZQXqLcdZZU1WNTljBa1C8warM5XmqOuy2gFS5D6E9QCgmLA7STkyEEoX68+l4BI9f6SbLAXqTtJgxkMJ/+uum0GnQHc9sr1ZKvTAmPUHa3bqdanN6rPzVkGoa3V9SiK+hrpDKCvwyGsqgP2BqN621ECjnL1scz+6mui06k/QjSSSzPo/UKhdZ8zz2M0E3nvt5Sm/UpxQTa39el+2ix392vLyr3H2Zpt5X+d/81d24+ieDx8cUsfusSG8uy8bXy7dz86g4nlkwbTzFSuBmpZLpQdVwPSLxSsoVCeB4dWgV+42rVUfJRNe46wPT2Xq2OCaBdgh+JMPKYAPIEtMZpMlWFnAqOVY+VwvNRBh2A3VmdhZeDmgsuhBp7HjcdoJc0WQRtHBgEHloPHRSzA6gu8fc2B6vMw+6tnPrls6k/VDqmKXzj4R4DbAfYSdUfkcXnvbnGBy1LpOOPO1jubQd1hup3qTtX7XOxg9qeDywnf2NTaQX0tPKdc98BgUbc9usodo99Jv6tuW9V5FY/64/GA3gABUeqOt+y4um7Fo+44LcHqDqoiX925umzqjtccqO4IzYG0KiuDzVa1NrdL/e1xqrc9TvUxAiLVbW8JUtdXNepr1WO5nVCWoz53nV7dUdmK1fdUeb76vvOPUJ+33qD+HdEegluo7zmXTX08v1B1p+cXBn7hmIuOwDGn+viKR33sshz1lOiSLHWbBMaox9scpVCYDkXplf8ragPGiZ4fNu6he0ILmgdbKc7aj7+nFKPHXlmrgQqXgp/eVfmeq/wxWiHqcvWx9Ub107THrdavNxKZVwDZzdQdvNupPt+ASHWblBxT6zVaT/qxnLhtMKrbxe2obLQEn2g06fTqNjUHqq+7waw2wJwV6uO6XWoDJPry83971/Z2VhSlDu/6hpGWlkZiYmKDL3s+FEVBV9layy62ceOsNZQ73FydEElK6lFuSG7J91szGdm5BVcnRLE7u4TsYhvxkYEMvSKGy5sFs+SPY/yclsPUwQneC5kXlDno98qvlDncRAdZWPb4tfibDdz1nw1syyhi7r1XkVtqZ97mDPZkl7A9sxiAYKuRl2/szPBOzU+r84HPN/PDjizaRgbw49R+mCryOLjtN1pGBnPHtznY9f68OyGJWz7fi83h4qd72hPib8VtCsBoDVJb984KNXCc5ZSWlvB/89bjVPQ8N74vAaHRKNYw/Pz9+WTNIb7dksnMW5KJDraQnl9O++ggMo4X8P7SLdhMwUQGBxJkNZKaXoheB88OTyTWXKKGm8HCvkPptE9IwFVWgK48F4OjhF1l/uS6/enXNqQyyCpDo+q2p/K2x82RIheFij+dLuuAzuNSxzjK2oZi8sdpjUDncfHCT0c4VgZ3ddTRp5WlsuWtUz85VeSr/5R6Y+WnE4v64ygnv7CI8JhWagiAOr/RT/0nN/lVfropVINL8aj3Oysqf8pOul2urk9v8IYUbocafib/E4Gv06nrshXjdjs5VG4lKroZwUHB4CijpLiQvPw84gI9OGwVmP2D0Hs/4RhPfALSG9QdalVjw1GubjOT+r5THGXoqnZOVd2LVTshSyD4V+4gPE61ceJxqTsnV4XaiFGqf1nxnP6XdHp0NSxvMwSg6M34uYpqfPxixR+HJYzIkGBQPJTZHeQUlRMdFkJAQID6uhgt6o7j+B71EyFUbg+T+hwUd7VGBujUYHaUnDSvsXKH6IPIjOsNd/9Q691nyre6ZJ8E/QV2MLeMez/dSLndRXJcGG9O6MITn6/h+11qEJuNeqICLRwtqsDfZOC9Sd34y+ebKHO4sZr0tA4PwGo2EGA2sPZAHi+N7cTT8//gzj5tuCo+nPs/34zZqMeo11HucBMeYCYhOpDrkprRq204z363nR1Hi3hvYjfW7s/DbNTz5NDLmPnrPt76eQ9Dk2JYuiObF0YncVvvNqSlpfHLMSOv/7gHg16HyaBT/289Hm67qjW5ZQ5W7TnOw4M7kF9mZ8fRYsYmt6RtZAAvL9nFhkP5mAx6wvzNFNucKArc0jOWOasPoigQE2zBqNeTWVjBU8MuZ/Efx9ibU0JEgIWcEhtOt0KrMD8KK68CNn10EmOTW7IlvZCczCO0i4/nnk83EhFg5v1J3bj+nVWU2l2sfWYQYf4mnG4Fs/H0LpZjRRUMe3sVRRVOkuNCefOmrrSNVEP55SW7+Gj1Qa5sHcrvB/KJDLQQFWRhycNXc7zEjtujEBloxmiovevmhzVbWZqucFvv1lwZFwbA8t05bD5SyH394wmwVP+w7PEo6PW1d9/8kpbNKz/s4r7+7bixW6ta56twuLnj4/WsP5hPy1A/Fj7UD3+LgRHvrmZfTil/G56IuzSPt9fm8s7NyQxNqrl7stzh4j9rDtG5ZSj9EtSTFlLTC/nrfzfz7oQruDI2HCd6TCdtg51Hi/l83WGSY0O5rmMzAq1GHvs6lX3HS7k6IYq/9G1BkFJ6opWLou7sKgoqf/LJSD9Cq7i2ld1rOhSPiwdT0tmQ788tA67k0QFt1K620hw8Rj/+b1UJn2wpxKjXsXRqP9oFeXj+u618sbWQEJObSb3ieGd1Nka9jmWPX0tsuD/3f7aJH3Zk0blVCCkP9uVwXjkvLNxJqd3FZ5N7YdZ51J2pya9al1razp0kXn6ZGvh6o7pTdFTuoP3D1XkVhXJbBRacGNyVn1xcdnA7UPxCceosmF0l6qcBj0vdWSqKupOxl6o7xKqGicGidqMaLeonoapGQw0k6C/Asr62adsODjlDSGoZTEJ0EAa9jszCCkb/azW5pQ78zQb+c1dPvt2SQX6Zg9xSB5uPFDC6SwvevjmZad/+wX/XHcGg19E+KpB/3ZrMo19vpX+HSB4amIDVZPCuq6jCyY2z1lS7KHqPNmFsOFTADckteeOmLtzy4e/8kVHE0CuaYXKW8f2uEq7pEEXf9hE8l7KD6aOT2J5ZxNcb1W8TJzYPJu1YMXodxARbOVZk8z72G+O70CLUj6lfbaFX2wiOFlaw8XABnVqG8MKYK7jvs400C/Ej3N/Est3qdQE+vL07QzrGoCgKZQ43gRYj6fnlPPp1KhsOFdA85MQ6DHodQVYjheVOIgLMFFY4cXsUnhx2GdlFNuZvyeSfY67AYjSwcNtRNh8uoGWYH063wp7sEh4elMD7K/ZjNuqZe+9VZBfbuXXO78RHBrD/eBmDLo/m6oRI/rFgJ5OuiuPz39WRTdtHBzL33qsw6HX8uCOLLUcKcXo8RAVa6BobyrR5WymwqcNlTBmUwEMD23PNq8s4WmQjLtyf9yd1o2OLYJbtzuGDFQf4I7OI18d3ZtgV6ietlXuOs/1oEdFBVlJSM1m1NxejXkeAxciyx68lPMBMen453289SonNRWLzIK7pEMX9n29i3cF8/jqgPbNXHCCxRTBtI/z5LvUorSP8Kapw4nK5KXV4CLQYeWRIB9YfzCM6yEqnliFc2TqUDYcK+H/L9pFRUIFOBw8PSuChgQncNHstmw4XkBwXyjPXJ3Lnx+u5uUccz45IpKDcwaiZqzla+bpEB1no1jqMJduz6NQyhB1HixiUGMP//SmJl5fsokebMCb0iMPtUbCa9Oh0OoptTvbv3UNypyTv+2dbRiF/+tdvxIb7kVFQwRvju3DDleqO7tUfdvHe8v3c2acN32zK4Kr4CGbf1o2eL/5MWICZfTml6HTQsXkwe7JLmNAjlieGXk6PF3+meYiVw3nlDE6MZuWeXAx6HRVON48O6cCUQQnkFNv4LjWTq+Ij6NwqFDg9Q7amF3JZs6Bq/1/ZxTZGzVxNn3YRvH1zsnd6QZmDez7dSEG5Q935ms/eK55dbOOv/93Mff3bMbhjzBnnlaC/AMv6Wm21rT+Yz93/2cDfRiRyS8+4avcVljvwNxsxG/UoisLc9em8t3wfb03oSo824WdcX3p+Of9v2T4m9mrNwm1Hmb3yAEM6xjBr4pUYDXrS88t5beluVu09TlGFk1Zh/nxxTy9iw/3JKbERHWQlq8jGpH+vY1KvOO7o04bNRwqIDrLSMtSPNfvzKHO4uCwmiDaR1VshLreHRX8co2/7SCIDLbg9Cga9Dqfbw4zFacSG+XN3v7Y11u32KMxeuZ8Vu48zJrkl6ZlHKdEF8sC17fhkzSFmrzzAA9e2Y1tGIVvTiyi1u4gIMJNXpvaTRwVZ6Nk2nK3phWQUVPDKjZ2Y0COO3Vkl3PLh7+SXOTAZdLQK82fRlH5kF9uJCrJgc7rpNeMX3B6FYUnN6NE2nNeX7qZZiJXcUjslNhdh/iYCLEZySuw4XB6CLXo+u6c3H/12kJTUo9zRuzWfrD3Mw4MS+HpjOk63h/HdY5m1fD8tQ/0I8TOx81gx47u1Ishq4qPfTlz8JjrIwt392tI/IYo//Ws113SIIirIwvzNmTjcHox6HS6PgsWox6MovDquM2OTW5GSmskLC3eSW+rgT11a8Of+8YycuRqLQcfHd/fkof9uIa/MQYsQK8U2F6X2E10TlzcLYtrwRFJSjzJvcwaXNwtiV1YJ/dpHsnpfLlaTHpNeT4ndRbfWYZTYnBzKK+eb+3vjdHt48ptt7D9exn3943lmeCL/Xn2QFxbuxM9kwOH24PYo3rqvig/nxitb8c9FaSgeN/cPSGBU5xbEhvvzj+938N91R1j11AD++t/NbDhUwLCkZsRF+PPBygPc0jOWGWM78d7y/by2dDc3dW/F1xszmHlLMm/+tIeDuWW8P6kbK/YcZ96mDEZ0bs63WzL55v7ePD3/Dw7mljHuylY8dl0Hpi/cyY87sukSG8KWI4W4PAohfibmPdCHcoeL7bv306fL5bSJDOCbTRk8/r+tJEQH8sTQyyi2uWgWbOVfy/by+wF1aPNFU/qx6XABq/bmknasmJxiOw63h7v7tuXvozqyPbOId37Zy76cUhwuD8lxofSKj6BvuwjiowJ57rvtfPb7YcxGPf+5qwd92tVyOvgZMuRs91WRoG8AZ6rN6fZU+3h8oSmKwsbDBXRuFYLFaDjt/otlu7ncHlbvy6VPu0hW7DnOvZ9uJKlFMP+7vzffpx4lLMDMoMujMRr0uNweDuaWkRAT5H2sw3llLNh6lMzCCm67qs2JL8pVmrE4DYfLw7MjEjEa9KysXEfvdhE8ft1lJLUIRqfTUWZ3sWrvcQylOQy5qguldheD31hBVrGN9tGB/Di1Pwdyyxj//hoKyp0M79SMtyZ0RVHgn4t28u3mTMocbsZ1a8Uz11/OsSIbHWKCvN1PMxan8cHKA/ibDYzs3JxHhnQgJsjKgm1H+WpDOg8NTKB3uwhv3R6PwoHcMlqF+WE1Gfh07SE8JbnceV13DuWWUVDuoGtsKIoC+46XsvlwAYnNg+ncKgSdToeiKPx3/RH+8f0O2kQEsHBKP7XlXmjjuwf7sHz3cb7emI4OHQ8Nas/Izuoh8nKHi/UH8+mfEIVerz7OY19vJTWjkPcndSOzsIK1+/MwGXT857dDlDncdGwejL/eycZM9cBvu6gAckrs9GsfyaxJ3XC5Pcz8dR8f/XaQEpuLvu0j+M9dPTEZ9Nicbh6au4WfdmZjMujY9NwQFm49xvzNGXz556sotrm46z8b2JpeSFy4PyueuJbcUgcOt4eWoX4A5JbauWn2WoKsJvq2i6BfQiRT5m6hoFz9lFhlwGVR/H4gn/bRgRwrspFbaq/2Xnl+VEfe+mkPFpOB4yV22kT4Ex5g5qlhl7Nw2zE+X3eYdlGB7MspJczfRN/2kSjApkMFZBWrn4ju6N2a/64/wrArmrM7q5gAi5Fv/9K3Tv8L53JfFQn6BiC11U9ttbk9Cp+uPcSQjjG0CvP32frtLneNO8dTa/thexb3f76JN2860e2QdqyYtfvzuKNPGwwn9c07XB6OFVUQF+7vPYh/MrdHIT2/nNhw/2rLnYv6vKaHcsvwNxuIDrZyvMROhcNNXMS5bduqKDn1eaXnl7N8dw7ju8dycN8ezJGxLNuVw4o9x0k9Usj7t3Wjb/vIao+TXWwnOshS7biGx6Mwe+UBPIrCgwPan7Z+m9PNa0t3kxwX6t0hnc32zCLeX7Gf/h2iUEqOc1wJ4r3l+/EzGVj88NVYjHp2HiumWbCVzMIKyh1uhiY14/8t28drS3dzS89YXhzTyVtnqd3F1C+3oNfp6NQyhDv6tiHYavI+ryOVn7a/3piB2aBn2RPXEuZvoqjCSfMQv1rrlKC/AMv6mtRWPxdTbdnFNmKCrY1Y0QkX03ZrSqpqyy1VD8if6fV0exQ2HsqnR5vwMx5kr4miKHy1IR2jQc+4Mxx4r6m2c72vyqV5Hr0QF1hTCXlx/iIDLWedx6DX0Ss+4qzz1USn03HzKcfkfE1bo1cKIYQ4jU+DfuXKlQwdOpQhQ4bwwQcf+HJVQgghauGzoHe73UyfPp05c+awaNEiFi5cyL59cl1WIYRoaD4L+m3bttG6dWtiY2Mxm82MGDGCX375xVerE0IIUQufHYzNzs6mWbMTX7+OiYlh27ZtZ1zGbreTlpZWr/XZbLZ6L+trUlv9SG31I7XVj5Zra1Jn3VgsFjm9soFJbfUjtdWP1FY/Zzu98mx81nUTExNDVlaW9+/s7GxiYs48noMQQogLz2dB36lTJw4dOkR6ejoOh4NFixYxcOBAX61OCCFELXz6zdgVK1YwY8YM3G43N954Iw888MAZ509NTcViOfuXFYQQQqjsdjtdu3Y94zxNaggEIYQQF558M1YIITROgl4IITROgl4IITROgl4IITROgl4IITROgl4IITSuSQ2BUB8rV67kxRdfxOPxMH78eP785z83Wi3Hjh3jySefJC8vD51Ox0033cQdd9zBzJkz+frrrwkPVy/q/eijj3LNNdc0eH0DBw4kICAAvV6PwWBg/vz5FBYW8sgjj5CZmUnLli15++23CQkJadC6Dhw4wCOPPOL9Oz09nSlTplBSUtJo2+2ZZ55h+fLlREREsHDhQoBat5WiKLz44ousWLECq9XKyy+/TFJSUoPV9corr7Bs2TJMJhNxcXG89NJLBAcHk5GRwfDhw2nbVr0Ye5cuXZg+fbpP6jpTfWd6/8+ePZtvvvkGvV7Ps88+y9VXX92gtU2dOpWDB9ULtZeUlBAUFERKSkqDbrvacuOCvt+Ui5jL5VIGDRqkHDlyRLHb7cqoUaOUvXv3Nlo92dnZyvbt2xVFUZSSkhLluuuuU/bu3au8++67ypw5cxqtrioDBgxQ8vLyqk175ZVXlNmzZyuKoiizZ89WXn311cYozcvlcil9+vRRMjIyGnW7rV+/Xtm+fbsyYsQI77TattXy5cuVyZMnKx6PR9myZYsybty4Bq1r1apVitPpVBRFUV599VVvXenp6dXmawg11Vfb67h3715l1KhRit1uV44cOaIMGjRIcblcDVrbyV566SVl5syZiqI07LarLTcu5Pvtou66aWpDIUdHR3v3rIGBgcTHx5Odnd1o9dTFL7/8wpgxYwAYM2YMP//8c6PWs3btWmJjY2nZsmWj1tGjR4/TPtnUtq2qput0Orp27UpxcTE5OTkNVle/fv0wGtUP5127dq02xlRDq6m+2vzyyy+MGDECs9lMbGwsrVu3PusIt76qTVEUlixZwsiRI322/trUlhsX8v12UQd9TUMhN5VgzcjIIC0tjS5dugDwxRdfMGrUKJ555hmKiooara7Jkydzww038NVXXwGQl5dHdHQ0AFFRUeTl5TVabQCLFi2q9s/WVLYb1L6tTn0fNmvWrNHeh/PmzaN///7evzMyMhgzZgyTJk1i48aNjVIT1Pw6NqX/340bNxIREUGbNm280xpj252cGxfy/XZRB31TVVZWxpQpU5g2bRqBgYHccsst/PTTT6SkpBAdHc3LL7/cKHXNnTuXb7/9lg8//JAvvviCDRs2VLtfp9Oh053bFe0vJIfDwa+//sqwYcMAmsx2q0ljb6uazJo1C4PBwJ/+9CdAbSkuW7aM7777jqeffprHHnuM0tLSBq+rKb+OVRYuXFitgdEY2+7U3DjZ+b7fLuqgb4pDITudTqZMmcKoUaO47rrrAIiMjMRgMKDX6xk/fjx//PFHo9RWtW0iIiIYMmQI27ZtIyIiwvuxLycnx3vArDGsXLmSpKQkIiMjgaaz3arUtq1OfR9mZWU1+Ptw/vz5LF++nNdff90bCGazmbCwMACuuOIK4uLivAceG1Jtr2NT+f91uVz89NNPDB8+3DutobddTblxId9vF3XQN7WhkBVF4W9/+xvx8fHcdddd3ukn95/9/PPPJCQkNHht5eXl3hZJeXk5v/32GwkJCQwcOJDvvvsOgO+++45BgwY1eG1VFi1axIgRI7x/N4XtdrLatlXVdEVRSE1NJSgoyPuRuyGsXLmSOXPmMGvWLPz8/LzT8/PzcbvdgHom06FDh4iNjW2wuqrU9joOHDiQRYsW4XA4vPV17ty5wetbs2YN8fHx1bpDGnLb1ZYbF/L9dtGPXnmuQyH70saNG5k4cSIdOnRAr1f3oY8++igLFy5k165dALRs2ZLp06c3aBCA+mZ98MEHAfXC7SNHjuSBBx6goKCAqVOncuzYMVq0aMHbb79NaGhog9YG6s5nwIAB/PzzzwQFBQHwxBNPNNp2e/TRR1m/fj0FBQVERETw0EMPMXjw4Bq3laIoTJ8+nVWrVuHn58eMGTPo1KlTg9X1wQcf4HA4vK9b1amAS5cu5d1338VoNKLX63nooYd83hCqqb7169fX+jrOmjWLefPmYTAYmDZtmk9Pn62ptvHjx/P000/TpUsXbrnlFu+8DbntasuNzp07X7D320Uf9EIIIc7sou66EUIIcXYS9EIIoXES9EIIoXES9EIIoXES9EIIoXES9EJcAOvWreO+++5r7DKEqJEEvRBCaNxFPx69EOciJSWFzz77DKfTSZcuXXj++efp3r0748eP57fffiMyMpK33nqL8PBw0tLSeP7556moqCAuLo4ZM2YQEhLC4cOHef7558nPz8dgMPDOO+8A6pe+pkyZwp49e0hKSqo2HIEQjUla9OKSsX//fpYsWcLcuXNJSUlBr9ezYMECysvLueKKK1i0aBE9evTgX//6FwBPPvkkjz/+OAsWLKBDhw7e6Y8//jgTJ07k+++/58svvyQqKgqAnTt3Mm3aNBYvXkxGRgabNm1qtOcqxMkk6MUlY+3atWzfvp1x48YxevRo1q5dS3p6Onq93jug1ejRo9m0aRMlJSWUlJTQs2dPAMaOHcvGjRspLS0lOzubIUOGAGCxWLzjy3Tu3JlmzZqh1+u5/PLLyczMbJwnKsQppOtGXDIURWHs2LE89thj1aa/99571f6ub3eL2Wz23jYYDN5BsYRobNKiF5eM3r17s3TpUu8FHAoLC8nMzMTj8bB06VIAFixYQLdu3QgKCiI4ONh7wYmUlBR69OhBYGAgzZo1817tx+FwUFFR0ThPSIg6kha9uGS0b9+eqVOncvfdd+PxeDCZTPz973/H39+fbdu2MWvWLMLDw3n77bcB9aLbVQdjY2NjeemllwB49dVX+fvf/84777yDyWTyHowVoqmS0SvFJS85OZktW7Y0dhlC+Ix03QghhMZJi14IITROWvRCCKFxEvRCCKFxEvRCCKFxEvRCCKFxEvRCCKFx/x+leejD8GSCGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "781b20d5-3d55-4e8c-b375-4b2e256ccac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59903f5a-fd84-4336-ab3c-0a70763d874a",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418bbba0-35cc-430b-aad1-3d20cfefdc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/home/helemanc/Desktop/Binary_Model/models/binary_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d82f4-b6fd-4a83-aa1c-58400daeff17",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df522ef-5a06-402e-a9f0-edf154f5e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = tf.keras.models.load_model(\"/home/helemanc/Desktop/Binary_Model/models/binary_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9e13c2d-2373-439d-8a35-54f4d1f72ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.353274941444397, 0.8333333134651184]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac0176b3-85fd-49a7-927d-6d714d770b61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58        12\n",
      "           1       0.90      0.90      0.90        48\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.74      0.74      0.74        60\n",
      "weighted avg       0.83      0.83      0.83        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "pred = [1 * (x[0]>=0.50) for x in predictions] #0.5 o 0.52? \n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e98024f-c131-4c6b-abf2-37557838f8ba",
   "metadata": {},
   "source": [
    "# Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68faab-5583-4708-87f6-4825b62b1c64",
   "metadata": {},
   "source": [
    "## Initializer, Batch Size, Learning Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "18d00ff2-5f1f-4b42-b3f6-7623081a4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model input dim = 248 \n",
    "'''\n",
    "def create_model( init_mode='glorot_uniform', lr = 0.001):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv1D(256, 5,padding='same',\n",
    "                     input_shape=(248,12), kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "\n",
    "    model.add(layers.Conv1D(128, 5,padding='same', kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, kernel_initializer=init_mode))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr = lr) , \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "'''\n",
    "def create_model( init_mode='glorot_uniform', lr = 0.001):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv1D(256, 5,padding='same',\n",
    "                     input_shape=(76,12), kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "\n",
    "    model.add(layers.Conv1D(128, 5,padding='same', kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, kernel_initializer=init_mode))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr = lr) , \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "159cb303-d526-4919-8863-4774d0a89f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_path = \"/home/helemanc/Desktop/Binary_Model/weights/binary_model_l1l2.hdf5\"\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                                                 factor=0.5, patience=4, \n",
    "                                                 verbose=1, mode='max', \n",
    "                                                 min_lr=0.000001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=45, \n",
    "                                              verbose=1, restore_best_weights = True)\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=weight_path, \n",
    "                                                      save_weights_only=True, \n",
    "                                                      monitor='val_accuracy', \n",
    "                                                      mode='max', \n",
    "                                                      save_best_only=True)\n",
    "# classweight \n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "16c58367-9ffe-4ae6-8993-7651d387eb30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 10:53:18.892845: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:53:18.893142: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 10:53:18.930639: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:53:18.930780: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 10:53:18.939842: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:53:18.939985: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 10:53:18.947185: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:53:18.947344: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 10:53:18.990410: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:53:18.990552: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 10:53:18.997093: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:53:18.997234: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 10:53:19.087708: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:53:19.087833: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 10:53:19.111174: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:53:19.111540: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-31 10:53:20.759436: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:20.760378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 10:53:20.767667: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:20.768595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 10:53:20.773873: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:20.774702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 10:53:20.781117: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:20.781901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 10:53:20.798354: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:20.799130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 10:53:20.805176: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:20.805924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 10:53:20.913313: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:20.914060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 10:53:20.919180: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:20.919835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 10:53:21.162782: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 10:53:21.162978: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-31 10:53:21.163325: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 10:53:21.163644: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:21.188468: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 10:53:21.188500: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-31 10:53:21.188540: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 10:53:21.188555: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 10:53:21.188560: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-31 10:53:21.188568: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 10:53:21.188639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-31 10:53:21.188639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-31 10:53:21.188941: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 10:53:21.188951: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 10:53:21.188973: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 10:53:21.188971: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 10:53:21.189315: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:21.189327: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:21.189342: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:21.189341: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:21.204714: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 10:53:21.204751: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-31 10:53:21.204977: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 10:53:21.205477: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:21.247868: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 10:53:21.248138: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-31 10:53:21.248166: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-31 10:53:21.248413: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 10:53:21.248417: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-31 10:53:21.248761: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:21.248970: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 10:53:21.249439: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 10:53:21.327128: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 10:53:21.328100: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-31 10:53:21.342816: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 10:53:21.343718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-31 10:53:21.349510: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 10:53:21.350274: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-31 10:53:21.352272: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 10:53:21.353016: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-31 10:53:21.370800: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 10:53:21.371803: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-31 10:53:21.389166: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 10:53:21.389976: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-31 10:53:21.430891: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 10:53:21.431606: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-31 10:53:21.433372: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 10:53:21.433948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 - 1s - loss: 0.8774 - accuracy: 0.4601\n",
      "Epoch 1/50\n",
      "14/14 - 1s - loss: 0.8450 - accuracy: 0.5421\n",
      "Epoch 1/50\n",
      "54/54 - 1s - loss: 0.7500 - accuracy: 0.6103\n",
      "Epoch 1/50\n",
      "14/14 - 1s - loss: 0.9027 - accuracy: 0.4601\n",
      "Epoch 1/50\n",
      "14/14 - 2s - loss: 0.9723 - accuracy: 0.5305\n",
      "Epoch 1/50\n",
      "14/14 - 2s - loss: 0.6740 - accuracy: 0.6056\n",
      "Epoch 1/50\n",
      "54/54 - 2s - loss: 0.7227 - accuracy: 0.6682\n",
      "Epoch 1/50\n",
      "54/54 - 2s - loss: 0.7389 - accuracy: 0.5305\n",
      "Epoch 2/50\n",
      "14/14 - 1s - loss: 0.8231 - accuracy: 0.5258\n",
      "Epoch 2/50\n",
      "14/14 - 0s - loss: 0.7788 - accuracy: 0.5794\n",
      "Epoch 2/50\n",
      "14/14 - 1s - loss: 0.6477 - accuracy: 0.5540\n",
      "Epoch 2/50\n",
      "14/14 - 1s - loss: 0.8147 - accuracy: 0.5634\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 0.6866 - accuracy: 0.5446\n",
      "Epoch 2/50\n",
      "14/14 - 1s - loss: 0.7282 - accuracy: 0.6056\n",
      "Epoch 3/50\n",
      "14/14 - 1s - loss: 0.8620 - accuracy: 0.6056\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 0.6924 - accuracy: 0.4860\n",
      "Epoch 3/50\n",
      "14/14 - 1s - loss: 0.8360 - accuracy: 0.4673\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 0.7102 - accuracy: 0.4319\n",
      "Epoch 3/50\n",
      "14/14 - 0s - loss: 0.6320 - accuracy: 0.7465\n",
      "Epoch 3/50\n",
      "14/14 - 1s - loss: 0.7717 - accuracy: 0.4836\n",
      "Epoch 3/50\n",
      "14/14 - 1s - loss: 0.5226 - accuracy: 0.7042\n",
      "Epoch 4/50\n",
      "14/14 - 1s - loss: 0.8420 - accuracy: 0.5775\n",
      "Epoch 4/50\n",
      "14/14 - 0s - loss: 0.8062 - accuracy: 0.4813\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6651 - accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "14/14 - 1s - loss: 0.5494 - accuracy: 0.6854\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6558 - accuracy: 0.6589\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6588 - accuracy: 0.5211\n",
      "Epoch 4/50\n",
      "14/14 - 1s - loss: 0.7886 - accuracy: 0.5587\n",
      "Epoch 4/50\n",
      "14/14 - 0s - loss: 0.5581 - accuracy: 0.7183\n",
      "Epoch 5/50\n",
      "14/14 - 0s - loss: 0.7590 - accuracy: 0.6075\n",
      "Epoch 5/50\n",
      "14/14 - 1s - loss: 0.8918 - accuracy: 0.5117\n",
      "Epoch 5/50\n",
      "14/14 - 1s - loss: 0.5079 - accuracy: 0.6948\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.6632 - accuracy: 0.5775\n",
      "Epoch 5/50\n",
      "14/14 - 1s - loss: 0.9270 - accuracy: 0.4883\n",
      "Epoch 6/50\n",
      "14/14 - 0s - loss: 0.7653 - accuracy: 0.5841\n",
      "Epoch 5/50\n",
      "14/14 - 1s - loss: 0.6423 - accuracy: 0.6948\n",
      "Epoch 6/50\n",
      "14/14 - 0s - loss: 0.8269 - accuracy: 0.5869\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.6480 - accuracy: 0.5841\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.6299 - accuracy: 0.7324\n",
      "Epoch 7/50\n",
      "14/14 - 0s - loss: 0.6489 - accuracy: 0.6215\n",
      "Epoch 6/50\n",
      "14/14 - 1s - loss: 0.5297 - accuracy: 0.7277\n",
      "Epoch 6/50\n",
      "14/14 - 0s - loss: 0.7277 - accuracy: 0.5540\n",
      "Epoch 6/50\n",
      "14/14 - 1s - loss: 0.4416 - accuracy: 0.7840\n",
      "Epoch 7/50\n",
      "14/14 - 1s - loss: 0.8311 - accuracy: 0.5822\n",
      "Epoch 8/50\n",
      "14/14 - 0s - loss: 0.7117 - accuracy: 0.5935\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.6667 - accuracy: 0.5822\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.6360 - accuracy: 0.6291\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.6473 - accuracy: 0.6636\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 7/50\n",
      "14/14 - 0s - loss: 0.7859 - accuracy: 0.5446\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 8/50\n",
      "14/14 - 0s - loss: 0.7569 - accuracy: 0.5869\n",
      "Epoch 7/50\n",
      "14/14 - 0s - loss: 0.4439 - accuracy: 0.8451\n",
      "Epoch 7/50\n",
      "14/14 - 1s - loss: 0.5276 - accuracy: 0.7559\n",
      "Epoch 9/50\n",
      "14/14 - 1s - loss: 0.7113 - accuracy: 0.5888\n",
      "Epoch 9/50\n",
      "14/14 - 0s - loss: 0.7288 - accuracy: 0.6056\n",
      "Epoch 8/50\n",
      "14/14 - 1s - loss: 0.6880 - accuracy: 0.6197\n",
      "Epoch 8/50\n",
      "14/14 - 1s - loss: 0.4067 - accuracy: 0.8075\n",
      "Epoch 8/50\n",
      "14/14 - 1s - loss: 0.4038 - accuracy: 0.7793\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.6011 - accuracy: 0.6667\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.6414 - accuracy: 0.6028\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.6666 - accuracy: 0.6103\n",
      "Epoch 10/50\n",
      "14/14 - 1s - loss: 0.6809 - accuracy: 0.6402\n",
      "Epoch 10/50\n",
      "14/14 - 0s - loss: 0.7579 - accuracy: 0.5681\n",
      "Epoch 9/50\n",
      "14/14 - 1s - loss: 0.8141 - accuracy: 0.5493\n",
      "Epoch 9/50\n",
      "14/14 - 1s - loss: 0.3590 - accuracy: 0.8310\n",
      "Epoch 9/50\n",
      "14/14 - 1s - loss: 0.3587 - accuracy: 0.8216\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.6231 - accuracy: 0.6542\n",
      "Epoch 11/50\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.6197\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.6499 - accuracy: 0.5634\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.6371 - accuracy: 0.6385\n",
      "Epoch 11/50\n",
      "14/14 - 0s - loss: 0.7276 - accuracy: 0.6121\n",
      "Epoch 10/50\n",
      "14/14 - 0s - loss: 0.3141 - accuracy: 0.8263\n",
      "Epoch 10/50\n",
      "14/14 - 1s - loss: 0.7414 - accuracy: 0.5962\n",
      "Epoch 10/50\n",
      "14/14 - 1s - loss: 0.3681 - accuracy: 0.8357\n",
      "Epoch 12/50\n",
      "14/14 - 1s - loss: 0.7108 - accuracy: 0.6385\n",
      "Epoch 12/50\n",
      "14/14 - 1s - loss: 0.7539 - accuracy: 0.5467\n",
      "Epoch 11/50\n",
      "14/14 - 1s - loss: 0.3793 - accuracy: 0.7981\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.6025 - accuracy: 0.6761\n",
      "Epoch 11/50\n",
      "14/14 - 1s - loss: 0.6598 - accuracy: 0.6620\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.5994 - accuracy: 0.6682\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.6311 - accuracy: 0.7042\n",
      "Epoch 11/50\n",
      "14/14 - 1s - loss: 0.3701 - accuracy: 0.8357\n",
      "Epoch 13/50\n",
      "14/14 - 0s - loss: 0.6986 - accuracy: 0.5841\n",
      "Epoch 13/50\n",
      "14/14 - 1s - loss: 0.7372 - accuracy: 0.6526\n",
      "Epoch 12/50\n",
      "14/14 - 0s - loss: 0.7778 - accuracy: 0.5728\n",
      "Epoch 12/50\n",
      "14/14 - 0s - loss: 0.3220 - accuracy: 0.8310\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/50\n",
      "14/14 - 1s - loss: 0.2732 - accuracy: 0.8732\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.5766 - accuracy: 0.7804\n",
      "Epoch 14/50\n",
      "14/14 - 0s - loss: 0.6451 - accuracy: 0.6776\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.5832 - accuracy: 0.6620\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.5877 - accuracy: 0.6714\n",
      "Epoch 13/50\n",
      "14/14 - 0s - loss: 0.7285 - accuracy: 0.6009\n",
      "Epoch 14/50\n",
      "14/14 - 1s - loss: 0.7268 - accuracy: 0.5915\n",
      "Epoch 13/50\n",
      "14/14 - 0s - loss: 0.2994 - accuracy: 0.8685\n",
      "Epoch 13/50\n",
      "14/14 - 1s - loss: 0.2915 - accuracy: 0.8592\n",
      "Epoch 15/50\n",
      "14/14 - 1s - loss: 0.6588 - accuracy: 0.6215\n",
      "Epoch 15/50\n",
      "14/14 - 0s - loss: 0.6474 - accuracy: 0.6338\n",
      "Epoch 14/50\n",
      "14/14 - 0s - loss: 0.2517 - accuracy: 0.8779\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.5762 - accuracy: 0.6869\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.5572 - accuracy: 0.7089\n",
      "Epoch 14/50\n",
      "14/14 - 1s - loss: 0.7218 - accuracy: 0.6009\n",
      "Epoch 14/50\n",
      "14/14 - 1s - loss: 0.2188 - accuracy: 0.8967\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.5836 - accuracy: 0.6854\n",
      "Epoch 16/50\n",
      "14/14 - 1s - loss: 0.5023 - accuracy: 0.7196\n",
      "Epoch 16/50\n",
      "14/14 - 0s - loss: 0.7604 - accuracy: 0.6479\n",
      "Epoch 15/50\n",
      "14/14 - 1s - loss: 0.2043 - accuracy: 0.9014\n",
      "Epoch 15/50\n",
      "14/14 - 1s - loss: 0.6460 - accuracy: 0.6197\n",
      "Epoch 15/50\n",
      "14/14 - 1s - loss: 0.2930 - accuracy: 0.9061\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.5895 - accuracy: 0.7243\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.5754 - accuracy: 0.6808\n",
      "Epoch 17/50\n",
      "14/14 - 0s - loss: 0.6475 - accuracy: 0.6197\n",
      "Epoch 17/50\n",
      "14/14 - 1s - loss: 0.6153 - accuracy: 0.7056\n",
      "Epoch 16/50\n",
      "14/14 - 0s - loss: 0.2143 - accuracy: 0.9202\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.5931 - accuracy: 0.6479\n",
      "Epoch 16/50\n",
      "14/14 - 0s - loss: 0.3153 - accuracy: 0.8826\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 16/50\n",
      "14/14 - 1s - loss: 0.7228 - accuracy: 0.5869\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 18/50\n",
      "14/14 - 1s - loss: 0.6373 - accuracy: 0.6620\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.5976 - accuracy: 0.6729\n",
      "Epoch 17/50\n",
      "14/14 - 0s - loss: 0.2626 - accuracy: 0.8545\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.5828 - accuracy: 0.7324\n",
      "Epoch 18/50\n",
      "14/14 - 1s - loss: 0.5490 - accuracy: 0.7056\n",
      "Epoch 17/50\n",
      "14/14 - 0s - loss: 0.2616 - accuracy: 0.8498\n",
      "Epoch 17/50\n",
      "14/14 - 0s - loss: 0.6532 - accuracy: 0.6526\n",
      "Epoch 19/50\n",
      "14/14 - 1s - loss: 0.6153 - accuracy: 0.6479\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.5634 - accuracy: 0.7700\n",
      "Epoch 18/50\n",
      "14/14 - 0s - loss: 0.1820 - accuracy: 0.9390\n",
      "Epoch 19/50\n",
      "14/14 - 1s - loss: 0.6591 - accuracy: 0.6822\n",
      "Epoch 18/50\n",
      "14/14 - 0s - loss: 0.2400 - accuracy: 0.8967\n",
      "Epoch 18/50\n",
      "14/14 - 1s - loss: 0.7037 - accuracy: 0.6526\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.5758 - accuracy: 0.6761\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.5766 - accuracy: 0.7150\n",
      "Epoch 20/50\n",
      "14/14 - 0s - loss: 0.6782 - accuracy: 0.6244\n",
      "Epoch 19/50\n",
      "14/14 - 1s - loss: 0.1535 - accuracy: 0.9249\n",
      "Epoch 20/50\n",
      "14/14 - 0s - loss: 0.6309 - accuracy: 0.6682\n",
      "Epoch 19/50\n",
      "14/14 - 0s - loss: 0.6481 - accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "14/14 - 1s - loss: 0.1554 - accuracy: 0.9577\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.5968 - accuracy: 0.6620\n",
      "Epoch 21/50\n",
      "14/14 - 1s - loss: 0.6477 - accuracy: 0.6197\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.5684 - accuracy: 0.7042\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 21/50\n",
      "14/14 - 1s - loss: 0.5267 - accuracy: 0.6636\n",
      "Epoch 20/50\n",
      "14/14 - 0s - loss: 0.6597 - accuracy: 0.6244\n",
      "Epoch 20/50\n",
      "14/14 - 1s - loss: 0.2112 - accuracy: 0.9484\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.5560 - accuracy: 0.6963\n",
      "Epoch 20/50\n",
      "14/14 - 0s - loss: 0.1672 - accuracy: 0.9155\n",
      "Epoch 22/50\n",
      "14/14 - 1s - loss: 0.6654 - accuracy: 0.6808\n",
      "Epoch 21/50\n",
      "14/14 - 0s - loss: 0.2585 - accuracy: 0.8545\n",
      "Epoch 22/50\n",
      "14/14 - 1s - loss: 0.4789 - accuracy: 0.7336\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.5751 - accuracy: 0.6808\n",
      "Epoch 21/50\n",
      "14/14 - 1s - loss: 0.6701 - accuracy: 0.6432\n",
      "Epoch 21/50\n",
      "14/14 - 0s - loss: 0.1684 - accuracy: 0.9202\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.5551 - accuracy: 0.7042\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.5644 - accuracy: 0.7383\n",
      "Epoch 23/50\n",
      "14/14 - 0s - loss: 0.6753 - accuracy: 0.6103\n",
      "Epoch 22/50\n",
      "14/14 - 0s - loss: 0.1522 - accuracy: 0.9390\n",
      "Epoch 23/50\n",
      "14/14 - 1s - loss: 0.6756 - accuracy: 0.6776\n",
      "Epoch 22/50\n",
      "14/14 - 0s - loss: 0.1709 - accuracy: 0.9202\n",
      "Epoch 22/50\n",
      "14/14 - 1s - loss: 0.6749 - accuracy: 0.6103\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.5415 - accuracy: 0.7559\n",
      "Epoch 24/50\n",
      "14/14 - 0s - loss: 0.6686 - accuracy: 0.6714\n",
      "Epoch 23/50\n",
      "14/14 - 1s - loss: 0.1508 - accuracy: 0.9343\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.5451 - accuracy: 0.7183\n",
      "Epoch 24/50\n",
      "14/14 - 1s - loss: 0.5592 - accuracy: 0.7056\n",
      "Epoch 23/50\n",
      "14/14 - 1s - loss: 0.1974 - accuracy: 0.9155\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.5582 - accuracy: 0.7336\n",
      "Epoch 23/50\n",
      "14/14 - 1s - loss: 0.6297 - accuracy: 0.6432\n",
      "Epoch 25/50\n",
      "14/14 - 1s - loss: 0.7109 - accuracy: 0.6385\n",
      "Epoch 24/50\n",
      "14/14 - 1s - loss: 0.0875 - accuracy: 0.9906\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.5746 - accuracy: 0.7230\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 24/50\n",
      "14/14 - 0s - loss: 0.1861 - accuracy: 0.8920\n",
      "Epoch 25/50\n",
      "14/14 - 1s - loss: 0.5531 - accuracy: 0.6776\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 24/50\n",
      "14/14 - 1s - loss: 0.6940 - accuracy: 0.6244\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.5367 - accuracy: 0.7183\n",
      "Epoch 26/50\n",
      "14/14 - 0s - loss: 0.6570 - accuracy: 0.6526\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.5512 - accuracy: 0.7009\n",
      "Epoch 26/50\n",
      "14/14 - 0s - loss: 0.5739 - accuracy: 0.6636\n",
      "Epoch 25/50\n",
      "14/14 - 1s - loss: 0.1716 - accuracy: 0.9296\n",
      "Epoch 25/50\n",
      "14/14 - 1s - loss: 0.1571 - accuracy: 0.9484\n",
      "Epoch 25/50\n",
      "14/14 - 1s - loss: 0.7322 - accuracy: 0.6573\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.5633 - accuracy: 0.6948\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 27/50\n",
      "14/14 - 1s - loss: 0.7158 - accuracy: 0.5915\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.5673 - accuracy: 0.7606\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 27/50\n",
      "14/14 - 1s - loss: 0.5330 - accuracy: 0.7009\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.5523 - accuracy: 0.6916\n",
      "Epoch 26/50\n",
      "14/14 - 1s - loss: 0.1461 - accuracy: 0.9343\n",
      "Epoch 26/50\n",
      "14/14 - 0s - loss: 0.1383 - accuracy: 0.9249\n",
      "Epoch 26/50\n",
      "14/14 - 1s - loss: 0.6899 - accuracy: 0.6667\n",
      "Epoch 28/50\n",
      "14/14 - 0s - loss: 0.6221 - accuracy: 0.6526\n",
      "Epoch 28/50\n",
      "14/14 - 0s - loss: 0.6104 - accuracy: 0.6729\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.5691 - accuracy: 0.6901\n",
      "Epoch 27/50\n",
      "14/14 - 1s - loss: 0.1380 - accuracy: 0.9390\n",
      "Epoch 27/50\n",
      "14/14 - 1s - loss: 0.0975 - accuracy: 0.9671\n",
      "Epoch 27/50\n",
      "14/14 - 1s - loss: 0.7082 - accuracy: 0.6526\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.5500 - accuracy: 0.6479\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.5452 - accuracy: 0.7336\n",
      "Epoch 29/50\n",
      "14/14 - 1s - loss: 0.5728 - accuracy: 0.6901\n",
      "Epoch 29/50\n",
      "14/14 - 0s - loss: 0.5881 - accuracy: 0.7103\n",
      "Epoch 28/50\n",
      "14/14 - 1s - loss: 0.1056 - accuracy: 0.9484\n",
      "Epoch 28/50\n",
      "14/14 - 1s - loss: 0.1383 - accuracy: 0.9343\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.5517 - accuracy: 0.7324\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 28/50\n",
      "14/14 - 1s - loss: 0.5671 - accuracy: 0.6995\n",
      "Epoch 30/50\n",
      "14/14 - 0s - loss: 0.5668 - accuracy: 0.6822\n",
      "Epoch 30/50\n",
      "14/14 - 1s - loss: 0.6659 - accuracy: 0.6573\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.5655 - accuracy: 0.7056\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.5385 - accuracy: 0.6948\n",
      "Epoch 29/50\n",
      "14/14 - 0s - loss: 0.1219 - accuracy: 0.9906\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 29/50\n",
      "14/14 - 1s - loss: 0.1184 - accuracy: 0.9484\n",
      "Epoch 29/50\n",
      "14/14 - 1s - loss: 0.6163 - accuracy: 0.6854\n",
      "Epoch 31/50\n",
      "14/14 - 0s - loss: 0.6511 - accuracy: 0.6150\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 31/50\n",
      "14/14 - 1s - loss: 0.5526 - accuracy: 0.7103\n",
      "Epoch 30/50\n",
      "14/14 - 0s - loss: 0.1236 - accuracy: 0.9296\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.5475 - accuracy: 0.6808\n",
      "Epoch 30/50\n",
      "14/14 - 0s - loss: 0.1037 - accuracy: 0.9671\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.5375 - accuracy: 0.7757\n",
      "Epoch 30/50\n",
      "14/14 - 0s - loss: 0.6157 - accuracy: 0.6854\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.5357 - accuracy: 0.7653\n",
      "Epoch 32/50\n",
      "14/14 - 1s - loss: 0.6055 - accuracy: 0.6963\n",
      "Epoch 32/50\n",
      "14/14 - 1s - loss: 0.6183 - accuracy: 0.6667\n",
      "Epoch 31/50\n",
      "14/14 - 0s - loss: 0.0859 - accuracy: 0.9765\n",
      "Epoch 31/50\n",
      "14/14 - 0s - loss: 0.1062 - accuracy: 0.9624\n",
      "Epoch 31/50\n",
      "14/14 - 0s - loss: 0.6895 - accuracy: 0.6667\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.5655 - accuracy: 0.6948\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.5261 - accuracy: 0.7336\n",
      "Epoch 33/50\n",
      "14/14 - 1s - loss: 0.4925 - accuracy: 0.7570\n",
      "Epoch 33/50\n",
      "14/14 - 1s - loss: 0.5862 - accuracy: 0.7230\n",
      "Epoch 32/50\n",
      "14/14 - 0s - loss: 0.1160 - accuracy: 0.9437\n",
      "Epoch 32/50\n",
      "14/14 - 0s - loss: 0.0915 - accuracy: 0.9531\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.5446 - accuracy: 0.6761\n",
      "Epoch 32/50\n",
      "14/14 - 1s - loss: 0.7094 - accuracy: 0.6150\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.5331 - accuracy: 0.7196\n",
      "Epoch 33/50\n",
      "14/14 - 0s - loss: 0.0860 - accuracy: 0.9765\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.6150 - accuracy: 0.6901\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 33/50\n",
      "14/14 - 1s - loss: 0.1190 - accuracy: 0.9531\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.5508 - accuracy: 0.6854\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.5462 - accuracy: 0.7430\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.5333 - accuracy: 0.7183\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 33/50\n",
      "14/14 - 1s - loss: 0.7487 - accuracy: 0.6009\n",
      "Epoch 35/50\n",
      "14/14 - 0s - loss: 0.5808 - accuracy: 0.7103\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.0873 - accuracy: 0.9765\n",
      "Epoch 35/50\n",
      "14/14 - 0s - loss: 0.6716 - accuracy: 0.6526\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.1069 - accuracy: 0.9671\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.5349 - accuracy: 0.7230\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.5583 - accuracy: 0.7089\n",
      "Epoch 36/50\n",
      "14/14 - 1s - loss: 0.5884 - accuracy: 0.7430\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.5156 - accuracy: 0.7664\n",
      "Epoch 35/50\n",
      "14/14 - 1s - loss: 0.0879 - accuracy: 0.9671\n",
      "Epoch 36/50\n",
      "14/14 - 1s - loss: 0.6205 - accuracy: 0.6479\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.5143 - accuracy: 0.7418\n",
      "Epoch 35/50\n",
      "14/14 - 0s - loss: 0.0810 - accuracy: 0.9577\n",
      "Epoch 35/50\n",
      "14/14 - 1s - loss: 0.7105 - accuracy: 0.6385\n",
      "Epoch 37/50\n",
      "14/14 - 0s - loss: 0.5100 - accuracy: 0.7477\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.5588 - accuracy: 0.7230\n",
      "Epoch 36/50\n",
      "14/14 - 1s - loss: 0.0752 - accuracy: 0.9671\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.5083 - accuracy: 0.7850\n",
      "Epoch 37/50\n",
      "14/14 - 1s - loss: 0.7049 - accuracy: 0.6150\n",
      "Epoch 36/50\n",
      "14/14 - 1s - loss: 0.0953 - accuracy: 0.9484\n",
      "Epoch 36/50\n",
      "14/14 - 0s - loss: 0.6775 - accuracy: 0.6620\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.5216 - accuracy: 0.7324\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 38/50\n",
      "14/14 - 1s - loss: 0.4999 - accuracy: 0.7336\n",
      "Epoch 37/50\n",
      "14/14 - 0s - loss: 0.0619 - accuracy: 0.9765\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 37/50\n",
      "14/14 - 0s - loss: 0.1094 - accuracy: 0.9577\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 38/50\n",
      "14/14 - 1s - loss: 0.6792 - accuracy: 0.6620\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.5681 - accuracy: 0.7465\n",
      "Epoch 37/50\n",
      "14/14 - 1s - loss: 0.6567 - accuracy: 0.6479\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.5176 - accuracy: 0.7243\n",
      "Epoch 39/50\n",
      "14/14 - 1s - loss: 0.5190 - accuracy: 0.7290\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 38/50\n",
      "14/14 - 0s - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "14/14 - 0s - loss: 0.0834 - accuracy: 0.9624\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.5296 - accuracy: 0.7371\n",
      "Epoch 39/50\n",
      "14/14 - 1s - loss: 0.5964 - accuracy: 0.6620\n",
      "Epoch 38/50\n",
      "14/14 - 1s - loss: 0.7043 - accuracy: 0.6291\n",
      "Epoch 40/50\n",
      "14/14 - 0s - loss: 0.4984 - accuracy: 0.7243\n",
      "Epoch 39/50\n",
      "14/14 - 0s - loss: 0.0687 - accuracy: 0.9859\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.5616 - accuracy: 0.7324\n",
      "Epoch 39/50\n",
      "14/14 - 0s - loss: 0.0618 - accuracy: 0.9859\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.5570 - accuracy: 0.7243\n",
      "Epoch 40/50\n",
      "14/14 - 0s - loss: 0.6691 - accuracy: 0.6385\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.4991 - accuracy: 0.7512\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 39/50\n",
      "14/14 - 1s - loss: 0.6235 - accuracy: 0.6479\n",
      "Epoch 41/50\n",
      "14/14 - 1s - loss: 0.5667 - accuracy: 0.6729\n",
      "Epoch 40/50\n",
      "14/14 - 1s - loss: 0.0510 - accuracy: 0.9765\n",
      "Epoch 40/50\n",
      "14/14 - 1s - loss: 0.0765 - accuracy: 0.9671\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.5512 - accuracy: 0.6995\n",
      "Epoch 41/50\n",
      "14/14 - 1s - loss: 0.5878 - accuracy: 0.6948\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.5056 - accuracy: 0.7430\n",
      "Epoch 40/50\n",
      "14/14 - 0s - loss: 0.7382 - accuracy: 0.5869\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 42/50\n",
      "14/14 - 1s - loss: 0.5346 - accuracy: 0.6963\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.5090 - accuracy: 0.7324\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 41/50\n",
      "14/14 - 1s - loss: 0.1238 - accuracy: 0.9671\n",
      "Epoch 41/50\n",
      "14/14 - 1s - loss: 0.0637 - accuracy: 0.9671\n",
      "Epoch 41/50\n",
      "14/14 - 0s - loss: 0.6751 - accuracy: 0.6573\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 42/50\n",
      "14/14 - 1s - loss: 0.6701 - accuracy: 0.6761\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.5511 - accuracy: 0.7089\n",
      "Epoch 43/50\n",
      "14/14 - 0s - loss: 0.5246 - accuracy: 0.6963\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.5495 - accuracy: 0.7383\n",
      "Epoch 42/50\n",
      "14/14 - 0s - loss: 0.0998 - accuracy: 0.9624\n",
      "Epoch 42/50\n",
      "14/14 - 1s - loss: 0.0940 - accuracy: 0.9577\n",
      "Epoch 42/50\n",
      "14/14 - 1s - loss: 0.7172 - accuracy: 0.6479\n",
      "Epoch 43/50\n",
      "14/14 - 1s - loss: 0.6525 - accuracy: 0.6808\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.5197 - accuracy: 0.7230\n",
      "Epoch 44/50\n",
      "14/14 - 0s - loss: 0.5407 - accuracy: 0.6869\n",
      "Epoch 43/50\n",
      "14/14 - 0s - loss: 0.0786 - accuracy: 0.9671\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 43/50\n",
      "14/14 - 1s - loss: 0.0584 - accuracy: 0.9718\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.5482 - accuracy: 0.6854\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.5391 - accuracy: 0.7196\n",
      "Epoch 43/50\n",
      "14/14 - 0s - loss: 0.6820 - accuracy: 0.6197\n",
      "Epoch 44/50\n",
      "14/14 - 0s - loss: 0.6454 - accuracy: 0.6901\n",
      "Epoch 45/50\n",
      "14/14 - 1s - loss: 0.5686 - accuracy: 0.6916\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.5149 - accuracy: 0.7089\n",
      "Epoch 44/50\n",
      "14/14 - 1s - loss: 0.0731 - accuracy: 0.9718\n",
      "Epoch 44/50\n",
      "14/14 - 1s - loss: 0.0467 - accuracy: 0.9812\n",
      "Epoch 44/50\n",
      "14/14 - 0s - loss: 0.6626 - accuracy: 0.6291\n",
      "Epoch 45/50\n",
      "14/14 - 1s - loss: 0.6297 - accuracy: 0.6573\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 46/50\n",
      "14/14 - 0s - loss: 0.5546 - accuracy: 0.6776\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.5299 - accuracy: 0.7383\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.5446 - accuracy: 0.7230\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 45/50\n",
      "14/14 - 0s - loss: 0.0652 - accuracy: 0.9765\n",
      "Epoch 45/50\n",
      "14/14 - 0s - loss: 0.7266 - accuracy: 0.6432\n",
      "Epoch 45/50\n",
      "14/14 - 1s - loss: 0.0656 - accuracy: 0.9671\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.5290 - accuracy: 0.7559\n",
      "Epoch 47/50\n",
      "14/14 - 1s - loss: 0.5589 - accuracy: 0.7009\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 46/50\n",
      "14/14 - 1s - loss: 0.6380 - accuracy: 0.6620\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.5142 - accuracy: 0.7664\n",
      "Epoch 46/50\n",
      "14/14 - 0s - loss: 0.6960 - accuracy: 0.6197\n",
      "Epoch 46/50\n",
      "14/14 - 1s - loss: 0.1127 - accuracy: 0.9671\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.5639 - accuracy: 0.7183\n",
      "Epoch 46/50\n",
      "14/14 - 1s - loss: 0.0711 - accuracy: 0.9812\n",
      "Epoch 47/50\n",
      "14/14 - 1s - loss: 0.6090 - accuracy: 0.6479\n",
      "Epoch 48/50\n",
      "14/14 - 1s - loss: 0.5180 - accuracy: 0.7103\n",
      "Epoch 47/50\n",
      "14/14 - 1s - loss: 0.6141 - accuracy: 0.6338\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.5177 - accuracy: 0.7089\n",
      "Epoch 47/50\n",
      "14/14 - 1s - loss: 0.1220 - accuracy: 0.9671\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 47/50\n",
      "14/14 - 1s - loss: 0.0351 - accuracy: 0.9859\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.5300 - accuracy: 0.7383\n",
      "Epoch 49/50\n",
      "14/14 - 0s - loss: 0.5780 - accuracy: 0.7103\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.5508 - accuracy: 0.7230\n",
      "Epoch 48/50\n",
      "14/14 - 1s - loss: 0.6953 - accuracy: 0.6338\n",
      "Epoch 48/50\n",
      "14/14 - 1s - loss: 0.6771 - accuracy: 0.6338\n",
      "Epoch 48/50\n",
      "14/14 - 1s - loss: 0.0593 - accuracy: 0.9812\n",
      "Epoch 48/50\n",
      "14/14 - 1s - loss: 0.0392 - accuracy: 0.9859\n",
      "Epoch 49/50\n",
      "14/14 - 0s - loss: 0.6657 - accuracy: 0.6150\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.5312 - accuracy: 0.7136\n",
      "Epoch 50/50\n",
      "14/14 - 1s - loss: 0.5145 - accuracy: 0.7383\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.5367 - accuracy: 0.6916\n",
      "Epoch 49/50\n",
      "14/14 - 0s - loss: 0.7121 - accuracy: 0.6197\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.5325 - accuracy: 0.7465\n",
      "Epoch 50/50\n",
      "14/14 - 0s - loss: 0.6164 - accuracy: 0.6573\n",
      "Epoch 49/50\n",
      "14/14 - 0s - loss: 0.0465 - accuracy: 0.9859\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 49/50\n",
      "14/14 - 1s - loss: 0.0941 - accuracy: 0.9484\n",
      "Epoch 50/50\n",
      "14/14 - 0s - loss: 0.0373 - accuracy: 0.9906\n",
      "Epoch 50/50\n",
      "14/14 - 0s - loss: 0.6225 - accuracy: 0.6808\n",
      "Epoch 50/50\n",
      "14/14 - 0s - loss: 0.0607 - accuracy: 0.9812\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.5384 - accuracy: 0.6948\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.5156 - accuracy: 0.7336\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.5343 - accuracy: 0.7042\n",
      "7/7 - 1s - loss: 0.5416 - accuracy: 0.7453\n",
      "7/7 - 1s - loss: 0.6464 - accuracy: 0.6355\n",
      "Epoch 35/50\n",
      "54/54 - 0s - loss: 0.4797 - accuracy: 0.7840\n",
      "7/7 - 0s - loss: 0.4666 - accuracy: 0.8224\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.4988 - accuracy: 0.7804\n",
      "Epoch 35/50\n",
      "54/54 - 0s - loss: 0.5617 - accuracy: 0.7230\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "7/7 - 1s - loss: 0.4638 - accuracy: 0.8318\n",
      "7/7 - 1s - loss: 0.6764 - accuracy: 0.6075\n",
      "Epoch 36/50\n",
      "54/54 - 0s - loss: 0.5547 - accuracy: 0.7230\n",
      "Epoch 37/50\n",
      "54/54 - 0s - loss: 0.5262 - accuracy: 0.7430\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.5458 - accuracy: 0.7324\n",
      "Epoch 37/50\n",
      "54/54 - 0s - loss: 0.5265 - accuracy: 0.7089\n",
      "Epoch 37/50\n",
      "54/54 - 0s - loss: 0.5328 - accuracy: 0.7089\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.5312 - accuracy: 0.7710\n",
      "Epoch 38/50\n",
      "54/54 - 0s - loss: 0.5235 - accuracy: 0.7136\n",
      "Epoch 38/50\n",
      "54/54 - 0s - loss: 0.5436 - accuracy: 0.6995\n",
      "Epoch 39/50\n",
      "54/54 - 0s - loss: 0.5181 - accuracy: 0.7523\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.5460 - accuracy: 0.7136\n",
      "Epoch 39/50\n",
      "54/54 - 0s - loss: 0.5167 - accuracy: 0.7277\n",
      "Epoch 40/50\n",
      "54/54 - 0s - loss: 0.5402 - accuracy: 0.7383\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 40/50\n",
      "54/54 - 0s - loss: 0.5532 - accuracy: 0.6808\n",
      "Epoch 40/50\n",
      "54/54 - 0s - loss: 0.5419 - accuracy: 0.7089\n",
      "Epoch 41/50\n",
      "54/54 - 0s - loss: 0.5133 - accuracy: 0.7383\n",
      "Epoch 1/50\n",
      "14/14 - 2s - loss: 0.6820 - accuracy: 0.5794\n",
      "Epoch 2/50\n",
      "14/14 - 0s - loss: 0.5777 - accuracy: 0.6916\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.5090 - accuracy: 0.7089\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.5243 - accuracy: 0.7324\n",
      "Epoch 1/50\n",
      "54/54 - 2s - loss: 0.6974 - accuracy: 0.5888\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.5259 - accuracy: 0.7850\n",
      "Epoch 3/50\n",
      "14/14 - 1s - loss: 0.5324 - accuracy: 0.7710\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 0.7339 - accuracy: 0.4977\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.5397 - accuracy: 0.7277\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 0.7428 - accuracy: 0.5493\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.5369 - accuracy: 0.7196\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.5414 - accuracy: 0.6854\n",
      "Epoch 4/50\n",
      "14/14 - 0s - loss: 0.4276 - accuracy: 0.8037\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 0.6553 - accuracy: 0.5140\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 0.6857 - accuracy: 0.5352\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 0.6797 - accuracy: 0.4554\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.5368 - accuracy: 0.7150\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.5325 - accuracy: 0.7183\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.4981 - accuracy: 0.7465\n",
      "Epoch 5/50\n",
      "14/14 - 1s - loss: 0.4224 - accuracy: 0.7991\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6393 - accuracy: 0.6308\n",
      "Epoch 1/50\n",
      "27/27 - 3s - loss: 1.0262 - accuracy: 0.5540\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6898 - accuracy: 0.6244\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.5485 - accuracy: 0.7570\n",
      "Epoch 6/50\n",
      "14/14 - 0s - loss: 0.4221 - accuracy: 0.8037\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6648 - accuracy: 0.6479\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.6616 - accuracy: 0.6995\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.5887 - accuracy: 0.6901\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.5074 - accuracy: 0.7136\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.5920 - accuracy: 0.7290\n",
      "Epoch 7/50\n",
      "14/14 - 0s - loss: 0.5091 - accuracy: 0.7523\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.6289 - accuracy: 0.6854\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.6281 - accuracy: 0.6150\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.6372 - accuracy: 0.6620\n",
      "Epoch 8/50\n",
      "14/14 - 0s - loss: 0.3517 - accuracy: 0.8084\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.5213 - accuracy: 0.7243\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.5418 - accuracy: 0.7042\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.5017 - accuracy: 0.7700\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.5519 - accuracy: 0.7430\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.4827 - accuracy: 0.7793\n",
      "Epoch 9/50\n",
      "14/14 - 1s - loss: 0.3510 - accuracy: 0.8738\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.5708 - accuracy: 0.6995\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.5910 - accuracy: 0.6854\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.5354 - accuracy: 0.7523\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.5289 - accuracy: 0.7136\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.5439 - accuracy: 0.7277\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.5550 - accuracy: 0.6729\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.5689 - accuracy: 0.6995\n",
      "Epoch 10/50\n",
      "14/14 - 1s - loss: 0.2957 - accuracy: 0.8738\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.5423 - accuracy: 0.7196\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.6036 - accuracy: 0.6854\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.5075 - accuracy: 0.7196\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.5642 - accuracy: 0.7089\n",
      "Epoch 11/50\n",
      "14/14 - 1s - loss: 0.3070 - accuracy: 0.8551\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.4933 - accuracy: 0.7653\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.5386 - accuracy: 0.6948\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.5130 - accuracy: 0.7230\n",
      "Epoch 12/50\n",
      "14/14 - 1s - loss: 0.2195 - accuracy: 0.8972\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.5097 - accuracy: 0.7477\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.5135 - accuracy: 0.7383\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.6014 - accuracy: 0.6103\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.3596 - accuracy: 0.7981\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.6087 - accuracy: 0.6854\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.5135 - accuracy: 0.7230\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.5395 - accuracy: 0.7183\n",
      "Epoch 13/50\n",
      "14/14 - 1s - loss: 0.1490 - accuracy: 0.9206\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.5301 - accuracy: 0.7653\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.4639 - accuracy: 0.7850\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.4895 - accuracy: 0.7664\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.5831 - accuracy: 0.7089\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.5543 - accuracy: 0.6714\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.5278 - accuracy: 0.7230\n",
      "Epoch 14/50\n",
      "14/14 - 1s - loss: 0.2582 - accuracy: 0.8832\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.5374 - accuracy: 0.7230\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.5011 - accuracy: 0.7512\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.4789 - accuracy: 0.7991\n",
      "Epoch 15/50\n",
      "14/14 - 0s - loss: 0.1702 - accuracy: 0.9252\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.5670 - accuracy: 0.6761\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.5589 - accuracy: 0.7089\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.5409 - accuracy: 0.7183\n",
      "Epoch 16/50\n",
      "14/14 - 0s - loss: 0.2151 - accuracy: 0.9019\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.3983 - accuracy: 0.8498\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.5101 - accuracy: 0.7324\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.4835 - accuracy: 0.7430\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.5562 - accuracy: 0.6620\n",
      "Epoch 11/50\n",
      "27/27 - 0s - loss: 0.4555 - accuracy: 0.7793\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.5100 - accuracy: 0.7371\n",
      "Epoch 17/50\n",
      "14/14 - 0s - loss: 0.2125 - accuracy: 0.8832\n",
      "27/27 - 1s - loss: 0.5601 - accuracy: 0.6887\n",
      "Epoch 18/50\n",
      "14/14 - 0s - loss: 0.2352 - accuracy: 0.8972\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.5147 - accuracy: 0.7700\n",
      "Epoch 12/50\n",
      "27/27 - 0s - loss: 0.3532 - accuracy: 0.8732\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.4384 - accuracy: 0.7804\n",
      "Epoch 11/50\n",
      "54/54 - 0s - loss: 0.5019 - accuracy: 0.7606\n",
      "27/27 - 1s - loss: 0.6162 - accuracy: 0.6449\n",
      "Epoch 19/50\n",
      "14/14 - 0s - loss: 0.1754 - accuracy: 0.9065\n",
      "27/27 - 1s - loss: 0.6046 - accuracy: 0.6636\n",
      "Epoch 13/50\n",
      "27/27 - 0s - loss: 0.3134 - accuracy: 0.8451\n",
      "Epoch 12/50\n",
      "54/54 - 0s - loss: 0.4492 - accuracy: 0.7089\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.4857 - accuracy: 0.7089\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 20/50\n",
      "14/14 - 0s - loss: 0.1950 - accuracy: 0.9159\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.4238 - accuracy: 0.8037\n",
      "Epoch 14/50\n",
      "27/27 - 0s - loss: 0.3292 - accuracy: 0.8592\n",
      "Epoch 21/50\n",
      "14/14 - 0s - loss: 0.1771 - accuracy: 0.9206\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.4677 - accuracy: 0.7981\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.5028 - accuracy: 0.7559\n",
      "Epoch 15/50\n",
      "27/27 - 0s - loss: 0.2804 - accuracy: 0.8920\n",
      "Epoch 22/50\n",
      "14/14 - 0s - loss: 0.1492 - accuracy: 0.9393\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.4095 - accuracy: 0.8084\n",
      "Epoch 16/50\n",
      "27/27 - 0s - loss: 0.2172 - accuracy: 0.9014\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.4488 - accuracy: 0.7887\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.4372 - accuracy: 0.7934\n",
      "Epoch 23/50\n",
      "14/14 - 0s - loss: 0.1233 - accuracy: 0.9393\n",
      "Epoch 17/50\n",
      "27/27 - 0s - loss: 0.2034 - accuracy: 0.9061\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.4263 - accuracy: 0.7897\n",
      "Epoch 24/50\n",
      "14/14 - 0s - loss: 0.1036 - accuracy: 0.9673\n",
      "Epoch 15/50\n",
      "54/54 - 0s - loss: 0.4632 - accuracy: 0.7418\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.4361 - accuracy: 0.7465\n",
      "Epoch 25/50\n",
      "14/14 - 0s - loss: 0.1206 - accuracy: 0.9346\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.4131 - accuracy: 0.7897\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.3199 - accuracy: 0.8638\n",
      "Epoch 26/50\n",
      "14/14 - 0s - loss: 0.0895 - accuracy: 0.9673\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.4401 - accuracy: 0.7606\n",
      "Epoch 19/50\n",
      "27/27 - 0s - loss: 0.3152 - accuracy: 0.8545\n",
      "Epoch 17/50\n",
      "54/54 - 0s - loss: 0.4054 - accuracy: 0.8084\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.3909 - accuracy: 0.7981\n",
      "Epoch 27/50\n",
      "14/14 - 0s - loss: 0.0779 - accuracy: 0.9533\n",
      "Epoch 20/50\n",
      "27/27 - 0s - loss: 0.2128 - accuracy: 0.8920\n",
      "Epoch 18/50\n",
      "54/54 - 0s - loss: 0.3679 - accuracy: 0.7804\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.4438 - accuracy: 0.7700\n",
      "Epoch 28/50\n",
      "14/14 - 0s - loss: 0.0688 - accuracy: 0.9813\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.2366 - accuracy: 0.9249\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.4350 - accuracy: 0.7606\n",
      "Epoch 29/50\n",
      "14/14 - 0s - loss: 0.0948 - accuracy: 0.9626\n",
      "Epoch 22/50\n",
      "27/27 - 0s - loss: 0.1654 - accuracy: 0.9108\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.4309 - accuracy: 0.7981\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.3496 - accuracy: 0.8551\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.2360 - accuracy: 0.9202\n",
      "Epoch 30/50\n",
      "14/14 - 0s - loss: 0.0592 - accuracy: 0.9860\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.4497 - accuracy: 0.8169\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.1587 - accuracy: 0.9202\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.3950 - accuracy: 0.7700\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.3250 - accuracy: 0.8551\n",
      "Epoch 31/50\n",
      "14/14 - 0s - loss: 0.0510 - accuracy: 0.9860\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.4044 - accuracy: 0.7934\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 0.9984 - accuracy: 0.5446\n",
      "Epoch 25/50\n",
      "27/27 - 0s - loss: 0.1693 - accuracy: 0.9296\n",
      "Epoch 32/50\n",
      "14/14 - 0s - loss: 0.0583 - accuracy: 0.9766\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.4023 - accuracy: 0.8216\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.3687 - accuracy: 0.8224\n",
      "Epoch 2/50\n",
      "27/27 - 0s - loss: 0.7752 - accuracy: 0.6808\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.1963 - accuracy: 0.9061\n",
      "Epoch 33/50\n",
      "14/14 - 0s - loss: 0.0468 - accuracy: 0.9907\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.4129 - accuracy: 0.7793\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 0.7199 - accuracy: 0.6244\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.8596 - accuracy: 0.6573\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.4051 - accuracy: 0.8028\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.3505 - accuracy: 0.8551\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 0.9597 - accuracy: 0.5981\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.2060 - accuracy: 0.9155\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.0900 - accuracy: 0.9720\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.6773 - accuracy: 0.5399\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.5145 - accuracy: 0.7606\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.3773 - accuracy: 0.8357\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.6551 - accuracy: 0.6449\n",
      "Epoch 35/50\n",
      "14/14 - 0s - loss: 0.0633 - accuracy: 0.9720\n",
      "Epoch 28/50\n",
      "27/27 - 1s - loss: 0.1885 - accuracy: 0.9296\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.3546 - accuracy: 0.8224\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.3533 - accuracy: 0.8451\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.6803 - accuracy: 0.5352\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.5310 - accuracy: 0.7700\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.5881 - accuracy: 0.7103\n",
      "Epoch 36/50\n",
      "14/14 - 1s - loss: 0.0717 - accuracy: 0.9813\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.2475 - accuracy: 0.9108\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.3474 - accuracy: 0.8216\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.6509 - accuracy: 0.5915\n",
      "Epoch 4/50\n",
      "27/27 - 0s - loss: 0.6142 - accuracy: 0.7056\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.5640 - accuracy: 0.7324\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.3246 - accuracy: 0.8411\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.3397 - accuracy: 0.8263\n",
      "Epoch 37/50\n",
      "14/14 - 1s - loss: 0.0376 - accuracy: 0.9860\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.2342 - accuracy: 0.9108\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.3649 - accuracy: 0.8357\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.6192 - accuracy: 0.6244\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.4694 - accuracy: 0.7710\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/50\n",
      "14/14 - 1s - loss: 0.1083 - accuracy: 0.9766\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.4957 - accuracy: 0.7277\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.1496 - accuracy: 0.9343\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.3204 - accuracy: 0.8364\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.3550 - accuracy: 0.8263\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.3483 - accuracy: 0.8357\n",
      "Epoch 39/50\n",
      "14/14 - 0s - loss: 0.0570 - accuracy: 0.9673\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.5881 - accuracy: 0.6948\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.1529 - accuracy: 0.9531\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.3740 - accuracy: 0.8131\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.3457 - accuracy: 0.8685\n",
      "Epoch 40/50\n",
      "14/14 - 1s - loss: 0.0402 - accuracy: 0.9907\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.3163 - accuracy: 0.8364\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.6168 - accuracy: 0.6761\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.3608 - accuracy: 0.8263\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.1254 - accuracy: 0.9390\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.3746 - accuracy: 0.8310\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.4878 - accuracy: 0.7757\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.3719 - accuracy: 0.8357\n",
      "Epoch 41/50\n",
      "14/14 - 1s - loss: 0.0454 - accuracy: 0.9813\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.5885 - accuracy: 0.6995\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.3158 - accuracy: 0.8458\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.0784 - accuracy: 0.9577\n",
      "Epoch 10/50\n",
      "27/27 - 0s - loss: 0.3905 - accuracy: 0.8075\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.3318 - accuracy: 0.8357\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.4217 - accuracy: 0.7850\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.3666 - accuracy: 0.7934\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 42/50\n",
      "14/14 - 0s - loss: 0.0511 - accuracy: 0.9766\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.3733 - accuracy: 0.8357\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.5577 - accuracy: 0.7042\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.1465 - accuracy: 0.9531\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.4300 - accuracy: 0.7897\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.3247 - accuracy: 0.8411\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.3389 - accuracy: 0.8357\n",
      "Epoch 43/50\n",
      "14/14 - 1s - loss: 0.0565 - accuracy: 0.9860\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.3455 - accuracy: 0.8404\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.5715 - accuracy: 0.6948\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.3344 - accuracy: 0.8357\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.0826 - accuracy: 0.9577\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.3079 - accuracy: 0.8598\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.2848 - accuracy: 0.8598\n",
      "Epoch 44/50\n",
      "14/14 - 1s - loss: 0.0469 - accuracy: 0.9766\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.3025 - accuracy: 0.8685\n",
      "Epoch 11/50\n",
      "27/27 - 0s - loss: 0.5807 - accuracy: 0.6573\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.3138 - accuracy: 0.8592\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.2967 - accuracy: 0.8645\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.2887 - accuracy: 0.8545\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.0763 - accuracy: 0.9624\n",
      "Epoch 45/50\n",
      "14/14 - 1s - loss: 0.0976 - accuracy: 0.9766\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.2896 - accuracy: 0.8598\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.2850 - accuracy: 0.8779\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.5753 - accuracy: 0.6573\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.2040 - accuracy: 0.9159\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.3306 - accuracy: 0.8545\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.3173 - accuracy: 0.8451\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 46/50\n",
      "14/14 - 1s - loss: 0.0388 - accuracy: 0.9579\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.0473 - accuracy: 0.9906\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.3140 - accuracy: 0.8738\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.5481 - accuracy: 0.6714\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.2698 - accuracy: 0.8826\n",
      "Epoch 47/50\n",
      "14/14 - 0s - loss: 0.0294 - accuracy: 0.9953\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.3440 - accuracy: 0.8364\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.2817 - accuracy: 0.8732\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.0749 - accuracy: 0.9812\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.3529 - accuracy: 0.8357\n",
      "Epoch 48/50\n",
      "14/14 - 0s - loss: 0.0246 - accuracy: 0.9907\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.2622 - accuracy: 0.8785\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.5719 - accuracy: 0.7277\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.2931 - accuracy: 0.8779\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.3391 - accuracy: 0.8505\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.2147 - accuracy: 0.9061\n",
      "Epoch 40/50\n",
      "27/27 - 1s - loss: 0.0783 - accuracy: 0.9624\n",
      "Epoch 49/50\n",
      "14/14 - 1s - loss: 0.0279 - accuracy: 0.9860\n",
      "Epoch 15/50\n",
      "27/27 - 0s - loss: 0.2132 - accuracy: 0.9159\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.3400 - accuracy: 0.8451\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.2907 - accuracy: 0.8785\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.5200 - accuracy: 0.6948\n",
      "Epoch 17/50\n",
      "27/27 - 1s - loss: 0.2293 - accuracy: 0.9014\n",
      "Epoch 50/50\n",
      "14/14 - 0s - loss: 0.0342 - accuracy: 0.9813\n",
      "Epoch 41/50\n",
      "27/27 - 1s - loss: 0.0716 - accuracy: 0.9765\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.2959 - accuracy: 0.8638\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.2794 - accuracy: 0.8738\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.2555 - accuracy: 0.8925\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.5355 - accuracy: 0.6948\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.3322 - accuracy: 0.8404\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.2250 - accuracy: 0.8920\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.0267 - accuracy: 0.9859\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 17/50\n",
      "27/27 - 1s - loss: 0.1540 - accuracy: 0.9299\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.2889 - accuracy: 0.8498\n",
      "Epoch 17/50\n",
      "27/27 - 1s - loss: 0.5560 - accuracy: 0.6948\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.2777 - accuracy: 0.8826\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.2266 - accuracy: 0.8920\n",
      "Epoch 18/50\n",
      "27/27 - 0s - loss: 0.1990 - accuracy: 0.9159\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.2908 - accuracy: 0.8692\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.0501 - accuracy: 0.9765\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.3111 - accuracy: 0.8638\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.5571 - accuracy: 0.6948\n",
      "7/7 - 1s - loss: 0.8146 - accuracy: 0.8019\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.1613 - accuracy: 0.9202\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.2021 - accuracy: 0.8972\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.3379 - accuracy: 0.8451\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.0419 - accuracy: 0.9906\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.2555 - accuracy: 0.8785\n",
      "Epoch 20/50\n",
      "27/27 - 0s - loss: 0.1580 - accuracy: 0.9439\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.1993 - accuracy: 0.8967\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.3032 - accuracy: 0.8967\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.0616 - accuracy: 0.9718\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.5483 - accuracy: 0.7089\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.1335 - accuracy: 0.9299\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.3372 - accuracy: 0.8310\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.2839 - accuracy: 0.8785\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.0336 - accuracy: 0.9906\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.2147 - accuracy: 0.9014\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.2464 - accuracy: 0.8826\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.5432 - accuracy: 0.7136\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.1427 - accuracy: 0.9299\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.3222 - accuracy: 0.8685\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.0579 - accuracy: 0.9812\n",
      "Epoch 23/50\n",
      "27/27 - 1s - loss: 0.1519 - accuracy: 0.9531\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.2843 - accuracy: 0.8738\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.2655 - accuracy: 0.8732\n",
      "Epoch 23/50\n",
      "27/27 - 1s - loss: 0.1286 - accuracy: 0.9346\n",
      "Epoch 21/50\n",
      "27/27 - 1s - loss: 0.5156 - accuracy: 0.7136\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 39/50\n",
      "54/54 - 0s - loss: 0.2826 - accuracy: 0.8785\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.2978 - accuracy: 0.8451\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.0379 - accuracy: 0.9906\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.0933 - accuracy: 0.9533\n",
      "Epoch 24/50\n",
      "27/27 - 1s - loss: 0.1511 - accuracy: 0.9014\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.4947 - accuracy: 0.7371\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.2562 - accuracy: 0.9014\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.3368 - accuracy: 0.8169\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.1100 - accuracy: 0.9486\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.2777 - accuracy: 0.8692\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.0546 - accuracy: 0.9859\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.2188 - accuracy: 0.9108\n",
      "Epoch 23/50\n",
      "27/27 - 1s - loss: 0.5257 - accuracy: 0.7230\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.2558 - accuracy: 0.8920\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.0772 - accuracy: 0.9484\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.1442 - accuracy: 0.9439\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.2995 - accuracy: 0.8779\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.2942 - accuracy: 0.8925\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.1028 - accuracy: 0.9624\n",
      "Epoch 24/50\n",
      "27/27 - 1s - loss: 0.5378 - accuracy: 0.7230\n",
      "Epoch 27/50\n",
      "27/27 - 0s - loss: 0.0970 - accuracy: 0.9860\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.2556 - accuracy: 0.8920\n",
      "Epoch 27/50\n",
      "27/27 - 0s - loss: 0.1112 - accuracy: 0.9624\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.3234 - accuracy: 0.8505\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.4982 - accuracy: 0.7418\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.3741 - accuracy: 0.8216\n",
      "Epoch 28/50\n",
      "27/27 - 1s - loss: 0.0834 - accuracy: 0.9579\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.1305 - accuracy: 0.9343\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.2857 - accuracy: 0.8920\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.2736 - accuracy: 0.8832\n",
      "Epoch 26/50\n",
      "27/27 - 0s - loss: 0.4954 - accuracy: 0.7418\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "14/14 - 1s - loss: 0.6455 - accuracy: 0.7944\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.1317 - accuracy: 0.9484\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.2471 - accuracy: 0.9014\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.0599 - accuracy: 0.9813\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.3165 - accuracy: 0.8685\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.2721 - accuracy: 0.8972\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.5221 - accuracy: 0.7746\n",
      "Epoch 30/50\n",
      "27/27 - 0s - loss: 0.1200 - accuracy: 0.9671\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.0601 - accuracy: 0.9720\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.2775 - accuracy: 0.8779\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.2891 - accuracy: 0.8692\n",
      "Epoch 28/50\n",
      "27/27 - 1s - loss: 0.4950 - accuracy: 0.7418\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.2738 - accuracy: 0.8826\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.1337 - accuracy: 0.9437\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.1122 - accuracy: 0.9533\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.2721 - accuracy: 0.8920\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.5132 - accuracy: 0.7793\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 0.7749 - accuracy: 0.5164\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.2816 - accuracy: 0.8458\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.2742 - accuracy: 0.8451\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.0854 - accuracy: 0.9673\n",
      "Epoch 32/50\n",
      "27/27 - 1s - loss: 0.0830 - accuracy: 0.9624\n",
      "Epoch 2/50\n",
      "27/27 - 0s - loss: 0.6700 - accuracy: 0.5587\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.2285 - accuracy: 0.9108\n",
      "Epoch 33/50\n",
      "27/27 - 0s - loss: 0.1413 - accuracy: 0.9299\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.4917 - accuracy: 0.7512\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.1072 - accuracy: 0.9531\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.2885 - accuracy: 0.8551\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.3316 - accuracy: 0.8216\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.6723 - accuracy: 0.6197\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.5067 - accuracy: 0.7512\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.1036 - accuracy: 0.9533\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.2383 - accuracy: 0.8920\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.1153 - accuracy: 0.9577\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.2755 - accuracy: 0.8920\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.5299 - accuracy: 0.6808\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.3108 - accuracy: 0.8505\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.6633 - accuracy: 0.6291\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.0991 - accuracy: 0.9720\n",
      "Epoch 33/50\n",
      "27/27 - 0s - loss: 0.5204 - accuracy: 0.7230\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.0874 - accuracy: 0.9718\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.2362 - accuracy: 0.9014\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.6405 - accuracy: 0.6009\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.3160 - accuracy: 0.8545\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.0765 - accuracy: 0.9579\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.5030 - accuracy: 0.7277\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.2883 - accuracy: 0.8972\n",
      "Epoch 6/50\n",
      "27/27 - 0s - loss: 0.6571 - accuracy: 0.5211\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.0844 - accuracy: 0.9531\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.0568 - accuracy: 0.9860\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.2251 - accuracy: 0.9108\n",
      "Epoch 7/50\n",
      "27/27 - 0s - loss: 0.6075 - accuracy: 0.6714\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.5120 - accuracy: 0.7465\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.2721 - accuracy: 0.9202\n",
      "Epoch 37/50\n",
      "27/27 - 0s - loss: 0.1357 - accuracy: 0.9390\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.2409 - accuracy: 0.8785\n",
      "Epoch 38/50\n",
      "27/27 - 0s - loss: 0.0550 - accuracy: 0.9813\n",
      "Epoch 38/50\n",
      "27/27 - 0s - loss: 0.1148 - accuracy: 0.9390\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.5704 - accuracy: 0.6479\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.5222 - accuracy: 0.7089\n",
      "Epoch 39/50\n",
      "27/27 - 0s - loss: 0.1012 - accuracy: 0.9671\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.2496 - accuracy: 0.9202\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.2919 - accuracy: 0.8685\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.0535 - accuracy: 0.9720\n",
      "Epoch 9/50\n",
      "27/27 - 0s - loss: 0.5873 - accuracy: 0.7559\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.4867 - accuracy: 0.7559\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.0435 - accuracy: 0.9812\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.3524 - accuracy: 0.8498\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.0571 - accuracy: 0.9626\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.2385 - accuracy: 0.9014\n",
      "Epoch 10/50\n",
      "27/27 - 0s - loss: 0.5736 - accuracy: 0.6385\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 38/50\n",
      "27/27 - 0s - loss: 0.5010 - accuracy: 0.7230\n",
      "27/27 - 1s - loss: 0.5274 - accuracy: 0.7453\n",
      "Epoch 41/50\n",
      "27/27 - 1s - loss: 0.0781 - accuracy: 0.9577\n",
      "Epoch 39/50\n",
      "27/27 - 0s - loss: 0.5223 - accuracy: 0.7136\n",
      "Epoch 41/50\n",
      "27/27 - 0s - loss: 0.0642 - accuracy: 0.9673\n",
      "Epoch 11/50\n",
      "27/27 - 0s - loss: 0.5377 - accuracy: 0.7230\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.3169 - accuracy: 0.8263\n",
      "Epoch 42/50\n",
      "27/27 - 0s - loss: 0.1376 - accuracy: 0.9484\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.4979 - accuracy: 0.7465\n",
      "Epoch 42/50\n",
      "27/27 - 0s - loss: 0.0455 - accuracy: 0.9860\n",
      "Epoch 12/50\n",
      "27/27 - 0s - loss: 0.5351 - accuracy: 0.6948\n",
      "27/27 - 1s - loss: 0.4308 - accuracy: 0.7850\n",
      "Epoch 43/50\n",
      "27/27 - 0s - loss: 0.0493 - accuracy: 0.9812\n",
      "Epoch 41/50\n",
      "27/27 - 0s - loss: 0.5200 - accuracy: 0.7324\n",
      "Epoch 1/50\n",
      "27/27 - 6s - loss: 0.7472 - accuracy: 0.3832\n",
      "Epoch 43/50\n",
      "27/27 - 0s - loss: 0.0652 - accuracy: 0.9766\n",
      "27/27 - 1s - loss: 0.4555 - accuracy: 0.7383\n",
      "Epoch 13/50\n",
      "27/27 - 0s - loss: 0.5354 - accuracy: 0.6854\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 42/50\n",
      "27/27 - 0s - loss: 0.5257 - accuracy: 0.7136\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.0995 - accuracy: 0.9671\n",
      "Epoch 2/50\n",
      "27/27 - 0s - loss: 0.7049 - accuracy: 0.7523\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 44/50\n",
      "27/27 - 0s - loss: 0.0300 - accuracy: 0.9907\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 14/50\n",
      "27/27 - 0s - loss: 0.5374 - accuracy: 0.7606\n",
      "Epoch 43/50\n",
      "27/27 - 0s - loss: 0.5045 - accuracy: 0.7230\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.0641 - accuracy: 0.9718\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.0688 - accuracy: 0.9813\n",
      "Epoch 3/50\n",
      "27/27 - 0s - loss: 0.6684 - accuracy: 0.4907\n",
      "Epoch 15/50\n",
      "27/27 - 0s - loss: 0.5376 - accuracy: 0.6901\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.1172 - accuracy: 0.9718\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.5185 - accuracy: 0.7230\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.0656 - accuracy: 0.9766\n",
      "Epoch 4/50\n",
      "27/27 - 0s - loss: 0.6645 - accuracy: 0.6168\n",
      "Epoch 16/50\n",
      "27/27 - 0s - loss: 0.5077 - accuracy: 0.7512\n",
      "Epoch 47/50\n",
      "27/27 - 0s - loss: 0.0669 - accuracy: 0.9812\n",
      "Epoch 5/50\n",
      "27/27 - 0s - loss: 0.6251 - accuracy: 0.6776\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.4995 - accuracy: 0.7324\n",
      "Epoch 47/50\n",
      "27/27 - 0s - loss: 0.0612 - accuracy: 0.9766\n",
      "Epoch 17/50\n",
      "27/27 - 0s - loss: 0.4710 - accuracy: 0.7653\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.0742 - accuracy: 0.9624\n",
      "Epoch 6/50\n",
      "27/27 - 0s - loss: 0.5684 - accuracy: 0.6916\n",
      "Epoch 18/50\n",
      "27/27 - 0s - loss: 0.4662 - accuracy: 0.7512\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.5119 - accuracy: 0.7230\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.0277 - accuracy: 0.9907\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.0653 - accuracy: 0.9859\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 7/50\n",
      "27/27 - 0s - loss: 0.5661 - accuracy: 0.7290\n",
      "Epoch 19/50\n",
      "27/27 - 0s - loss: 0.4698 - accuracy: 0.7512\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.0661 - accuracy: 0.9813\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.5121 - accuracy: 0.6901\n",
      "Epoch 8/50\n",
      "27/27 - 0s - loss: 0.6105 - accuracy: 0.6869\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.0474 - accuracy: 0.9812\n",
      "Epoch 20/50\n",
      "27/27 - 0s - loss: 0.4570 - accuracy: 0.7887\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.0527 - accuracy: 0.9813\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.4970 - accuracy: 0.7559\n",
      "Epoch 9/50\n",
      "27/27 - 0s - loss: 0.6023 - accuracy: 0.6215\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.4881 - accuracy: 0.7606\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 0.9257 - accuracy: 0.6714\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.5054 - accuracy: 0.7653\n",
      "Epoch 10/50\n",
      "27/27 - 0s - loss: 0.5424 - accuracy: 0.7523\n",
      "14/14 - 1s - loss: 0.4626 - accuracy: 0.8224\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.5109 - accuracy: 0.7183\n",
      "Epoch 22/50\n",
      "27/27 - 0s - loss: 0.4551 - accuracy: 0.7746\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 11/50\n",
      "27/27 - 0s - loss: 0.5529 - accuracy: 0.7336\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 1.4075 - accuracy: 0.5399\n",
      "14/14 - 1s - loss: 0.7530 - accuracy: 0.7830\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.4602 - accuracy: 0.7746\n",
      "Epoch 12/50\n",
      "27/27 - 0s - loss: 0.5304 - accuracy: 0.7243\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 1.5469 - accuracy: 0.5374\n",
      "14/14 - 1s - loss: 0.5935 - accuracy: 0.6822\n",
      "Epoch 13/50\n",
      "27/27 - 0s - loss: 0.5394 - accuracy: 0.7196\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.4549 - accuracy: 0.7746\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6902 - accuracy: 0.6901\n",
      "Epoch 2/50\n",
      "54/54 - 0s - loss: 0.6237 - accuracy: 0.6776\n",
      "Epoch 14/50\n",
      "27/27 - 0s - loss: 0.5094 - accuracy: 0.6963\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 25/50\n",
      "27/27 - 0s - loss: 0.4523 - accuracy: 0.7840\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.5528 - accuracy: 0.6854\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.5519 - accuracy: 0.7150\n",
      "Epoch 26/50\n",
      "27/27 - 0s - loss: 0.4389 - accuracy: 0.7840\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 15/50\n",
      "27/27 - 0s - loss: 0.5217 - accuracy: 0.7430\n",
      "Epoch 1/50\n",
      "54/54 - 5s - loss: 1.3820 - accuracy: 0.5540\n",
      "Epoch 27/50\n",
      "27/27 - 0s - loss: 0.4703 - accuracy: 0.7700\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.6039 - accuracy: 0.7477\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.5903 - accuracy: 0.7559\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.4760 - accuracy: 0.7418\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.4970 - accuracy: 0.7196\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 0.8171 - accuracy: 0.5869\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 29/50\n",
      "27/27 - 0s - loss: 0.4494 - accuracy: 0.8028\n",
      "Epoch 5/50\n",
      "54/54 - 0s - loss: 0.4757 - accuracy: 0.7570\n",
      "Epoch 17/50\n",
      "27/27 - 0s - loss: 0.5399 - accuracy: 0.7103\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.4167 - accuracy: 0.8028\n",
      "Epoch 30/50\n",
      "27/27 - 0s - loss: 0.4455 - accuracy: 0.7606\n",
      "Epoch 6/50\n",
      "54/54 - 0s - loss: 0.5545 - accuracy: 0.7570\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.5962 - accuracy: 0.7277\n",
      "Epoch 18/50\n",
      "27/27 - 0s - loss: 0.5227 - accuracy: 0.7477\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.4363 - accuracy: 0.7887\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 19/50\n",
      "27/27 - 0s - loss: 0.5018 - accuracy: 0.7664\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.4226 - accuracy: 0.7793\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.5859 - accuracy: 0.7183\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.4025 - accuracy: 0.8037\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.3964 - accuracy: 0.8122\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.5180 - accuracy: 0.7430\n",
      "Epoch 1/50\n",
      "27/27 - 3s - loss: 1.8631 - accuracy: 0.6103\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.4434 - accuracy: 0.7559\n",
      "Epoch 8/50\n",
      "54/54 - 0s - loss: 0.4345 - accuracy: 0.7570\n",
      "Epoch 2/50\n",
      "27/27 - 0s - loss: 0.9876 - accuracy: 0.6667\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.5293 - accuracy: 0.7196\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.6129 - accuracy: 0.6948\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.4789 - accuracy: 0.7653\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.3542 - accuracy: 0.8451\n",
      "Epoch 3/50\n",
      "27/27 - 0s - loss: 0.9378 - accuracy: 0.6385\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.4990 - accuracy: 0.7430\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.4024 - accuracy: 0.7944\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.4233 - accuracy: 0.7934\n",
      "Epoch 4/50\n",
      "27/27 - 0s - loss: 0.8865 - accuracy: 0.6197\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.4400 - accuracy: 0.8451\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 1.5927 - accuracy: 0.5352\n",
      "Epoch 23/50\n",
      "27/27 - 1s - loss: 0.5062 - accuracy: 0.7383\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.3933 - accuracy: 0.8169\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.5055 - accuracy: 0.7897\n",
      "Epoch 5/50\n",
      "27/27 - 0s - loss: 0.5214 - accuracy: 0.7934\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.4188 - accuracy: 0.8169\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 24/50\n",
      "27/27 - 1s - loss: 0.5200 - accuracy: 0.7430\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.6792 - accuracy: 0.7042\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 1.7705 - accuracy: 0.6197\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.4263 - accuracy: 0.8131\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.5525 - accuracy: 0.7277\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.4377 - accuracy: 0.7840\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.3723 - accuracy: 0.8451\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 2.1401 - accuracy: 0.5701\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 1.0715 - accuracy: 0.6009\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.4939 - accuracy: 0.7477\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.4058 - accuracy: 0.8169\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.4992 - accuracy: 0.7793\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.3261 - accuracy: 0.8638\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.4367 - accuracy: 0.7700\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.6306 - accuracy: 0.7324\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.2687 - accuracy: 0.8785\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.5178 - accuracy: 0.7336\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 1.0823 - accuracy: 0.6636\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.4629 - accuracy: 0.7700\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.5289 - accuracy: 0.7230\n",
      "Epoch 5/50\n",
      "27/27 - 0s - loss: 0.7408 - accuracy: 0.6432\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.3174 - accuracy: 0.8685\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.5165 - accuracy: 0.7664\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.8667 - accuracy: 0.7009\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.4129 - accuracy: 0.8404\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.4239 - accuracy: 0.8028\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.4299 - accuracy: 0.7887\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.2878 - accuracy: 0.8738\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.6061 - accuracy: 0.7418\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.4663 - accuracy: 0.7700\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 28/50\n",
      "27/27 - 1s - loss: 0.5169 - accuracy: 0.7850\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.5506 - accuracy: 0.7383\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.3514 - accuracy: 0.8075\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 40/50\n",
      "27/27 - 1s - loss: 0.4620 - accuracy: 0.7512\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.3855 - accuracy: 0.8310\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.5452 - accuracy: 0.7700\n",
      "Epoch 29/50\n",
      "27/27 - 0s - loss: 0.5033 - accuracy: 0.7477\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.3540 - accuracy: 0.8263\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.4453 - accuracy: 0.8271\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.4217 - accuracy: 0.7981\n",
      "Epoch 41/50\n",
      "27/27 - 1s - loss: 0.4601 - accuracy: 0.7653\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.5093 - accuracy: 0.7290\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.4720 - accuracy: 0.7746\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.3067 - accuracy: 0.8638\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.5239 - accuracy: 0.7150\n",
      "Epoch 12/50\n",
      "27/27 - 0s - loss: 0.3706 - accuracy: 0.8263\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.4531 - accuracy: 0.7700\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.4629 - accuracy: 0.7700\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.5075 - accuracy: 0.7430\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.2428 - accuracy: 0.8738\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.5362 - accuracy: 0.6948\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.2517 - accuracy: 0.8732\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.5108 - accuracy: 0.7290\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.3667 - accuracy: 0.8263\n",
      "Epoch 43/50\n",
      "27/27 - 0s - loss: 0.4491 - accuracy: 0.7746\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.6370 - accuracy: 0.7430\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.3845 - accuracy: 0.8028\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.5177 - accuracy: 0.7336\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.4461 - accuracy: 0.8075\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 44/50\n",
      "27/27 - 0s - loss: 0.4106 - accuracy: 0.7887\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.3479 - accuracy: 0.8598\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.2881 - accuracy: 0.8873\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.3317 - accuracy: 0.8404\n",
      "Epoch 11/50\n",
      "27/27 - 0s - loss: 0.4546 - accuracy: 0.7746\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.4784 - accuracy: 0.7570\n",
      "Epoch 15/50\n",
      "27/27 - 0s - loss: 0.2949 - accuracy: 0.8545\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.4292 - accuracy: 0.7887\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.4798 - accuracy: 0.7477\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.3131 - accuracy: 0.8826\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.2525 - accuracy: 0.8920\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.4134 - accuracy: 0.7700\n",
      "Epoch 16/50\n",
      "27/27 - 0s - loss: 0.3128 - accuracy: 0.8779\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.4197 - accuracy: 0.8551\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.4240 - accuracy: 0.8075\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.3691 - accuracy: 0.7897\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.5136 - accuracy: 0.7430\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.4394 - accuracy: 0.7840\n",
      "Epoch 17/50\n",
      "27/27 - 1s - loss: 0.3510 - accuracy: 0.8545\n",
      "Epoch 10/50\n",
      "27/27 - 0s - loss: 0.4734 - accuracy: 0.7850\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.4939 - accuracy: 0.7617\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.2651 - accuracy: 0.8738\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.2462 - accuracy: 0.9108\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.4076 - accuracy: 0.8028\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.1940 - accuracy: 0.9014\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.2792 - accuracy: 0.8732\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.3367 - accuracy: 0.8498\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.4797 - accuracy: 0.7477\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.4767 - accuracy: 0.7710\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.4251 - accuracy: 0.7981\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.2339 - accuracy: 0.9112\n",
      "Epoch 37/50\n",
      "27/27 - 0s - loss: 0.4927 - accuracy: 0.7336\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.2332 - accuracy: 0.8967\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.2054 - accuracy: 0.9249\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.3135 - accuracy: 0.8451\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.4172 - accuracy: 0.8224\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.4103 - accuracy: 0.8028\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.3680 - accuracy: 0.8357\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.5495 - accuracy: 0.6963\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.2063 - accuracy: 0.9202\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.2095 - accuracy: 0.8832\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.4400 - accuracy: 0.7934\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.2476 - accuracy: 0.8873\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.4016 - accuracy: 0.8131\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.3956 - accuracy: 0.8404\n",
      "Epoch 39/50\n",
      "27/27 - 0s - loss: 0.5126 - accuracy: 0.7290\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.3209 - accuracy: 0.8498\n",
      "Epoch 17/50\n",
      "27/27 - 0s - loss: 0.3576 - accuracy: 0.8357\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.2443 - accuracy: 0.8967\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.5035 - accuracy: 0.7570\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.3564 - accuracy: 0.8364\n",
      "Epoch 21/50\n",
      "27/27 - 1s - loss: 0.3846 - accuracy: 0.8216\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.1672 - accuracy: 0.9393\n",
      "14/14 - 1s - loss: 0.5753 - accuracy: 0.7196\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.3217 - accuracy: 0.8545\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.2801 - accuracy: 0.9061\n",
      "Epoch 15/50\n",
      "27/27 - 0s - loss: 0.2852 - accuracy: 0.8551\n",
      "Epoch 22/50\n",
      "27/27 - 0s - loss: 0.2832 - accuracy: 0.8920\n",
      "Epoch 41/50\n",
      "27/27 - 1s - loss: 0.5420 - accuracy: 0.7009\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.1997 - accuracy: 0.8925\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.2476 - accuracy: 0.8873\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.2315 - accuracy: 0.8920\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.3297 - accuracy: 0.8404\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.2955 - accuracy: 0.8692\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.4920 - accuracy: 0.7570\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.2330 - accuracy: 0.8967\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.2943 - accuracy: 0.8404\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.1304 - accuracy: 0.9533\n",
      "Epoch 17/50\n",
      "27/27 - 0s - loss: 0.3743 - accuracy: 0.8178\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.2628 - accuracy: 0.8638\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.1948 - accuracy: 0.9061\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.5282 - accuracy: 0.7477\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.2790 - accuracy: 0.8685\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.3712 - accuracy: 0.8263\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.4051 - accuracy: 0.8458\n",
      "Epoch 21/50\n",
      "27/27 - 1s - loss: 0.2676 - accuracy: 0.8685\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.1330 - accuracy: 0.9486\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.1906 - accuracy: 0.9155\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.4772 - accuracy: 0.7477\n",
      "Epoch 19/50\n",
      "27/27 - 0s - loss: 0.3558 - accuracy: 0.8364\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.2022 - accuracy: 0.8967\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.2945 - accuracy: 0.8685\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.2523 - accuracy: 0.8779\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.1625 - accuracy: 0.9202\n",
      "Epoch 20/50\n",
      "27/27 - 0s - loss: 0.3386 - accuracy: 0.8411\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.5205 - accuracy: 0.7243\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.1328 - accuracy: 0.9252\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.2263 - accuracy: 0.8967\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.2273 - accuracy: 0.8967\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.4878 - accuracy: 0.7710\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.1459 - accuracy: 0.9249\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 21/50\n",
      "27/27 - 1s - loss: 0.2197 - accuracy: 0.9206\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.2103 - accuracy: 0.8920\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.2705 - accuracy: 0.8779\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.2516 - accuracy: 0.8920\n",
      "Epoch 47/50\n",
      "27/27 - 0s - loss: 0.4912 - accuracy: 0.7664\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.1921 - accuracy: 0.9299\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.3723 - accuracy: 0.8404\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.4812 - accuracy: 0.7430\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.2133 - accuracy: 0.9112\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.3232 - accuracy: 0.8451\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.1550 - accuracy: 0.9484\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.1641 - accuracy: 0.9155\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.5303 - accuracy: 0.7196\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.2228 - accuracy: 0.9019\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.3692 - accuracy: 0.8545\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.2316 - accuracy: 0.8972\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.2209 - accuracy: 0.9014\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.1257 - accuracy: 0.9531\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.1739 - accuracy: 0.9202\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.1727 - accuracy: 0.9531\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.5085 - accuracy: 0.7710\n",
      "Epoch 24/50\n",
      "27/27 - 1s - loss: 0.2275 - accuracy: 0.9112\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.1583 - accuracy: 0.9019\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.1838 - accuracy: 0.9014\n",
      "Epoch 25/50\n",
      "27/27 - 0s - loss: 0.1781 - accuracy: 0.9159\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.2617 - accuracy: 0.8967\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.1163 - accuracy: 0.9531\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.1199 - accuracy: 0.9486\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.0997 - accuracy: 0.9437\n",
      "Epoch 32/50\n",
      "27/27 - 1s - loss: 0.2477 - accuracy: 0.8967\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 26/50\n",
      "27/27 - 0s - loss: 0.1695 - accuracy: 0.9206\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.2996 - accuracy: 0.8779\n",
      "Epoch 33/50\n",
      "27/27 - 0s - loss: 0.1698 - accuracy: 0.9343\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.0824 - accuracy: 0.9673\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.1148 - accuracy: 0.9577\n",
      "Epoch 27/50\n",
      "27/27 - 0s - loss: 0.1559 - accuracy: 0.9252\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.0808 - accuracy: 0.9624\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.2203 - accuracy: 0.9061\n",
      "14/14 - 1s - loss: 0.5368 - accuracy: 0.7264\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.1898 - accuracy: 0.9249\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.1757 - accuracy: 0.9159\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.2112 - accuracy: 0.9249\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.1415 - accuracy: 0.9439\n",
      "Epoch 1/50\n",
      "27/27 - 5s - loss: 0.9167 - accuracy: 0.4225\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.2213 - accuracy: 0.9202\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.1101 - accuracy: 0.9671\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.2153 - accuracy: 0.9014\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.1744 - accuracy: 0.9252\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.1629 - accuracy: 0.9484\n",
      "Epoch 2/50\n",
      "27/27 - 0s - loss: 0.8705 - accuracy: 0.6103\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 32/50\n",
      "27/27 - 1s - loss: 0.1965 - accuracy: 0.8732\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.0906 - accuracy: 0.9720\n",
      "Epoch 3/50\n",
      "27/27 - 0s - loss: 0.7936 - accuracy: 0.5399\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.2101 - accuracy: 0.9249\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.1975 - accuracy: 0.9252\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.0686 - accuracy: 0.9671\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.0732 - accuracy: 0.9718\n",
      "Epoch 4/50\n",
      "27/27 - 0s - loss: 0.6637 - accuracy: 0.6197\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.1068 - accuracy: 0.9673\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.1930 - accuracy: 0.9577\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.1748 - accuracy: 0.9249\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.1517 - accuracy: 0.9393\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.0852 - accuracy: 0.9624\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.7832 - accuracy: 0.6056\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.1703 - accuracy: 0.9343\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.0557 - accuracy: 0.9813\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.1790 - accuracy: 0.9112\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.1650 - accuracy: 0.9390\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.1866 - accuracy: 0.9155\n",
      "Epoch 6/50\n",
      "27/27 - 0s - loss: 0.5354 - accuracy: 0.6995\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.0789 - accuracy: 0.9531\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.1437 - accuracy: 0.9202\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.1620 - accuracy: 0.9439\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.1692 - accuracy: 0.9108\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.1201 - accuracy: 0.9579\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.1366 - accuracy: 0.9531\n",
      "Epoch 36/50\n",
      "27/27 - 0s - loss: 0.1256 - accuracy: 0.9343\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.6966 - accuracy: 0.6808\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.1631 - accuracy: 0.9296\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.0858 - accuracy: 0.9718\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.1688 - accuracy: 0.9299\n",
      "Epoch 37/50\n",
      "27/27 - 0s - loss: 0.0780 - accuracy: 0.9671\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.0688 - accuracy: 0.9720\n",
      "Epoch 41/50\n",
      "27/27 - 0s - loss: 0.1853 - accuracy: 0.9061\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.1846 - accuracy: 0.9014\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.5842 - accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "27/27 - 0s - loss: 0.1996 - accuracy: 0.9061\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.1631 - accuracy: 0.9299\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.0470 - accuracy: 0.9906\n",
      "Epoch 39/50\n",
      "27/27 - 0s - loss: 0.1503 - accuracy: 0.9390\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.1819 - accuracy: 0.9437\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.0505 - accuracy: 0.9860\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.6129 - accuracy: 0.6808\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.1369 - accuracy: 0.9346\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.1179 - accuracy: 0.9577\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.0759 - accuracy: 0.9718\n",
      "Epoch 37/50\n",
      "27/27 - 0s - loss: 0.1477 - accuracy: 0.9252\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.1216 - accuracy: 0.9579\n",
      "Epoch 40/50\n",
      "27/27 - 1s - loss: 0.1598 - accuracy: 0.9202\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.5797 - accuracy: 0.7136\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.0870 - accuracy: 0.9577\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.1187 - accuracy: 0.9531\n",
      "Epoch 41/50\n",
      "27/27 - 1s - loss: 0.1711 - accuracy: 0.9484\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.0488 - accuracy: 0.9671\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.1143 - accuracy: 0.9626\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.7105 - accuracy: 0.6150\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.1199 - accuracy: 0.9437\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.1080 - accuracy: 0.9439\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.1407 - accuracy: 0.9437\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.1362 - accuracy: 0.9296\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.1090 - accuracy: 0.9439\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.1082 - accuracy: 0.9484\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.0693 - accuracy: 0.9671\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.5282 - accuracy: 0.7465\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.0606 - accuracy: 0.9673\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.1187 - accuracy: 0.9720\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.1649 - accuracy: 0.9155\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.0902 - accuracy: 0.9718\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.0871 - accuracy: 0.9577\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.5078 - accuracy: 0.7793\n",
      "Epoch 41/50\n",
      "27/27 - 0s - loss: 0.0915 - accuracy: 0.9533\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.0926 - accuracy: 0.9671\n",
      "Epoch 47/50\n",
      "27/27 - 0s - loss: 0.1393 - accuracy: 0.9484\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.0481 - accuracy: 0.9860\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.0799 - accuracy: 0.9718\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.5214 - accuracy: 0.7042\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.1024 - accuracy: 0.9577\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.0562 - accuracy: 0.9671\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.1902 - accuracy: 0.9439\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.1011 - accuracy: 0.9765\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.1527 - accuracy: 0.9484\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.0411 - accuracy: 0.9860\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.0931 - accuracy: 0.9531\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.5371 - accuracy: 0.7418\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.1238 - accuracy: 0.9718\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.1057 - accuracy: 0.9579\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.0874 - accuracy: 0.9624\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.0752 - accuracy: 0.9718\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.0552 - accuracy: 0.9813\n",
      "Epoch 1/50\n",
      "27/27 - 7s - loss: 0.9543 - accuracy: 0.5117\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.1399 - accuracy: 0.9624\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.4986 - accuracy: 0.7324\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.1037 - accuracy: 0.9484\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.0885 - accuracy: 0.9673\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.0712 - accuracy: 0.9671\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.8642 - accuracy: 0.5352\n",
      "Epoch 17/50\n",
      "27/27 - 0s - loss: 0.5449 - accuracy: 0.7324\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.0464 - accuracy: 0.9720\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.0879 - accuracy: 0.9624\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.7349 - accuracy: 0.5915\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.0875 - accuracy: 0.9577\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.4668 - accuracy: 0.7746\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.1115 - accuracy: 0.9626\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.1418 - accuracy: 0.9906\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.0911 - accuracy: 0.9577\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.0554 - accuracy: 0.9860\n",
      "Epoch 4/50\n",
      "27/27 - 0s - loss: 0.7639 - accuracy: 0.5962\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.1458 - accuracy: 0.9346\n",
      "14/14 - 1s - loss: 0.4759 - accuracy: 0.7944\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.5037 - accuracy: 0.7512\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.1258 - accuracy: 0.9577\n",
      "Epoch 5/50\n",
      "27/27 - 0s - loss: 0.7007 - accuracy: 0.6479\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.0762 - accuracy: 0.9718\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.0723 - accuracy: 0.9766\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.0875 - accuracy: 0.9531\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.0768 - accuracy: 0.9718\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.4395 - accuracy: 0.7793\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.0422 - accuracy: 0.9813\n",
      "Epoch 6/50\n",
      "27/27 - 0s - loss: 0.6717 - accuracy: 0.6479\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.4806 - accuracy: 0.7512\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.1200 - accuracy: 0.9531\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.1692 - accuracy: 0.9346\n",
      "Epoch 7/50\n",
      "27/27 - 0s - loss: 0.6512 - accuracy: 0.6432\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.0694 - accuracy: 0.9671\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.0499 - accuracy: 0.9720\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 22/50\n",
      "27/27 - 0s - loss: 0.5352 - accuracy: 0.7230\n",
      "Epoch 8/50\n",
      "27/27 - 0s - loss: 0.6084 - accuracy: 0.7042\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.1238 - accuracy: 0.9486\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.0757 - accuracy: 0.9624\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.4302 - accuracy: 0.7746\n",
      "14/14 - 1s - loss: 0.4168 - accuracy: 0.8505\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.1003 - accuracy: 0.9439\n",
      "Epoch 9/50\n",
      "27/27 - 0s - loss: 0.5705 - accuracy: 0.6901\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.0301 - accuracy: 0.9953\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.1000 - accuracy: 0.9673\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.4677 - accuracy: 0.7606\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.0540 - accuracy: 0.9859\n",
      "Epoch 10/50\n",
      "27/27 - 0s - loss: 0.5551 - accuracy: 0.6948\n",
      "Epoch 25/50\n",
      "27/27 - 0s - loss: 0.4887 - accuracy: 0.7840\n",
      "Epoch 49/50\n",
      "54/54 - 0s - loss: 0.0849 - accuracy: 0.9626\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.0930 - accuracy: 0.9765\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.0322 - accuracy: 0.9859\n",
      "Epoch 11/50\n",
      "27/27 - 0s - loss: 0.5895 - accuracy: 0.6714\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 50/50\n",
      "54/54 - 0s - loss: 0.0592 - accuracy: 0.9766\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.4444 - accuracy: 0.7653\n",
      "Epoch 12/50\n",
      "27/27 - 0s - loss: 0.6120 - accuracy: 0.6948\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.0783 - accuracy: 0.9671\n",
      "14/14 - 1s - loss: 0.4991 - accuracy: 0.7925\n",
      "Epoch 27/50\n",
      "27/27 - 0s - loss: 0.4575 - accuracy: 0.7465\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.0295 - accuracy: 0.9906\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 13/50\n",
      "27/27 - 0s - loss: 0.5493 - accuracy: 0.7277\n",
      "27/27 - 1s - loss: 0.6467 - accuracy: 0.8208\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.5341 - accuracy: 0.7465\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.1183 - accuracy: 0.9484\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.0291 - accuracy: 0.9906\n",
      "Epoch 29/50\n",
      "27/27 - 0s - loss: 0.4912 - accuracy: 0.7512\n",
      "Epoch 14/50\n",
      "27/27 - 0s - loss: 0.5493 - accuracy: 0.7418\n",
      "Epoch 49/50\n",
      "54/54 - 0s - loss: 0.0631 - accuracy: 0.9859\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 30/50\n",
      "27/27 - 0s - loss: 0.4749 - accuracy: 0.7606\n",
      "Epoch 15/50\n",
      "27/27 - 0s - loss: 0.6165 - accuracy: 0.6667\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 50/50\n",
      "54/54 - 0s - loss: 0.0718 - accuracy: 0.9859\n",
      "Epoch 31/50\n",
      "27/27 - 0s - loss: 0.4126 - accuracy: 0.7746\n",
      "27/27 - 1s - loss: 0.5529 - accuracy: 0.8224\n",
      "Epoch 16/50\n",
      "27/27 - 0s - loss: 0.5114 - accuracy: 0.7042\n",
      "Epoch 1/50\n",
      "27/27 - 3s - loss: 0.8109 - accuracy: 0.5467\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.4469 - accuracy: 0.7559\n",
      "Epoch 17/50\n",
      "27/27 - 0s - loss: 0.5138 - accuracy: 0.7700\n",
      "Epoch 2/50\n",
      "27/27 - 0s - loss: 0.8243 - accuracy: 0.5888\n",
      "Epoch 33/50\n",
      "27/27 - 0s - loss: 0.5377 - accuracy: 0.7371\n",
      "27/27 - 1s - loss: 0.5025 - accuracy: 0.8224\n",
      "Epoch 18/50\n",
      "27/27 - 0s - loss: 0.5008 - accuracy: 0.7512\n",
      "Epoch 3/50\n",
      "27/27 - 0s - loss: 0.7268 - accuracy: 0.5748\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 34/50\n",
      "27/27 - 0s - loss: 0.4985 - accuracy: 0.7559\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 1.5331 - accuracy: 0.4225\n",
      "Epoch 4/50\n",
      "27/27 - 0s - loss: 0.6256 - accuracy: 0.5467\n",
      "Epoch 19/50\n",
      "27/27 - 0s - loss: 0.5531 - accuracy: 0.7277\n",
      "Epoch 35/50\n",
      "27/27 - 0s - loss: 0.4494 - accuracy: 0.7653\n",
      "Epoch 5/50\n",
      "27/27 - 0s - loss: 0.7245 - accuracy: 0.6215\n",
      "Epoch 2/50\n",
      "54/54 - 0s - loss: 1.0466 - accuracy: 0.5117\n",
      "Epoch 20/50\n",
      "27/27 - 0s - loss: 0.5256 - accuracy: 0.7512\n",
      "Epoch 36/50\n",
      "27/27 - 0s - loss: 0.4342 - accuracy: 0.7653\n",
      "Epoch 6/50\n",
      "27/27 - 0s - loss: 0.6104 - accuracy: 0.6916\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.4919 - accuracy: 0.7512\n",
      "Epoch 3/50\n",
      "54/54 - 0s - loss: 0.9715 - accuracy: 0.5915\n",
      "Epoch 37/50\n",
      "27/27 - 0s - loss: 0.4671 - accuracy: 0.8075\n",
      "Epoch 7/50\n",
      "27/27 - 0s - loss: 0.5912 - accuracy: 0.6308\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 22/50\n",
      "27/27 - 0s - loss: 0.5104 - accuracy: 0.7183\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 1.4007 - accuracy: 0.5211\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 1.0361 - accuracy: 0.5540\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 1.5420 - accuracy: 0.4626\n",
      "Epoch 38/50\n",
      "27/27 - 0s - loss: 0.4209 - accuracy: 0.7934\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.5526 - accuracy: 0.7196\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.5502 - accuracy: 0.7277\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.8444 - accuracy: 0.5775\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 1.2000 - accuracy: 0.5352\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.4388 - accuracy: 0.7793\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 1.2922 - accuracy: 0.5654\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.4710 - accuracy: 0.7465\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.5686 - accuracy: 0.6355\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.4172 - accuracy: 0.7840\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.8204 - accuracy: 0.5962\n",
      "Epoch 10/50\n",
      "27/27 - 0s - loss: 0.5752 - accuracy: 0.7290\n",
      "Epoch 25/50\n",
      "27/27 - 0s - loss: 0.4852 - accuracy: 0.7653\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 1.1486 - accuracy: 0.5187\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 1.3541 - accuracy: 0.4554\n",
      "Epoch 41/50\n",
      "27/27 - 0s - loss: 0.4665 - accuracy: 0.7700\n",
      "Epoch 11/50\n",
      "27/27 - 0s - loss: 0.5062 - accuracy: 0.7477\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.7726 - accuracy: 0.6338\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.4989 - accuracy: 0.7371\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.9558 - accuracy: 0.6355\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 1.0271 - accuracy: 0.5915\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.4458 - accuracy: 0.8075\n",
      "Epoch 12/50\n",
      "27/27 - 0s - loss: 0.5036 - accuracy: 0.7243\n",
      "Epoch 27/50\n",
      "27/27 - 0s - loss: 0.4841 - accuracy: 0.7559\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.9688 - accuracy: 0.5962\n",
      "Epoch 43/50\n",
      "27/27 - 0s - loss: 0.4687 - accuracy: 0.7746\n",
      "Epoch 13/50\n",
      "27/27 - 0s - loss: 0.5161 - accuracy: 0.7570\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 1.1636 - accuracy: 0.5514\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.9827 - accuracy: 0.5915\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.5140 - accuracy: 0.7465\n",
      "Epoch 44/50\n",
      "27/27 - 0s - loss: 0.4605 - accuracy: 0.8075\n",
      "Epoch 14/50\n",
      "27/27 - 0s - loss: 0.5457 - accuracy: 0.6869\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.7111 - accuracy: 0.6526\n",
      "Epoch 29/50\n",
      "27/27 - 0s - loss: 0.5327 - accuracy: 0.7324\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 1.1144 - accuracy: 0.5514\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.9567 - accuracy: 0.6150\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.4394 - accuracy: 0.8075\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.4259 - accuracy: 0.7850\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.7830 - accuracy: 0.6995\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 30/50\n",
      "27/27 - 0s - loss: 0.4872 - accuracy: 0.7793\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.3901 - accuracy: 0.7887\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.8836 - accuracy: 0.6215\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.9075 - accuracy: 0.6291\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.4704 - accuracy: 0.7383\n",
      "Epoch 31/50\n",
      "27/27 - 0s - loss: 0.5134 - accuracy: 0.7653\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.8395 - accuracy: 0.6620\n",
      "Epoch 47/50\n",
      "27/27 - 0s - loss: 0.4897 - accuracy: 0.8028\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.8587 - accuracy: 0.6168\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.6596 - accuracy: 0.6573\n",
      "Epoch 17/50\n",
      "27/27 - 1s - loss: 0.4684 - accuracy: 0.8037\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.4800 - accuracy: 0.7136\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.4454 - accuracy: 0.7559\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.6895 - accuracy: 0.6948\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.9061 - accuracy: 0.7150\n",
      "Epoch 18/50\n",
      "27/27 - 0s - loss: 0.4450 - accuracy: 0.7570\n",
      "Epoch 33/50\n",
      "27/27 - 0s - loss: 0.5481 - accuracy: 0.7277\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.4324 - accuracy: 0.8122\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.8825 - accuracy: 0.6197\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.7756 - accuracy: 0.7183\n",
      "Epoch 34/50\n",
      "27/27 - 0s - loss: 0.5270 - accuracy: 0.7277\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.9026 - accuracy: 0.6729\n",
      "Epoch 19/50\n",
      "27/27 - 0s - loss: 0.3950 - accuracy: 0.8224\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.4538 - accuracy: 0.7606\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.7825 - accuracy: 0.6714\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 35/50\n",
      "27/27 - 0s - loss: 0.5472 - accuracy: 0.7559\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.6510 - accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "27/27 - 0s - loss: 0.3835 - accuracy: 0.8037\n",
      "Epoch 36/50\n",
      "27/27 - 0s - loss: 0.4903 - accuracy: 0.7277\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.6853 - accuracy: 0.7009\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.8554 - accuracy: 0.6385\n",
      "Epoch 15/50\n",
      "54/54 - 0s - loss: 0.5658 - accuracy: 0.7183\n",
      "Epoch 37/50\n",
      "27/27 - 0s - loss: 0.4549 - accuracy: 0.7793\n",
      "Epoch 21/50\n",
      "27/27 - 0s - loss: 0.4707 - accuracy: 0.7710\n",
      "14/14 - 1s - loss: 0.5160 - accuracy: 0.7383\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.8142 - accuracy: 0.6338\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.9147 - accuracy: 0.6589\n",
      "Epoch 38/50\n",
      "27/27 - 0s - loss: 0.5743 - accuracy: 0.7371\n",
      "Epoch 22/50\n",
      "27/27 - 0s - loss: 0.3784 - accuracy: 0.8224\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.7597 - accuracy: 0.6620\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 39/50\n",
      "27/27 - 0s - loss: 0.5669 - accuracy: 0.7606\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.7660 - accuracy: 0.6197\n",
      "Epoch 23/50\n",
      "27/27 - 0s - loss: 0.4362 - accuracy: 0.8131\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.7409 - accuracy: 0.6589\n",
      "Epoch 17/50\n",
      "54/54 - 0s - loss: 0.5978 - accuracy: 0.6573\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.5578 - accuracy: 0.7230\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 24/50\n",
      "27/27 - 0s - loss: 0.4077 - accuracy: 0.7897\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.6357 - accuracy: 0.7136\n",
      "Epoch 41/50\n",
      "27/27 - 0s - loss: 0.4455 - accuracy: 0.7606\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.7550 - accuracy: 0.6495\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.5808 - accuracy: 0.6995\n",
      "Epoch 25/50\n",
      "27/27 - 0s - loss: 0.3631 - accuracy: 0.8458\n",
      "Epoch 42/50\n",
      "27/27 - 0s - loss: 0.5121 - accuracy: 0.7230\n",
      "Epoch 15/50\n",
      "54/54 - 0s - loss: 0.6880 - accuracy: 0.7009\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.7025 - accuracy: 0.7183\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.5301 - accuracy: 0.7418\n",
      "Epoch 26/50\n",
      "27/27 - 0s - loss: 0.3698 - accuracy: 0.8364\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 43/50\n",
      "27/27 - 0s - loss: 0.5200 - accuracy: 0.7606\n",
      "Epoch 16/50\n",
      "54/54 - 0s - loss: 0.6698 - accuracy: 0.7056\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.6203 - accuracy: 0.7230\n",
      "Epoch 27/50\n",
      "27/27 - 0s - loss: 0.4151 - accuracy: 0.8318\n",
      "Epoch 20/50\n",
      "54/54 - 0s - loss: 0.5861 - accuracy: 0.6901\n",
      "Epoch 44/50\n",
      "27/27 - 0s - loss: 0.4713 - accuracy: 0.7793\n",
      "Epoch 28/50\n",
      "27/27 - 0s - loss: 0.3653 - accuracy: 0.8224\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.7963 - accuracy: 0.6916\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.4847 - accuracy: 0.7512\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.6457 - accuracy: 0.6854\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.5199 - accuracy: 0.7324\n",
      "Epoch 29/50\n",
      "27/27 - 0s - loss: 0.3541 - accuracy: 0.8458\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.4767 - accuracy: 0.7746\n",
      "Epoch 18/50\n",
      "54/54 - 0s - loss: 0.6214 - accuracy: 0.7277\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.8528 - accuracy: 0.6916\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 30/50\n",
      "27/27 - 0s - loss: 0.3573 - accuracy: 0.8458\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.5660 - accuracy: 0.7183\n",
      "Epoch 47/50\n",
      "27/27 - 0s - loss: 0.4822 - accuracy: 0.7559\n",
      "Epoch 19/50\n",
      "54/54 - 0s - loss: 0.6413 - accuracy: 0.6948\n",
      "Epoch 19/50\n",
      "54/54 - 0s - loss: 0.6260 - accuracy: 0.6916\n",
      "Epoch 31/50\n",
      "27/27 - 0s - loss: 0.3583 - accuracy: 0.8318\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.5898 - accuracy: 0.6714\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.5266 - accuracy: 0.7606\n",
      "Epoch 20/50\n",
      "54/54 - 0s - loss: 0.7615 - accuracy: 0.6620\n",
      "Epoch 32/50\n",
      "27/27 - 0s - loss: 0.3359 - accuracy: 0.8318\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.7045 - accuracy: 0.6963\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 24/50\n",
      "54/54 - 0s - loss: 0.6237 - accuracy: 0.6620\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.5150 - accuracy: 0.7324\n",
      "Epoch 33/50\n",
      "27/27 - 0s - loss: 0.3751 - accuracy: 0.8224\n",
      "Epoch 21/50\n",
      "54/54 - 0s - loss: 0.6844 - accuracy: 0.6526\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.4891 - accuracy: 0.7371\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.6806 - accuracy: 0.6589\n",
      "Epoch 25/50\n",
      "54/54 - 0s - loss: 0.5022 - accuracy: 0.7371\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 34/50\n",
      "27/27 - 0s - loss: 0.3931 - accuracy: 0.8131\n",
      "Epoch 22/50\n",
      "54/54 - 0s - loss: 0.5764 - accuracy: 0.7512\n",
      "Epoch 35/50\n",
      "27/27 - 0s - loss: 0.3658 - accuracy: 0.8224\n",
      "14/14 - 0s - loss: 0.4918 - accuracy: 0.7944\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.6008 - accuracy: 0.7336\n",
      "Epoch 26/50\n",
      "54/54 - 0s - loss: 0.5172 - accuracy: 0.7418\n",
      "Epoch 36/50\n",
      "27/27 - 0s - loss: 0.3694 - accuracy: 0.7944\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.6321 - accuracy: 0.6808\n",
      "Epoch 23/50\n",
      "54/54 - 0s - loss: 0.6145 - accuracy: 0.7196\n",
      "Epoch 27/50\n",
      "54/54 - 0s - loss: 0.5999 - accuracy: 0.7089\n",
      "Epoch 37/50\n",
      "27/27 - 0s - loss: 0.3605 - accuracy: 0.8224\n",
      "Epoch 24/50\n",
      "54/54 - 0s - loss: 0.5367 - accuracy: 0.7606\n",
      "Epoch 24/50\n",
      "54/54 - 0s - loss: 0.7632 - accuracy: 0.6776\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 38/50\n",
      "27/27 - 0s - loss: 0.3443 - accuracy: 0.8318\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 28/50\n",
      "54/54 - 0s - loss: 0.6043 - accuracy: 0.7089\n",
      "Epoch 25/50\n",
      "54/54 - 0s - loss: 0.6537 - accuracy: 0.7042\n",
      "Epoch 39/50\n",
      "27/27 - 0s - loss: 0.4049 - accuracy: 0.7944\n",
      "Epoch 25/50\n",
      "54/54 - 0s - loss: 0.6112 - accuracy: 0.7243\n",
      "Epoch 29/50\n",
      "54/54 - 0s - loss: 0.5512 - accuracy: 0.6808\n",
      "Epoch 40/50\n",
      "27/27 - 0s - loss: 0.3396 - accuracy: 0.8551\n",
      "Epoch 26/50\n",
      "54/54 - 0s - loss: 0.5646 - accuracy: 0.7371\n",
      "Epoch 26/50\n",
      "54/54 - 0s - loss: 0.7536 - accuracy: 0.6636\n",
      "Epoch 41/50\n",
      "27/27 - 0s - loss: 0.3842 - accuracy: 0.7897\n",
      "Epoch 30/50\n",
      "54/54 - 0s - loss: 0.4656 - accuracy: 0.7934\n",
      "Epoch 27/50\n",
      "54/54 - 0s - loss: 0.5473 - accuracy: 0.7089\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 27/50\n",
      "54/54 - 0s - loss: 0.6258 - accuracy: 0.7336\n",
      "Epoch 42/50\n",
      "27/27 - 0s - loss: 0.3708 - accuracy: 0.8084\n",
      "Epoch 31/50\n",
      "54/54 - 0s - loss: 0.5197 - accuracy: 0.7465\n",
      "Epoch 43/50\n",
      "27/27 - 0s - loss: 0.3332 - accuracy: 0.8645\n",
      "Epoch 28/50\n",
      "54/54 - 0s - loss: 0.5404 - accuracy: 0.7136\n",
      "Epoch 28/50\n",
      "54/54 - 0s - loss: 0.6697 - accuracy: 0.7243\n",
      "Epoch 32/50\n",
      "54/54 - 0s - loss: 0.6290 - accuracy: 0.7277\n",
      "Epoch 44/50\n",
      "27/27 - 0s - loss: 0.3585 - accuracy: 0.8224\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 29/50\n",
      "54/54 - 0s - loss: 0.5327 - accuracy: 0.7465\n",
      "Epoch 29/50\n",
      "54/54 - 0s - loss: 0.7461 - accuracy: 0.6822\n",
      "Epoch 45/50\n",
      "27/27 - 0s - loss: 0.3166 - accuracy: 0.8178\n",
      "Epoch 33/50\n",
      "54/54 - 0s - loss: 0.5051 - accuracy: 0.7512\n",
      "Epoch 30/50\n",
      "54/54 - 0s - loss: 0.5192 - accuracy: 0.7512\n",
      "Epoch 30/50\n",
      "54/54 - 0s - loss: 0.6344 - accuracy: 0.7196\n",
      "Epoch 46/50\n",
      "27/27 - 0s - loss: 0.3412 - accuracy: 0.8505\n",
      "Epoch 34/50\n",
      "54/54 - 0s - loss: 0.5359 - accuracy: 0.7277\n",
      "Epoch 47/50\n",
      "27/27 - 0s - loss: 0.3274 - accuracy: 0.8271\n",
      "Epoch 31/50\n",
      "54/54 - 0s - loss: 0.5668 - accuracy: 0.7042\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 31/50\n",
      "54/54 - 0s - loss: 0.5719 - accuracy: 0.7056\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 35/50\n",
      "54/54 - 0s - loss: 0.4914 - accuracy: 0.7606\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 48/50\n",
      "27/27 - 0s - loss: 0.3188 - accuracy: 0.8738\n",
      "Epoch 32/50\n",
      "54/54 - 0s - loss: 0.4822 - accuracy: 0.7793\n",
      "Epoch 32/50\n",
      "54/54 - 0s - loss: 0.6112 - accuracy: 0.7150\n",
      "Epoch 49/50\n",
      "27/27 - 0s - loss: 0.3086 - accuracy: 0.8738\n",
      "Epoch 36/50\n",
      "54/54 - 0s - loss: 0.4903 - accuracy: 0.7559\n",
      "Epoch 33/50\n",
      "54/54 - 0s - loss: 0.4787 - accuracy: 0.7606\n",
      "Epoch 50/50\n",
      "27/27 - 0s - loss: 0.3629 - accuracy: 0.7897\n",
      "Epoch 33/50\n",
      "54/54 - 0s - loss: 0.6852 - accuracy: 0.7150\n",
      "Epoch 37/50\n",
      "54/54 - 0s - loss: 0.5327 - accuracy: 0.6901\n",
      "14/14 - 0s - loss: 0.4667 - accuracy: 0.7642\n",
      "Epoch 34/50\n",
      "54/54 - 0s - loss: 0.5601 - accuracy: 0.7324\n",
      "Epoch 34/50\n",
      "54/54 - 0s - loss: 0.6600 - accuracy: 0.6869\n",
      "Epoch 38/50\n",
      "54/54 - 0s - loss: 0.5162 - accuracy: 0.7230\n",
      "Epoch 35/50\n",
      "54/54 - 0s - loss: 0.4836 - accuracy: 0.7887\n",
      "Epoch 35/50\n",
      "54/54 - 0s - loss: 0.6147 - accuracy: 0.7150\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 39/50\n",
      "54/54 - 0s - loss: 0.5701 - accuracy: 0.6854\n",
      "Epoch 36/50\n",
      "54/54 - 0s - loss: 0.5491 - accuracy: 0.7418\n",
      "Epoch 36/50\n",
      "54/54 - 0s - loss: 0.8303 - accuracy: 0.6869\n",
      "Epoch 40/50\n",
      "54/54 - 0s - loss: 0.4609 - accuracy: 0.7793\n",
      "Epoch 37/50\n",
      "54/54 - 0s - loss: 0.5737 - accuracy: 0.6995\n",
      "Epoch 37/50\n",
      "54/54 - 0s - loss: 0.5802 - accuracy: 0.7430\n",
      "Epoch 41/50\n",
      "54/54 - 0s - loss: 0.6049 - accuracy: 0.6901\n",
      "Epoch 38/50\n",
      "54/54 - 0s - loss: 0.5506 - accuracy: 0.7136\n",
      "Epoch 38/50\n",
      "54/54 - 0s - loss: 0.6544 - accuracy: 0.7243\n",
      "Epoch 42/50\n",
      "54/54 - 0s - loss: 0.5302 - accuracy: 0.7512\n",
      "Epoch 39/50\n",
      "54/54 - 0s - loss: 0.4642 - accuracy: 0.7371\n",
      "Epoch 39/50\n",
      "54/54 - 0s - loss: 0.7167 - accuracy: 0.6822\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 43/50\n",
      "54/54 - 0s - loss: 0.5393 - accuracy: 0.7418\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 40/50\n",
      "54/54 - 0s - loss: 0.4478 - accuracy: 0.7512\n",
      "Epoch 40/50\n",
      "54/54 - 0s - loss: 0.6824 - accuracy: 0.7196\n",
      "Epoch 44/50\n",
      "54/54 - 0s - loss: 0.6226 - accuracy: 0.7324\n",
      "Epoch 41/50\n",
      "54/54 - 0s - loss: 0.5781 - accuracy: 0.7324\n",
      "Epoch 41/50\n",
      "54/54 - 0s - loss: 0.6554 - accuracy: 0.7196\n",
      "Epoch 45/50\n",
      "54/54 - 0s - loss: 0.4706 - accuracy: 0.7559\n",
      "Epoch 42/50\n",
      "54/54 - 0s - loss: 0.4991 - accuracy: 0.7746\n",
      "Epoch 42/50\n",
      "54/54 - 0s - loss: 0.5527 - accuracy: 0.7336\n",
      "Epoch 46/50\n",
      "54/54 - 0s - loss: 0.5963 - accuracy: 0.6995\n",
      "Epoch 43/50\n",
      "54/54 - 0s - loss: 0.4714 - accuracy: 0.7324\n",
      "Epoch 43/50\n",
      "54/54 - 0s - loss: 0.6653 - accuracy: 0.6495\n",
      "Epoch 47/50\n",
      "54/54 - 0s - loss: 0.5934 - accuracy: 0.7465\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 44/50\n",
      "54/54 - 0s - loss: 0.4607 - accuracy: 0.7746\n",
      "Epoch 44/50\n",
      "54/54 - 0s - loss: 0.6340 - accuracy: 0.7056\n",
      "Epoch 48/50\n",
      "54/54 - 0s - loss: 0.5691 - accuracy: 0.7183\n",
      "Epoch 45/50\n",
      "54/54 - 0s - loss: 0.5957 - accuracy: 0.7559\n",
      "Epoch 45/50\n",
      "54/54 - 0s - loss: 0.5657 - accuracy: 0.7009\n",
      "Epoch 49/50\n",
      "54/54 - 0s - loss: 0.5259 - accuracy: 0.7371\n",
      "Epoch 46/50\n",
      "54/54 - 0s - loss: 0.4817 - accuracy: 0.7371\n",
      "Epoch 46/50\n",
      "54/54 - 0s - loss: 0.5346 - accuracy: 0.7336\n",
      "Epoch 50/50\n",
      "54/54 - 0s - loss: 0.5298 - accuracy: 0.7324\n",
      "Epoch 47/50\n",
      "54/54 - 0s - loss: 0.4134 - accuracy: 0.7934\n",
      "Epoch 47/50\n",
      "54/54 - 0s - loss: 0.6824 - accuracy: 0.7150\n",
      "27/27 - 0s - loss: 0.5339 - accuracy: 0.7103\n",
      "Epoch 48/50\n",
      "54/54 - 0s - loss: 0.4563 - accuracy: 0.8028\n",
      "Epoch 48/50\n",
      "54/54 - 0s - loss: 0.7047 - accuracy: 0.6776\n",
      "Epoch 49/50\n",
      "54/54 - 0s - loss: 0.4979 - accuracy: 0.7418\n",
      "Epoch 49/50\n",
      "54/54 - 0s - loss: 0.8506 - accuracy: 0.6308\n",
      "Epoch 50/50\n",
      "54/54 - 0s - loss: 0.4144 - accuracy: 0.7746\n",
      "Epoch 50/50\n",
      "54/54 - 0s - loss: 0.6292 - accuracy: 0.7336\n",
      "27/27 - 0s - loss: 0.5012 - accuracy: 0.7570\n",
      "27/27 - 0s - loss: 0.4946 - accuracy: 0.7453\n",
      "Epoch 1/50\n",
      "80/80 - 0s - loss: 1.1164 - accuracy: 0.5688\n",
      "Epoch 2/50\n",
      "80/80 - 0s - loss: 0.7506 - accuracy: 0.6594\n",
      "Epoch 3/50\n",
      "80/80 - 0s - loss: 0.5285 - accuracy: 0.7125\n",
      "Epoch 4/50\n",
      "80/80 - 0s - loss: 0.6695 - accuracy: 0.7094\n",
      "Epoch 5/50\n",
      "80/80 - 0s - loss: 0.5282 - accuracy: 0.7594\n",
      "Epoch 6/50\n",
      "80/80 - 0s - loss: 0.5067 - accuracy: 0.7812\n",
      "Epoch 7/50\n",
      "80/80 - 0s - loss: 0.5343 - accuracy: 0.7250\n",
      "Epoch 8/50\n",
      "80/80 - 0s - loss: 0.3663 - accuracy: 0.8469\n",
      "Epoch 9/50\n",
      "80/80 - 0s - loss: 0.4078 - accuracy: 0.8219\n",
      "Epoch 10/50\n",
      "80/80 - 0s - loss: 0.3688 - accuracy: 0.8188\n",
      "Epoch 11/50\n",
      "80/80 - 0s - loss: 0.4734 - accuracy: 0.7781\n",
      "Epoch 12/50\n",
      "80/80 - 0s - loss: 0.3767 - accuracy: 0.8562\n",
      "Epoch 13/50\n",
      "80/80 - 0s - loss: 0.4459 - accuracy: 0.7812\n",
      "Epoch 14/50\n",
      "80/80 - 0s - loss: 0.3287 - accuracy: 0.8562\n",
      "Epoch 15/50\n",
      "80/80 - 0s - loss: 0.3839 - accuracy: 0.8438\n",
      "Epoch 16/50\n",
      "80/80 - 0s - loss: 0.3959 - accuracy: 0.8281\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 17/50\n",
      "80/80 - 0s - loss: 0.2733 - accuracy: 0.8906\n",
      "Epoch 18/50\n",
      "80/80 - 0s - loss: 0.2460 - accuracy: 0.8813\n",
      "Epoch 19/50\n",
      "80/80 - 0s - loss: 0.3114 - accuracy: 0.8562\n",
      "Epoch 20/50\n",
      "80/80 - 0s - loss: 0.2342 - accuracy: 0.9000\n",
      "Epoch 21/50\n",
      "80/80 - 0s - loss: 0.2040 - accuracy: 0.9000\n",
      "Epoch 22/50\n",
      "80/80 - 0s - loss: 0.1955 - accuracy: 0.9094\n",
      "Epoch 23/50\n",
      "80/80 - 0s - loss: 0.2094 - accuracy: 0.9125\n",
      "Epoch 24/50\n",
      "80/80 - 0s - loss: 0.1724 - accuracy: 0.9312\n",
      "Epoch 25/50\n",
      "80/80 - 0s - loss: 0.1683 - accuracy: 0.9281\n",
      "Epoch 26/50\n",
      "80/80 - 0s - loss: 0.1741 - accuracy: 0.9344\n",
      "Epoch 27/50\n",
      "80/80 - 0s - loss: 0.2699 - accuracy: 0.8813\n",
      "Epoch 28/50\n",
      "80/80 - 0s - loss: 0.2091 - accuracy: 0.9094\n",
      "Epoch 29/50\n",
      "80/80 - 0s - loss: 0.1498 - accuracy: 0.9125\n",
      "Epoch 30/50\n",
      "80/80 - 0s - loss: 0.1674 - accuracy: 0.9375\n",
      "Epoch 31/50\n",
      "80/80 - 0s - loss: 0.1314 - accuracy: 0.9344\n",
      "Epoch 32/50\n",
      "80/80 - 0s - loss: 0.1234 - accuracy: 0.9406\n",
      "Epoch 33/50\n",
      "80/80 - 0s - loss: 0.1120 - accuracy: 0.9594\n",
      "Epoch 34/50\n",
      "80/80 - 0s - loss: 0.1043 - accuracy: 0.9406\n",
      "Epoch 35/50\n",
      "80/80 - 0s - loss: 0.1968 - accuracy: 0.9187\n",
      "Epoch 36/50\n",
      "80/80 - 0s - loss: 0.1173 - accuracy: 0.9406\n",
      "Epoch 37/50\n",
      "80/80 - 0s - loss: 0.1215 - accuracy: 0.9656\n",
      "Epoch 38/50\n",
      "80/80 - 0s - loss: 0.1524 - accuracy: 0.9281\n",
      "Epoch 39/50\n",
      "80/80 - 0s - loss: 0.1400 - accuracy: 0.9375\n",
      "Epoch 40/50\n",
      "80/80 - 0s - loss: 0.1494 - accuracy: 0.9469\n",
      "Epoch 41/50\n",
      "80/80 - 0s - loss: 0.1239 - accuracy: 0.9469\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/50\n",
      "80/80 - 0s - loss: 0.1226 - accuracy: 0.9469\n",
      "Epoch 43/50\n",
      "80/80 - 0s - loss: 0.1169 - accuracy: 0.9531\n",
      "Epoch 44/50\n",
      "80/80 - 0s - loss: 0.0785 - accuracy: 0.9656\n",
      "Epoch 45/50\n",
      "80/80 - 0s - loss: 0.1220 - accuracy: 0.9531\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 46/50\n",
      "80/80 - 0s - loss: 0.1108 - accuracy: 0.9469\n",
      "Epoch 47/50\n",
      "80/80 - 0s - loss: 0.0861 - accuracy: 0.9594\n",
      "Epoch 48/50\n",
      "80/80 - 0s - loss: 0.0476 - accuracy: 0.9844\n",
      "Epoch 49/50\n",
      "80/80 - 0s - loss: 0.0875 - accuracy: 0.9719\n",
      "Epoch 50/50\n",
      "80/80 - 0s - loss: 0.0946 - accuracy: 0.9750\n",
      "CPU times: user 34.6 s, sys: 2.46 s, total: 37.1 s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "#import tensorflow as tf \n",
    "#from tf.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "epochs = 50\n",
    "batch_size = 4 \n",
    "model_CV = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, epochs=epochs, \n",
    "                           batch_size=batch_size, verbose=2)\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'glorot_uniform', 'glorot_normal']\n",
    "batches = [4,8,16]\n",
    "lr = [0.001, 0.0001, 0.00005]\n",
    "\n",
    "param_grid = dict(init_mode=init_mode, lr = lr, batch_size = batches)\n",
    "grid = RandomizedSearchCV(estimator=model_CV, param_distributions=param_grid, n_jobs=-1, cv=StratifiedKFold(3))\n",
    "grid_result = grid.fit(X_train, y_train, callbacks=[reduce_lr, early_stop], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2654c810-4414-46fd-ad80-98fbfa1cf466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy for 0.8218714992205302 using {'lr': 0.001, 'init_mode': 'glorot_normal', 'batch_size': 4}\n",
      " mean=0.6628, std=0.05947 using {'lr': 5e-05, 'init_mode': 'glorot_uniform', 'batch_size': 16}\n",
      " mean=0.6657, std=0.01795 using {'lr': 5e-05, 'init_mode': 'uniform', 'batch_size': 4}\n",
      " mean=0.8187, std=0.01248 using {'lr': 0.001, 'init_mode': 'uniform', 'batch_size': 16}\n",
      " mean=0.7562, std=0.02058 using {'lr': 0.0001, 'init_mode': 'uniform', 'batch_size': 4}\n",
      " mean=0.7999, std=0.01656 using {'lr': 0.001, 'init_mode': 'glorot_uniform', 'batch_size': 8}\n",
      " mean=0.7094, std=0.01942 using {'lr': 0.0001, 'init_mode': 'uniform', 'batch_size': 8}\n",
      " mean=0.8219, std=0.0007897 using {'lr': 0.001, 'init_mode': 'glorot_normal', 'batch_size': 4}\n",
      " mean=0.8124, std=0.0269 using {'lr': 0.001, 'init_mode': 'lecun_uniform', 'batch_size': 8}\n",
      " mean=0.7656, std=0.02292 using {'lr': 0.0001, 'init_mode': 'glorot_normal', 'batch_size': 8}\n",
      " mean=0.7375, std=0.01985 using {'lr': 5e-05, 'init_mode': 'lecun_uniform', 'batch_size': 4}\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56db698-7d28-46a0-9572-4efe4f4a4163",
   "metadata": {},
   "source": [
    "## Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4263775-96ad-4c66-ae2e-acd9c35a1919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Accuracy for 0.875 using {'lr': 0.001, 'init_mode': 'lecun_uniform', 'batch_size': 8}\n",
    "# New length best parameters: \n",
    "# Best Accuracy for 0.8218714992205302 using {'lr': 0.001, 'init_mode': 'glorot_uniform', 'batch_size': 8}\n",
    "'''\n",
    "def create_model( init_mode='glorot_uniform', lr = 0.001):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv1D(256, 5,padding='same',\n",
    "                     input_shape=(248,12), kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "\n",
    "    model.add(layers.Conv1D(128, 5,padding='same', kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, kernel_initializer=init_mode))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr = lr) , \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "'''\n",
    "def create_model( init_mode='glorot_uniform', lr = 0.001):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv1D(256, 5,padding='same',\n",
    "                     input_shape=(76,12), kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "\n",
    "    model.add(layers.Conv1D(128, 5,padding='same', kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, kernel_initializer=init_mode))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr = lr) , \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88ca0028-341b-4ac2-9960-2660d2334d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7562bfeb-cf95-4f0c-b3dd-ef84924d3022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 11:21:29.472201: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 11:21:29.472597: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67929029-a030-49cc-9ae5-93463a5c038e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c8efaa7-2fa2-485b-827e-ec2197fd5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89cdfc11-1cc1-473e-9fe2-38b4c7a5e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9de3201a-cf63-4655-a785-0e10106fbcc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 11:21:36.489666: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-08-31 11:21:36.489768: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-08-31 11:21:36.547396: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef719f44-de1a-4a2f-ab6c-69aee988a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                                                 factor=0.5, patience=4, \n",
    "                                                 verbose=1, mode='max', \n",
    "                                                 min_lr=0.000001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=45, \n",
    "                                              verbose=1, restore_best_weights = True )\n",
    "\n",
    "# classweight \n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "641a1073-383a-4cbd-aa57-ee24a3333e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 11:21:37.228956: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-31 11:21:37.247682: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/40 [==================>...........] - ETA: 0s - loss: 0.9638 - accuracy: 0.5729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 11:21:37.744010: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-08-31 11:21:37.744036: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-08-31 11:21:37.748855: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-08-31 11:21:37.750168: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-08-31 11:21:37.751965: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37\n",
      "2021-08-31 11:21:37.752763: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37/helemanc-Latitude-5410.trace.json.gz\n",
      "2021-08-31 11:21:37.754995: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37\n",
      "2021-08-31 11:21:37.755101: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37/helemanc-Latitude-5410.memory_profile.json.gz\n",
      "2021-08-31 11:21:37.755372: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37Dumped tool data for xplane.pb to logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37/helemanc-Latitude-5410.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37/helemanc-Latitude-5410.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37/helemanc-Latitude-5410.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37/helemanc-Latitude-5410.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20210831-112136/train/plugins/profile/2021_08_31_11_21_37/helemanc-Latitude-5410.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 12ms/step - loss: 0.9776 - accuracy: 0.5747 - val_loss: 0.6661 - val_accuracy: 0.6167\n",
      "Epoch 2/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.7362 - val_loss: 0.5984 - val_accuracy: 0.7000\n",
      "Epoch 3/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7076 - val_loss: 0.3883 - val_accuracy: 0.8167\n",
      "Epoch 4/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.7166 - val_loss: 0.4947 - val_accuracy: 0.7667\n",
      "Epoch 5/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7923 - val_loss: 0.4385 - val_accuracy: 0.8000\n",
      "Epoch 6/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7843 - val_loss: 0.3704 - val_accuracy: 0.8333\n",
      "Epoch 7/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7802 - val_loss: 0.4903 - val_accuracy: 0.7833\n",
      "Epoch 8/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.8041 - val_loss: 0.4218 - val_accuracy: 0.8500\n",
      "Epoch 9/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8164 - val_loss: 0.4680 - val_accuracy: 0.8167\n",
      "Epoch 10/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8137 - val_loss: 0.4305 - val_accuracy: 0.8167\n",
      "Epoch 11/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.8527 - val_loss: 0.3135 - val_accuracy: 0.8667\n",
      "Epoch 12/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8625 - val_loss: 0.3667 - val_accuracy: 0.8333\n",
      "Epoch 13/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8190 - val_loss: 0.3352 - val_accuracy: 0.8333\n",
      "Epoch 14/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8611 - val_loss: 0.4629 - val_accuracy: 0.7667\n",
      "Epoch 15/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.8254 - val_loss: 0.3481 - val_accuracy: 0.8333\n",
      "Epoch 16/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2779 - accuracy: 0.8631 - val_loss: 0.3479 - val_accuracy: 0.8500\n",
      "Epoch 17/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.9143 - val_loss: 0.4208 - val_accuracy: 0.8167\n",
      "Epoch 18/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8872 - val_loss: 0.3717 - val_accuracy: 0.8667\n",
      "Epoch 19/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9062 - val_loss: 0.4532 - val_accuracy: 0.8000\n",
      "Epoch 20/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.8981 - val_loss: 0.5450 - val_accuracy: 0.7667\n",
      "Epoch 21/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.8782 - val_loss: 0.4431 - val_accuracy: 0.8333\n",
      "Epoch 22/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8415 - val_loss: 0.4015 - val_accuracy: 0.8167\n",
      "Epoch 23/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.8811 - val_loss: 0.3886 - val_accuracy: 0.8167\n",
      "Epoch 24/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1582 - accuracy: 0.9262 - val_loss: 0.3950 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 25/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9342 - val_loss: 0.4605 - val_accuracy: 0.8167\n",
      "Epoch 26/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9354 - val_loss: 0.4121 - val_accuracy: 0.8167\n",
      "Epoch 27/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1590 - accuracy: 0.9376 - val_loss: 0.3713 - val_accuracy: 0.8333\n",
      "Epoch 28/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9576 - val_loss: 0.3958 - val_accuracy: 0.8167\n",
      "Epoch 29/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0815 - accuracy: 0.9494 - val_loss: 0.3711 - val_accuracy: 0.8333\n",
      "Epoch 30/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9431 - val_loss: 0.4299 - val_accuracy: 0.8333\n",
      "Epoch 31/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1604 - accuracy: 0.9279 - val_loss: 0.4222 - val_accuracy: 0.8167\n",
      "Epoch 32/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9413 - val_loss: 0.3673 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 33/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1203 - accuracy: 0.9633 - val_loss: 0.3834 - val_accuracy: 0.8333\n",
      "Epoch 34/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9898 - val_loss: 0.3694 - val_accuracy: 0.8333\n",
      "Epoch 35/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0942 - accuracy: 0.9612 - val_loss: 0.3726 - val_accuracy: 0.8333\n",
      "Epoch 36/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9477 - val_loss: 0.4128 - val_accuracy: 0.8333\n",
      "Epoch 37/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9677 - val_loss: 0.3796 - val_accuracy: 0.8000\n",
      "Epoch 38/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9406 - val_loss: 0.3576 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 39/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9792 - val_loss: 0.3637 - val_accuracy: 0.8167\n",
      "Epoch 40/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9633 - val_loss: 0.3598 - val_accuracy: 0.8333\n",
      "Epoch 41/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9698 - val_loss: 0.3707 - val_accuracy: 0.8667\n",
      "Epoch 42/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9844 - val_loss: 0.3734 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 43/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9750 - val_loss: 0.3722 - val_accuracy: 0.8333\n",
      "Epoch 44/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9665 - val_loss: 0.3752 - val_accuracy: 0.8333\n",
      "Epoch 45/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9876 - val_loss: 0.3761 - val_accuracy: 0.8333\n",
      "Epoch 46/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9793 - val_loss: 0.3739 - val_accuracy: 0.8167\n",
      "Epoch 47/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9952 - val_loss: 0.3755 - val_accuracy: 0.8333\n",
      "Epoch 48/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9753 - val_loss: 0.3756 - val_accuracy: 0.8500\n",
      "Epoch 49/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9706 - val_loss: 0.3758 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 50/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9695 - val_loss: 0.3742 - val_accuracy: 0.8167\n",
      "Epoch 51/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9784 - val_loss: 0.3735 - val_accuracy: 0.8167\n",
      "Epoch 52/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9576 - val_loss: 0.3727 - val_accuracy: 0.8667\n",
      "Epoch 53/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9718 - val_loss: 0.3724 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 54/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9878 - val_loss: 0.3723 - val_accuracy: 0.8500\n",
      "Epoch 55/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9786 - val_loss: 0.3741 - val_accuracy: 0.8500\n",
      "Epoch 56/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9771 - val_loss: 0.3762 - val_accuracy: 0.8333\n",
      "Epoch 57/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9783 - val_loss: 0.3787 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 58/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9677 - val_loss: 0.3784 - val_accuracy: 0.8333\n",
      "Epoch 59/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9938 - val_loss: 0.3785 - val_accuracy: 0.8500\n",
      "Epoch 60/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9765 - val_loss: 0.3785 - val_accuracy: 0.8500\n",
      "Epoch 61/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9620 - val_loss: 0.3786 - val_accuracy: 0.8500\n",
      "Epoch 62/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9858 - val_loss: 0.3789 - val_accuracy: 0.8500\n",
      "Epoch 63/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9655 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 64/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0472 - accuracy: 0.9887 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 65/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9756 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Epoch 66/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9722 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 67/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9609 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 68/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9677 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 69/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9766 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 70/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9508 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 71/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9858 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 72/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9746 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 73/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9661 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 74/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9533 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 75/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9613 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 76/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9413 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 77/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9702 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 78/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9858 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 79/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9856 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 80/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9661 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 81/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9883 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 82/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0991 - accuracy: 0.9647 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 83/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9814 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 84/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9795 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 85/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9927 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 86/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9785 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 87/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9588 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Epoch 88/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9883 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 89/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9480 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 90/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9763 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 91/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9776 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Epoch 92/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9715 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Epoch 93/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9633 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Epoch 94/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0896 - accuracy: 0.9545 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Epoch 95/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9848 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 96/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9879 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 97/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9690 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 98/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9892 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 99/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9807 - val_loss: 0.3799 - val_accuracy: 0.8500\n",
      "Epoch 100/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9798 - val_loss: 0.3799 - val_accuracy: 0.8500\n",
      "Epoch 101/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9898 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 102/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9611 - val_loss: 0.3798 - val_accuracy: 0.8500\n",
      "Epoch 103/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9508 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Epoch 104/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.1501 - accuracy: 0.9539 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 105/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9802 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 106/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9732 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 107/500\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9861 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 108/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9750 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 109/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0873 - accuracy: 0.9468 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 110/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9723 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 111/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9801 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 112/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9686 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 113/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9779 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 114/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9863 - val_loss: 0.3792 - val_accuracy: 0.8500\n",
      "Epoch 115/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9662 - val_loss: 0.3792 - val_accuracy: 0.8500\n",
      "Epoch 116/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0942 - accuracy: 0.9710 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 117/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9820 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 118/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9808 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 119/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9400 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 120/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9650 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 121/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9745 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 122/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9708 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 123/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0577 - accuracy: 0.9776 - val_loss: 0.3792 - val_accuracy: 0.8500\n",
      "Epoch 124/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0466 - accuracy: 0.9881 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 125/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9542 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 126/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9745 - val_loss: 0.3792 - val_accuracy: 0.8500\n",
      "Epoch 127/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9792 - val_loss: 0.3792 - val_accuracy: 0.8500\n",
      "Epoch 128/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9830 - val_loss: 0.3792 - val_accuracy: 0.8500\n",
      "Epoch 129/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9620 - val_loss: 0.3793 - val_accuracy: 0.8500\n",
      "Epoch 130/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9799 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 131/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9859 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 132/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9800 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 133/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9697 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 134/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9827 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Epoch 135/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9751 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 136/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9631 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 137/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9836 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 138/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9626 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 139/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9716 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
      "Epoch 140/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9836 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
      "Epoch 141/500\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9759 - val_loss: 0.3797 - val_accuracy: 0.8500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00141: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=8, epochs=500, validation_data=(X_val, y_val),\n",
    "           callbacks=[reduce_lr, early_stop, tensorboard_callback], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f1455e9-032d-4056-af77-af824623b71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 31441), started 23:59:11 ago. (Use '!kill 31441' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d261a7ab3aa2e4f9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d261a7ab3aa2e4f9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49c10806-e877-4e7b-a172-a85f45b79027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3047849237918854, 0.8833333253860474]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6fd89b08-e5e9-40da-acf2-b54042672143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.58      0.67        12\n",
      "           1       0.90      0.96      0.93        48\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.84      0.77      0.80        60\n",
      "weighted avg       0.88      0.88      0.88        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "pred = [1 * (x[0]>=0.50) for x in predictions] #0.5 o 0.52? \n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881660c-00e1-4237-9056-5ac81d0a86b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
