{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb83b69-4efa-4a1e-b074-88ed7a6bca33",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configuration\n",
    "\n",
    "NOTES: The warnings after the import are referred to the fact that Tensorflow 2.x versions are built to directly look for a GPU in the system. The warning can be forgot if you are not going to use the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4851a3-2ca2-4532-9a66-00132102832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source myenv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d9a9ae-114f-45ff-9142-1c804c9e54f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples in 5 seconds of audio, 16 KHz sample rate \n",
    "LENGTH_CHOSEN =  80000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78d3416a-395b-421c-ad3b-56a6c9b5b3ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import ipywidgets\n",
    "import math\n",
    "from time import time  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, AveragePooling1D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from livelossplot import PlotLossesKeras\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ae1b218-ec16-4f22-93bd-dbcdc9dd46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SVM\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c70b1-d037-49b9-9f0f-7a8782a65f7f",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "759395d6-c6ae-4b8c-a114-0dbf2031707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_scaled(df_train, df_val, df_test): \n",
    "    load_train = load_files(df_train)\n",
    "    samples_train = extract_samples(load_train)\n",
    "    labels_train = extract_labels(df_train)\n",
    "    samples_train, labels_train = cut_and_pad(samples_train, labels_train)\n",
    "    samples_train, scaler = minmax_scaling_train(samples_train)\n",
    "    \n",
    "  \n",
    "    load_val = load_files(df_val)\n",
    "    samples_val = extract_samples(load_val)\n",
    "    labels_val = extract_labels(df_val)\n",
    "    samples_val, labels_val = cut_and_pad(samples_val, labels_val)\n",
    "    samples_val = np.array(samples_val)\n",
    "    samples_val = scaler.transform(samples_val)\n",
    "    labels_val = np.array(labels_val)\n",
    "    \n",
    "    \n",
    "    load_test = load_files(df_test)\n",
    "    samples_test = extract_samples(load_test)\n",
    "    labels_test = extract_labels(df_test)\n",
    "    samples_test, labels_test = cut_and_pad(samples_test, labels_test)\n",
    "    samples_test = np.array(samples_test)\n",
    "    \n",
    "    samples_test = scaler.transform(samples_test)\n",
    "    \n",
    "    labels_test = np.array(labels_test)\n",
    "\n",
    "    return samples_train, labels_train,  samples_val, labels_val, samples_test, labels_test\n",
    "\n",
    "def samples_scaled_tess(df_train, df_test): \n",
    "    load_train = load_files(df_train)\n",
    "    samples_train = extract_samples(load_train)\n",
    "    labels_train = extract_labels(df_train)\n",
    "    samples_train, labels_train = cut_and_pad(samples_train, labels_train)\n",
    "    samples_train, scaler = minmax_scaling_train(samples_train)\n",
    "    \n",
    "    \n",
    "    load_test = load_files(df_test)\n",
    "    samples_test = extract_samples(load_test)\n",
    "    labels_test = extract_labels(df_test)\n",
    "    samples_test, labels_test = cut_and_pad(samples_test, labels_test)\n",
    "    samples_test = np.array(samples_test)\n",
    "    \n",
    "    samples_test = scaler.transform(samples_test)\n",
    "    \n",
    "    labels_test = np.array(labels_test)\n",
    "\n",
    "    return samples_train, labels_train,  samples_test, labels_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27877e2c-3ded-43b0-a22f-e513cf5f8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(df):\n",
    "    X = []\n",
    "    for i in tqdm(df['path']): \n",
    "        X.append(librosa.load(i, res_type='kaiser_fast', sr=16000))\n",
    "    return X\n",
    "\n",
    "def extract_samples(X): \n",
    "    samples = []\n",
    "    for ind,i in enumerate(X):\n",
    "        samples.append(i[0])\n",
    "    return samples \n",
    "\n",
    "def extract_labels(df): \n",
    "    labels = df['emotion_label'].copy()\n",
    "    return labels \n",
    "\n",
    "def compute_lengths(samples): \n",
    "    lengths = [len(x) for x in samples]\n",
    "    return lengths \n",
    "\n",
    "def check_outliers(lengths):\n",
    "    # outliers\n",
    "    lengths = np.array(lengths)\n",
    "    print((lengths > 300000).sum())\n",
    "    new_lengths = lengths[lengths < 300000]\n",
    "    return new_lengths \n",
    "\n",
    "def compute_mean_length(lengths): \n",
    "    return lengths.mean()\n",
    "\n",
    "\n",
    "def cut_and_pad(samples, labels, length_chosen = LENGTH_CHOSEN): \n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    count = 0 \n",
    "    for ind,i in enumerate(samples):\n",
    "        if i.shape[0] < 300000:\n",
    "            if i.shape[0] > length_chosen:\n",
    "                new = i[:length_chosen]\n",
    "                X_new.append(new)\n",
    "            elif i.shape[0] < length_chosen:\n",
    "                new = np.pad(i,math.ceil((length_chosen-i.shape[0])/2), mode='median')\n",
    "                X_new.append(new)\n",
    "            else:\n",
    "                X_new.append(i)\n",
    "            y_new.append(labels[count])\n",
    "        count+=1\n",
    "    c = 0 \n",
    "    for el in X_new: \n",
    "        if len(el) == 80001: \n",
    "            X_new[c] = el[:-1]\n",
    "        c+=1\n",
    "    \n",
    "    return X_new, y_new\n",
    "'''    \n",
    "def compute_mfccs(samples, n_mfcc): \n",
    "    mfccs = []\n",
    "    for i in tqdm(samples):\n",
    "        mfcc = librosa.feature.mfcc(y=i, sr=16000, n_mfcc=n_mfcc)\n",
    "        mfcc = mfcc.T\n",
    "        mfcc = np.array(mfcc)\n",
    "        mfccs.append(mfcc[:, 1:]) # get rid of the first component \n",
    "    mfccs = np.array(mfccs)\n",
    "    return mfccs\n",
    "'''\n",
    "def compute_mfccs(samples, n_mfcc): \n",
    "    mfccs = []\n",
    "    for i in tqdm(samples):\n",
    "        mfcc = librosa.feature.mfcc(y=i, sr=16000, n_mfcc=n_mfcc)\n",
    "        mfcc = mfcc.T\n",
    "        mfcc = np.array(mfcc)\n",
    "        #mfccs.append(mfcc[:, 1:]) # get rid of the first component \n",
    "        mfccs.append(np.mean(mfcc[:, 1:], axis = 0))\n",
    "    mfccs = np.array(mfccs)\n",
    "    return mfccs\n",
    "\n",
    "def compute_energy(samples): \n",
    "    energy_per_sample = []\n",
    "    for i in tqdm(samples):\n",
    "        energy = librosa.feature.rms(i)\n",
    "        energy = energy.T \n",
    "        energy = np.array(energy)\n",
    "        energy_per_sample.append(energy) \n",
    "    return energy_per_sample\n",
    "       \n",
    "def feature_extractor(df_train, df_val, df_test, n_mfcc): \n",
    "    samples_train, labels_train, samples_val, labels_val, samples_test, labels_test=samples_scaled(df_train, df_val, df_test)\n",
    "\n",
    "    mfccs_train = compute_mfccs(samples_train, n_mfcc = n_mfcc)\n",
    " \n",
    "            \n",
    "    mfccs_val = compute_mfccs(samples_val, n_mfcc = n_mfcc)\n",
    "    \n",
    "    \n",
    "    mfccs_test = compute_mfccs(samples_test, n_mfcc = n_mfcc)\n",
    "\n",
    "    \n",
    "\n",
    "    return mfccs_train, labels_train,  mfccs_val, labels_val, mfccs_test, labels_test\n",
    "    \n",
    "\n",
    "def feature_extractor_tess(df_train,  df_test, n_mfcc): \n",
    "    # we do not have the validation set here \n",
    "    samples_train, labels_train,  samples_test, labels_test=samples_scaled(df_train, df_test)\n",
    "    mfccs_train = compute_mfccs(samples_train, n_mfcc = n_mfcc)\n",
    "\n",
    "    mfccs_test = compute_mfccs(samples_test, n_mfcc = n_mfcc)\n",
    "\n",
    "    return mfccs_train, labels_train,  mfccs_val, labels_val, mfccs_test, labels_test\n",
    "    \n",
    "def encode_labels(labels_train, labels_val, labels_test): \n",
    "    \n",
    "    emotion_enc = {'fear':1, 'disgust':1, 'neutral':0, 'calm':0,  'happy':0, 'sadness':1, 'surprise':0, 'angry':1}\n",
    "    y_train = pd.Series(labels_train).replace(emotion_enc)\n",
    "  \n",
    "    y_test = pd.Series(labels_test).map(emotion_enc)\n",
    "    y_val = pd.Series(labels_val).map(emotion_enc)\n",
    "    return y_train, y_val, y_test \n",
    "\n",
    "\n",
    "def encode_labels_tess(labels_train, labels_test): \n",
    "    \n",
    "    emotion_enc = {'fear':1, 'disgust':1, 'neutral':0, 'calm':0,  'happy':0, 'sadness':1, 'surprise':0, 'angry':1}\n",
    "    y_train = pd.Series(labels_train).replace(emotion_enc)\n",
    "  \n",
    "    y_test = pd.Series(labels_test).map(emotion_enc)\n",
    "    return y_train, y_test\n",
    "    \n",
    "def standard_scaling(X_train, X_val, X_test): \n",
    "  \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "    X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "    X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "def minmax_scaling_train(data):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    data = scaler.fit_transform(data)\n",
    "    return data, scaler\n",
    "    \n",
    "def standard_scaling_tess(X_train, X_test): \n",
    "  \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "    X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "    return X_train, X_test   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38008c9-a661-4033-b6c6-efce3dd1708a",
   "metadata": {},
   "source": [
    "# Compute dataframes for datasets and split in Train, Val, Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee6c038-69cf-4883-9e7a-4323efc03f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/media/helemanc/OS/Users/i2CAT/Desktop/Datasets SER/'\n",
    "TESS = os.path.join(main_path, \"tess/TESS Toronto emotional speech set data/\") \n",
    "RAV = os.path.join(main_path, \"ravdess-emotional-speech-audio/audio_speech_actors_01-24\")\n",
    "SAVEE = os.path.join(main_path, \"savee/ALL/\")\n",
    "CREMA = os.path.join(main_path, \"creamd/AudioWAV/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563dd85-a231-4082-9c23-4b497c192afa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RADVESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8bcbc8-132f-4905-8bc7-95b97efc7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 578.23it/s]\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "emotion = []\n",
    "voc_channel = []\n",
    "full_path = []\n",
    "modality = []\n",
    "intensity = []\n",
    "actors = []\n",
    "phrase =[]\n",
    "\n",
    "for root, dirs, files in tqdm(os.walk(RAV)):\n",
    "    for file in files:\n",
    "        try:\n",
    "            #Load librosa array, obtain mfcss, store the file and the mfcss information in a new array\n",
    "            # X, sample_rate = librosa.load(os.path.join(root,file), res_type='kaiser_fast')\n",
    "            # mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "            # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
    "            # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
    "           \n",
    "            modal = int(file[1:2])\n",
    "            vchan = int(file[4:5])\n",
    "            lab = int(file[7:8])\n",
    "            ints = int(file[10:11])\n",
    "            phr = int(file[13:14])\n",
    "            act = int(file[18:20])\n",
    "            # arr = mfccs, lab\n",
    "            # lst.append(arr)\n",
    "            \n",
    "            modality.append(modal)\n",
    "            voc_channel.append(vchan)\n",
    "            emotion.append(lab) #only labels\n",
    "            intensity.append(ints)\n",
    "            phrase.append(phr)\n",
    "            actors.append(act)\n",
    "            \n",
    "            full_path.append((root, file)) # only files\n",
    "          # If the file is not valid, skip it\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c779656b-0e7a-4785-a5db-73e836bda80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n",
    "# merge neutral and calm\n",
    "emotions_list = ['neutral', 'neutral', 'happy', 'sadness', 'angry', 'fear', 'disgust', 'surprise']\n",
    "emotion_dict = {em[0]+1:em[1] for em in enumerate(emotions_list)}\n",
    "\n",
    "df = pd.DataFrame([emotion, voc_channel, modality, intensity, actors, actors,phrase, full_path]).T\n",
    "df.columns = ['emotion', 'voc_channel', 'modality', 'intensity', 'actors', 'gender', 'phrase', 'path']\n",
    "df['emotion'] = df['emotion'].map(emotion_dict)\n",
    "df['voc_channel'] = df['voc_channel'].map({1: 'speech', 2:'song'})\n",
    "df['modality'] = df['modality'].map({1: 'full AV', 2:'video only', 3:'audio only'})\n",
    "df['intensity'] = df['intensity'].map({1: 'normal', 2:'strong'})\n",
    "df['actors'] = df['actors']\n",
    "df['gender'] = df['actors'].apply(lambda x: 'female' if x%2 == 0 else 'male')\n",
    "df['phrase'] = df['phrase'].map({1: 'Kids are talking by the door', 2:'Dogs are sitting by the door'})\n",
    "df['path'] = df['path'].apply(lambda x: x[0] + '/' + x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a59679-09ba-4473-b80d-5eb9563cd767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove files with noise to apply the same noise to all files for data augmentation \n",
    "df = df[~df.path.str.contains('noise')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05cf4e42-eef9-42a8-bece-a5fcbef1bad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>voc_channel</th>\n",
       "      <th>modality</th>\n",
       "      <th>intensity</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>phrase</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust</td>\n",
       "      <td>speech</td>\n",
       "      <td>audio only</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>speech</td>\n",
       "      <td>audio only</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>speech</td>\n",
       "      <td>audio only</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>Kids are talking by the door</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>disgust</td>\n",
       "      <td>speech</td>\n",
       "      <td>audio only</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disgust</td>\n",
       "      <td>speech</td>\n",
       "      <td>audio only</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>Dogs are sitting by the door</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion voc_channel    modality intensity actors gender  \\\n",
       "0  disgust      speech  audio only    normal      1   male   \n",
       "2  disgust      speech  audio only    strong      1   male   \n",
       "4  disgust      speech  audio only    strong      1   male   \n",
       "6  disgust      speech  audio only    strong      1   male   \n",
       "8  disgust      speech  audio only    strong      1   male   \n",
       "\n",
       "                         phrase  \\\n",
       "0  Dogs are sitting by the door   \n",
       "2  Kids are talking by the door   \n",
       "4  Kids are talking by the door   \n",
       "6  Dogs are sitting by the door   \n",
       "8  Dogs are sitting by the door   \n",
       "\n",
       "                                                path  \n",
       "0  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "4  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "6  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "8  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c6cfe1-e009-4a71-99bd-6a7431b1ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only speech\n",
    "RAV_df = df\n",
    "RAV_df = RAV_df.loc[RAV_df.voc_channel == 'speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23a31587-031e-442f-9952-89b0edc4d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAV_df.insert(0, \"emotion_label\", RAV_df.emotion, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "063cee86-3e09-494e-91c9-658fdd85582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAV_df = RAV_df.drop(['emotion', 'voc_channel', 'modality', 'intensity', 'phrase'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c99eaa6-256b-48d5-a947-79767f5ffbbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>neutral</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>neutral</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>neutral</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>neutral</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>neutral</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion_label actors  gender  \\\n",
       "0          disgust      1    male   \n",
       "2          disgust      1    male   \n",
       "4          disgust      1    male   \n",
       "6          disgust      1    male   \n",
       "8          disgust      1    male   \n",
       "...            ...    ...     ...   \n",
       "2871       neutral     24  female   \n",
       "2873       neutral     24  female   \n",
       "2875       neutral     24  female   \n",
       "2877       neutral     24  female   \n",
       "2879       neutral     24  female   \n",
       "\n",
       "                                                   path  \n",
       "0     /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2     /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "4     /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "6     /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "8     /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "...                                                 ...  \n",
       "2871  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2873  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2875  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2877  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2879  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "\n",
       "[1440 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAV_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472166a4-549e-4ccd-9fc7-d02281ba63e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAV_train = []\n",
    "RAV_val = []\n",
    "RAV_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb394dde-e466-47f9-b609-19328f9a16f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 120, 120)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in RAV_df.iterrows():\n",
    "    if row['actors'] in range(1,21): \n",
    "        RAV_train.append(row) \n",
    "    elif row['actors'] in range(21,23): \n",
    "        RAV_val.append(row)\n",
    "    elif row['actors'] in range(23,25): \n",
    "        RAV_test.append(row)\n",
    "len(RAV_train), len(RAV_val), len(RAV_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b2aee8-35ba-4096-8a31-c31f58c567df",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAV_train = pd.DataFrame(RAV_train)\n",
    "RAV_val = pd.DataFrame(RAV_val)\n",
    "RAV_test = pd.DataFrame(RAV_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf782755-b0f0-432c-83d1-c9ef0f780981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAV_train = RAV_train.drop(['actors'], 1)\n",
    "RAV_val = RAV_val.drop(['actors'], 1)\n",
    "RAV_test = RAV_test.drop(['actors'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f99cd66-a38f-46c3-a6d1-43cd2ff0fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAV_train.reset_index(drop=True, inplace = True) \n",
    "RAV_val.reset_index(drop=True, inplace = True) \n",
    "RAV_test.reset_index(drop=True, inplace = True ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd4aec-8825-490d-a839-9bc2180402f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SAVEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3141628-1f32-4411-a221-5df11ea817fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     120\n",
       "sadness      60\n",
       "surprise     60\n",
       "happy        60\n",
       "disgust      60\n",
       "fear         60\n",
       "angry        60\n",
       "Name: emotion_label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data location for SAVEE\n",
    "dir_list = os.listdir(SAVEE)\n",
    "\n",
    "# parse the filename to get the emotions\n",
    "emotion=[]\n",
    "path = []\n",
    "actors = []\n",
    "gender = []\n",
    "for i in dir_list:\n",
    "    actors.append(i[:2])\n",
    "    if i[-8:-6]=='_a':\n",
    "        emotion.append('angry')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='_d':\n",
    "        emotion.append('disgust')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='_f':\n",
    "        emotion.append('fear')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='_h':\n",
    "        emotion.append('happy')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='_n':\n",
    "        emotion.append('neutral')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='sa':\n",
    "        emotion.append('sadness')\n",
    "        gender.append('male')\n",
    "    elif i[-8:-6]=='su':\n",
    "        emotion.append('surprise')\n",
    "        gender.append('male') \n",
    "    else:\n",
    "        emotion.append('Unknown') \n",
    "    path.append(SAVEE + i)\n",
    "    \n",
    "# Now check out the label count distribution \n",
    "SAVEE_df = pd.DataFrame(emotion, columns = ['emotion_label'])\n",
    "                      \n",
    "SAVEE_df = pd.concat([SAVEE_df,\n",
    "                      pd.DataFrame(actors, columns = ['actors']),\n",
    "                      pd.DataFrame(gender, columns = ['gender']), \n",
    "                      pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
    "SAVEE_df.emotion_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9321f32c-d3fc-430c-b1c0-8258c83eb574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>DC</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>KL</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>KL</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>KL</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sadness</td>\n",
       "      <td>KL</td>\n",
       "      <td>male</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion_label actors gender  \\\n",
       "0       neutral     DC   male   \n",
       "1       sadness     KL   male   \n",
       "2       sadness     KL   male   \n",
       "3       sadness     KL   male   \n",
       "4       sadness     KL   male   \n",
       "\n",
       "                                                path  \n",
       "0  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "1  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "3  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "4  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVEE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90e1e137-e514-4128-9b61-0ba29eaa9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEE_train = []\n",
    "SAVEE_val = []\n",
    "SAVEE_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad176b21-3668-4539-9284-1e3f86f11b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 120, 120)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DC, JE, JK, KL\n",
    "for index, row in SAVEE_df.iterrows(): \n",
    "    if row['actors'] == 'DC' or row ['actors'] == 'JE':\n",
    "        SAVEE_train.append(row)\n",
    "    elif row['actors'] == 'JK': \n",
    "        SAVEE_val.append(row)\n",
    "    else: \n",
    "        SAVEE_test.append(row)\n",
    "len(SAVEE_train), len(SAVEE_val), len(SAVEE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6ea74bd-9880-4c93-9277-938958bb105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEE_train = pd.DataFrame(SAVEE_train)\n",
    "SAVEE_val = pd.DataFrame(SAVEE_val)\n",
    "SAVEE_test = pd.DataFrame(SAVEE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5f1660d-dbf2-4bdf-9499-d86694b361cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEE_train = SAVEE_train.drop(['actors'], 1)\n",
    "SAVEE_val = SAVEE_val.drop(['actors'], 1)\n",
    "SAVEE_test = SAVEE_test.drop(['actors'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5db34a2-e1d5-4d2c-9a15-1aeca97cc1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVEE_train = SAVEE_train.reset_index(drop=True) \n",
    "SAVEE_val = SAVEE_val.reset_index(drop=True) \n",
    "SAVEE_test = SAVEE_test.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c2271-c790-4bb7-bcbf-2a0cab67e935",
   "metadata": {},
   "source": [
    "## TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37a8890a-3b57-4970-992e-87af596ebf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angry       1200\n",
       "fear         800\n",
       "surprise     800\n",
       "sadness      800\n",
       "disgust      800\n",
       "neutral      800\n",
       "happy        400\n",
       "Name: emotion_label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list = os.listdir(TESS)\n",
    "dir_list.sort()\n",
    "dir_list\n",
    "\n",
    "path = []\n",
    "emotion = []\n",
    "gender = []\n",
    "actors = []\n",
    "\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(TESS + i)\n",
    "    for f in fname:\n",
    "        if i == 'OAF_angry':\n",
    "            emotion.append('angry')\n",
    "            gender.append('female')\n",
    "            actors.append('OAF')\n",
    "        elif i == 'YAF_angry': \n",
    "            emotion.append('angry')\n",
    "            gender.append('female')\n",
    "            actors.append('YAF')\n",
    "            \n",
    "            \n",
    "        elif i == 'OAF_disgust' :\n",
    "            emotion.append('disgust')\n",
    "            gender.append('female')\n",
    "            actors.append('OAF')\n",
    "        elif i == 'YAF_disgust': \n",
    "            emotion.append('disgust')\n",
    "            gender.append('female')\n",
    "            actors.append('YAF')\n",
    "            \n",
    "            \n",
    "        elif i == 'OAF_Fear':\n",
    "            emotion.append('fear')\n",
    "            gender.append('female')\n",
    "            actors.append('OAF')\n",
    "        elif i == 'YAF_fear': \n",
    "            emotion.append('fear')\n",
    "            gender.append('female')\n",
    "            actors.append('YAF') \n",
    "            \n",
    "            \n",
    "        elif i == 'OAF_happy' :\n",
    "            emotion.append('happy')\n",
    "            gender.append('female')\n",
    "            actors.append('OAF')\n",
    "        elif i == 'YAF_happy': \n",
    "            emotion.append('angry')\n",
    "            gender.append('female')\n",
    "            actors.append('YAF')            \n",
    "            \n",
    "        elif i == 'OAF_neutral':\n",
    "            emotion.append('neutral')\n",
    "            gender.append('female')\n",
    "            actors.append('OAF')   \n",
    "        elif i == 'YAF_neutral': \n",
    "            emotion.append('neutral')\n",
    "            gender.append('female')\n",
    "            actors.append('YAF')      \n",
    "            \n",
    "                \n",
    "        elif i == 'OAF_Pleasant_surprise':\n",
    "            emotion.append('surprise')\n",
    "            gender.append('female')\n",
    "            actors.append('OAF')\n",
    "        \n",
    "        elif i == 'YAF_pleasant_surprised': \n",
    "            emotion.append('surprise')\n",
    "            gender.append('female')\n",
    "            actors.append('YAF')            \n",
    "            \n",
    "        elif i == 'OAF_Sad':\n",
    "            emotion.append('sadness')\n",
    "            gender.append('female')\n",
    "            actors.append('OAF')\n",
    "        elif i == 'YAF_sad': \n",
    "            emotion.append('sadness')\n",
    "            gender.append('female')\n",
    "            actors.append('YAF')            \n",
    "        else:\n",
    "            emotion.append('Unknown')\n",
    "        path.append(TESS + i + \"/\" + f)\n",
    "\n",
    "TESS_df = pd.DataFrame(emotion, columns = ['emotion_label'])\n",
    "TESS_df = pd.concat([TESS_df, pd.DataFrame(gender, columns = ['gender']), \n",
    "                     pd.DataFrame(actors, columns= ['actors']),\n",
    "                     pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "TESS_df.emotion_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38e4c23f-b039-487e-ab43-0af5647b3a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TESS_df= TESS_df[~TESS_df.path.str.contains('noise')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd6e4a0d-4bdf-448e-86de-51e8fb9c8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS_train = []\n",
    "TESS_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a96ed5e7-9bf3-4d86-9499-a0063bed1a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1400)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in TESS_df.iterrows(): \n",
    "    if row['actors'] == 'YAF': \n",
    "        TESS_train.append(row)\n",
    "    else: \n",
    "        TESS_test.append(row)\n",
    "len(TESS_train), len(TESS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f76e5ad-766d-4d53-982c-aecf333da264",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS_train = pd.DataFrame(TESS_train)\n",
    "TESS_test = pd.DataFrame(TESS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "546b8739-76fe-40c6-a604-1c16d1293e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS_train = TESS_train.reset_index(drop=True) \n",
    "TESS_test  = TESS_test.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6c400-6b52-4728-a1a3-07f4333db71d",
   "metadata": {},
   "source": [
    "## CREMA-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1281bcc-21ce-4ead-aaab-1474b294f633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "males = [1,\n",
    "5,\n",
    "11,\n",
    "14,\n",
    "15,\n",
    "16,\n",
    "17,\n",
    "19,\n",
    "22,\n",
    "23,\n",
    "26,\n",
    "27,\n",
    "31,\n",
    "32,\n",
    "33,\n",
    "34,\n",
    "35,\n",
    "36,\n",
    "38,\n",
    "39,\n",
    "41,\n",
    "42,\n",
    "44,\n",
    "45,\n",
    "48,\n",
    "50,\n",
    "51,\n",
    "57,\n",
    "59, \n",
    "62, \n",
    "64,\n",
    "65, \n",
    "66,\n",
    "67,\n",
    "68,\n",
    "69,\n",
    "70,\n",
    "71,\n",
    "77, \n",
    "80, \n",
    "81, \n",
    "83, \n",
    "85, \n",
    "86, \n",
    "87,\n",
    "88, \n",
    "90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f535f67-e981-4de7-9f69-f28ce807bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "females = [ 2,\n",
    "3,\n",
    "4,\n",
    "6,\n",
    "7,\n",
    "8,\n",
    "9,\n",
    "10,\n",
    "12,\n",
    "13,\n",
    "18,\n",
    "20,\n",
    "21,\n",
    "24,\n",
    "25,\n",
    "28,\n",
    "29,\n",
    "30,\n",
    "37,\n",
    "40,\n",
    "43,\n",
    "46,\n",
    "47,\n",
    "49,\n",
    "52,\n",
    "53,\n",
    "54,\n",
    "55,\n",
    "56, \n",
    "58, \n",
    "60,\n",
    "61,\n",
    "63,\n",
    "72, \n",
    "73, \n",
    "74, \n",
    "75, \n",
    "76, \n",
    "78, \n",
    "79, \n",
    "82, \n",
    "84, \n",
    "89, \n",
    "91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09973b86-65e1-42fc-8b90-288aebde088a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgust</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>91</td>\n",
       "      <td>female</td>\n",
       "      <td>/media/helemanc/OS/Users/i2CAT/Desktop/Dataset...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion_label actors  gender  \\\n",
       "0         happy     91  female   \n",
       "1       sadness     91  female   \n",
       "2         angry     91  female   \n",
       "3       disgust     91  female   \n",
       "4          fear     91  female   \n",
       "\n",
       "                                                path  \n",
       "0  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "1  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "2  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "3  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  \n",
       "4  /media/helemanc/OS/Users/i2CAT/Desktop/Dataset...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_directory_list = os.listdir(CREMA)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "actors = []\n",
    "gender = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in crema_directory_list:\n",
    "\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    \n",
    "    # use only high intensity files\n",
    "    if \"HI\" in part[3] :\n",
    "        actor = part[0][2:]\n",
    "        actors.append(actor)\n",
    "        if int(actor) in males:\n",
    "            gender.append('male')\n",
    "        else: \n",
    "            gender.append('female')\n",
    "    \n",
    "        # storing file paths\n",
    "        file_path.append(CREMA + file)\n",
    "        if part[2] == 'SAD':\n",
    "            file_emotion.append('sadness')\n",
    "        elif part[2] == 'ANG':\n",
    "            file_emotion.append('angry')\n",
    "        elif part[2] == 'DIS':\n",
    "            file_emotion.append('disgust')\n",
    "        elif part[2] == 'FEA':\n",
    "            file_emotion.append('fear')\n",
    "        elif part[2] == 'HAP':\n",
    "            file_emotion.append('happy')\n",
    "        elif part[2] == 'NEU':\n",
    "            file_emotion.append('neutral')\n",
    "        else:\n",
    "            file_emotion.append('Unknown')\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['emotion_label'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['path'])\n",
    "actors_df = pd.DataFrame(actors, columns=['actors'])\n",
    "gender_df = pd.DataFrame(gender, columns=['gender'])                      \n",
    "Crema_df = pd.concat([emotion_df, actors_df, gender_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d9a47c7-c638-4e5e-b4d5-63d874d27d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crema_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee6f295f-4562-4dd8-85c0-3c48277256d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_files = {}\n",
    "\n",
    "for index, row in Crema_df.iterrows():\n",
    "    actor = row['actors']\n",
    "    if actor not in actor_files.keys(): \n",
    "        actor_files[actor] = 1\n",
    "    else: \n",
    "        actor_files[actor]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac52958d-9414-4899-a967-970a5db71f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'91': 5,\n",
       " '90': 5,\n",
       " '89': 5,\n",
       " '88': 5,\n",
       " '87': 5,\n",
       " '86': 5,\n",
       " '85': 5,\n",
       " '84': 5,\n",
       " '83': 5,\n",
       " '82': 5,\n",
       " '81': 5,\n",
       " '80': 5,\n",
       " '79': 5,\n",
       " '78': 5,\n",
       " '77': 5,\n",
       " '76': 5,\n",
       " '75': 5,\n",
       " '74': 5,\n",
       " '73': 5,\n",
       " '72': 5,\n",
       " '71': 5,\n",
       " '70': 5,\n",
       " '69': 5,\n",
       " '68': 5,\n",
       " '67': 5,\n",
       " '66': 5,\n",
       " '65': 5,\n",
       " '64': 5,\n",
       " '63': 5,\n",
       " '62': 5,\n",
       " '61': 5,\n",
       " '60': 5,\n",
       " '59': 5,\n",
       " '58': 5,\n",
       " '57': 5,\n",
       " '56': 5,\n",
       " '55': 5,\n",
       " '54': 5,\n",
       " '53': 5,\n",
       " '52': 5,\n",
       " '51': 5,\n",
       " '50': 5,\n",
       " '49': 5,\n",
       " '48': 5,\n",
       " '47': 5,\n",
       " '46': 5,\n",
       " '45': 5,\n",
       " '44': 5,\n",
       " '43': 5,\n",
       " '42': 5,\n",
       " '41': 5,\n",
       " '40': 5,\n",
       " '39': 5,\n",
       " '38': 5,\n",
       " '37': 5,\n",
       " '36': 5,\n",
       " '35': 5,\n",
       " '34': 5,\n",
       " '33': 5,\n",
       " '32': 5,\n",
       " '31': 5,\n",
       " '30': 5,\n",
       " '29': 5,\n",
       " '28': 5,\n",
       " '27': 5,\n",
       " '26': 5,\n",
       " '25': 5,\n",
       " '24': 5,\n",
       " '23': 5,\n",
       " '22': 5,\n",
       " '21': 5,\n",
       " '20': 5,\n",
       " '19': 5,\n",
       " '18': 5,\n",
       " '17': 5,\n",
       " '16': 5,\n",
       " '15': 5,\n",
       " '14': 5,\n",
       " '13': 5,\n",
       " '12': 5,\n",
       " '11': 5,\n",
       " '10': 5,\n",
       " '09': 5,\n",
       " '08': 5,\n",
       " '07': 5,\n",
       " '06': 5,\n",
       " '05': 5,\n",
       " '04': 5,\n",
       " '03': 5,\n",
       " '02': 5,\n",
       " '01': 5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "723a6eb8-3b98-4f7e-9d29-693d2cf38a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_males = 0 \n",
    "count_females = 0 \n",
    "male_list = []\n",
    "for index, row in Crema_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if gender == 'male':\n",
    "        count_males +=1\n",
    "        if actor not in male_list: \n",
    "            male_list.append(actor)\n",
    "    else: \n",
    "        count_females +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "207f3b81-528a-4aec-bba4-c1875f5a894f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 220)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_males, count_females"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17639c72-dfe2-40a8-bf04-0e1846d73cde",
   "metadata": {},
   "source": [
    "Since there are more males than females we will remove randomly 3 male actors (since there are exactly 5 audio files per actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f2b53a9-40e9-4c69-af01-10bfa59ffad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17', '80', '88']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "random.seed(42)\n",
    "males_to_remove = random.sample(male_list, 3)\n",
    "males_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65ecb9da-e9b4-4c9f-a8dc-4c1e3ad22419",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = []\n",
    "for index, row in Crema_df.iterrows(): \n",
    "    if row['actors'] not in males_to_remove: \n",
    "        new_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b80ce1c6-bac2-4d50-9c36-8d33092ffb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_df = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "239d9e4d-38c4-4849-931f-517e3267540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in CREMA_df.iterrows(): \n",
    "    if row['actors'] == '17': \n",
    "        print(\"Elements not removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0533cf9b-ecf2-4074-8916-5c3a062cd098",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_males = 0 \n",
    "count_females = 0 \n",
    "male_list = []\n",
    "female_list = []\n",
    "for index, row in CREMA_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if gender == 'male':\n",
    "        count_males +=1\n",
    "        if actor not in male_list: \n",
    "            male_list.append(actor)\n",
    "    else: \n",
    "        count_females +=1\n",
    "        if actor not in female_list: \n",
    "            female_list.append(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0afa962-041b-44c9-babe-4ed9ea8c8b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 220)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_males, count_females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fe40210-7db7-4943-991c-7ef9102f6b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76017109-a10e-4ad8-8e43-be2ee7a5e8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa775b29-41b8-4494-8112-836fa15b19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_train = []\n",
    "CREMA_val = []\n",
    "CREMA_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa7c8219-b10c-4073-8c8c-6e0a8ba6821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "females_train = random.sample(female_list, 32)\n",
    "males_train = random.sample(male_list, 32)\n",
    "\n",
    "# remove the elements assigned to train \n",
    "for element in females_train:\n",
    "    if element in female_list:\n",
    "        female_list.remove(element)\n",
    "        \n",
    "for element in males_train:\n",
    "    if element in male_list:\n",
    "        male_list.remove(element)\n",
    "\n",
    "         \n",
    "females_val = random.sample(female_list, 6) \n",
    "males_val = random.sample(male_list, 6) \n",
    "\n",
    "# remove the elements assigned to val\n",
    "for element in females_val:\n",
    "    if element in female_list:\n",
    "        female_list.remove(element)\n",
    "        \n",
    "for element in males_val:\n",
    "    if element in male_list:\n",
    "        male_list.remove(element)\n",
    "        \n",
    "females_test = random.sample(female_list, 6) \n",
    "males_test = random.sample(male_list, 6)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79dc2543-1a64-468d-8fbe-f448e26a3c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['54',\n",
       "  '56',\n",
       "  '58',\n",
       "  '74',\n",
       "  '76',\n",
       "  '13',\n",
       "  '78',\n",
       "  '29',\n",
       "  '84',\n",
       "  '89',\n",
       "  '09',\n",
       "  '60',\n",
       "  '04',\n",
       "  '55',\n",
       "  '52',\n",
       "  '91',\n",
       "  '02',\n",
       "  '07',\n",
       "  '46',\n",
       "  '49',\n",
       "  '37',\n",
       "  '10',\n",
       "  '20',\n",
       "  '75',\n",
       "  '21',\n",
       "  '53',\n",
       "  '06',\n",
       "  '28',\n",
       "  '18',\n",
       "  '63',\n",
       "  '30',\n",
       "  '03'],\n",
       " ['57',\n",
       "  '69',\n",
       "  '65',\n",
       "  '45',\n",
       "  '77',\n",
       "  '81',\n",
       "  '41',\n",
       "  '15',\n",
       "  '44',\n",
       "  '23',\n",
       "  '59',\n",
       "  '86',\n",
       "  '34',\n",
       "  '01',\n",
       "  '85',\n",
       "  '66',\n",
       "  '31',\n",
       "  '33',\n",
       "  '05',\n",
       "  '48',\n",
       "  '50',\n",
       "  '67',\n",
       "  '51',\n",
       "  '22',\n",
       "  '36',\n",
       "  '87',\n",
       "  '71',\n",
       "  '39',\n",
       "  '42',\n",
       "  '11',\n",
       "  '32',\n",
       "  '14'],\n",
       " ['43', '61', '40', '47', '73', '24'],\n",
       " ['62', '68', '64', '83', '70', '26'],\n",
       " ['08', '79', '12', '25', '72', '82'],\n",
       " ['16', '19', '38', '35', '27', '90'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "females_train, males_train, females_val, males_val, females_test, males_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5d45f1f-2eeb-4beb-9ca0-1d103e71db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = females_train + males_train \n",
    "val = females_val + males_val \n",
    "test = females_test + males_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "812cb951-3e40-4f04-ba1c-9827c1933411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in CREMA_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if actor in train: \n",
    "        CREMA_train.append(row)\n",
    "    elif actor in val: \n",
    "        CREMA_val.append(row)\n",
    "    else:\n",
    "        CREMA_test.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65b643f1-a355-46a7-9a30-2023cfdf1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_train = pd.DataFrame(CREMA_train) \n",
    "CREMA_val = pd.DataFrame(CREMA_val) \n",
    "CREMA_test = pd.DataFrame(CREMA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4cb62669-629f-4dee-9bef-4a3820204c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 4), (60, 4), (60, 4))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREMA_train.shape, CREMA_val.shape, CREMA_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df94c069-195b-43e2-8b14-40f1de129f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CREMA_train = CREMA_train.reset_index(drop=True) \n",
    "CREMA_val = CREMA_val.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9584054e-8417-4340-96a3-95d2545c7624",
   "metadata": {},
   "source": [
    "# Random Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10c7b893-ca49-4e3e-a435-09e2c94c21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_clf = {'C': [0.1,1, 10, 100], 'kernel': ['rbf',  'linear']}\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee036c31-36df-4775-9198-aa48e963060c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment 1.1 : RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e5a70d4-5579-4787-87b3-39b64e289f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = RAV_train\n",
    "df_val = RAV_val\n",
    "df_test = RAV_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a26dba78-1c60-4200-a2dd-9896027604b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.reset_index(drop = True, inplace = True) \n",
    "df_val.reset_index(drop = True, inplace = True)\n",
    "df_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910aee57-d285-4e0f-a1bd-d209990710ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "049cd11f-7fdf-4930-816a-3b624c227216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:00<00:00, 2463.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:00<00:00, 1853.37it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:00<00:00, 1008.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:16<00:00, 72.93it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:01<00:00, 91.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:01<00:00, 81.89it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = feature_extractor(df_train, df_val, df_test, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "44908781-7f43-4e49-9ef3-fa2d64a79bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_val, y_test = encode_labels(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21172b50-6c0b-46b1-8a83-111c6196ba87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65ae5137-4bb4-4bfa-a2e7-fe937f3828e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = standard_scaling(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9832b2ec-975e-4054-b134-f45be7e5bd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 25)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c64d76f0-c2b8-4e8c-ad4f-996b01fa15ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "008c08da-ed93-41ee-8980-c204f66790de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6919b6-861b-48c1-847a-b833c07bb700",
   "metadata": {},
   "source": [
    "## Shuffle training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b215dc0b-d36f-4ae6-87b3-f2163bb224eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc8d57-b5db-4a28-91e6-79eb25c0c857",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hypeparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eba41b73-df50-4c0c-88bc-8a8bb9f6b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classweight \n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a44e320b-8a6f-4e94-9a94-43450f3c0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search = RandomizedSearchCV(estimator=svc, \n",
    "                                 param_distributions=param_grid_clf, \n",
    "                                 n_jobs = -1, \n",
    "                                 cv=KFold(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6494dd99-4a2c-4594-8ecd-a39083b10378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Randomized Search...\n",
      "\n",
      "Done in 5.749s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing Randomized Search...\")\n",
    "t0 = time()\n",
    "rand_search.fit(X_train, y_train) \n",
    "print(\"\\nDone in %0.3fs\" % (time()-t0))\n",
    "print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b6857410-2032-4402-b6d9-b60280907a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'C': 100}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = rand_search.best_params_\n",
    "best_clf = rand_search.best_estimator_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e951c222-56f7-4096-9b61-9aa41e6e3876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, class_weight={0: 1.0714285714285714, 1: 0.9375})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf =  SVC(C=best_params.get('C'), kernel=best_params.get('kernel'), class_weight=class_weights)\n",
    "best_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd3e22-19f0-435e-aadd-c00d2934a8fb",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "752282f9-dfa9-4955-83a0-c39223a03143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy: 0.5916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/scikit_learn-0.24.2-py3.8-linux-x86_64.egg/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/scikit_learn-0.24.2-py3.8-linux-x86_64.egg/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/scikit_learn-0.24.2-py3.8-linux-x86_64.egg/sklearn/svm/_base.py\", line 169, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/scikit_learn-0.24.2-py3.8-linux-x86_64.egg/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/scikit_learn-0.24.2-py3.8-linux-x86_64.egg/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/scikit_learn-0.24.2-py3.8-linux-x86_64.egg/sklearn/utils/validation.py\", line 871, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/scikit_learn-0.24.2-py3.8-linux-x86_64.egg/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/scikit_learn-0.24.2-py3.8-linux-x86_64.egg/sklearn/utils/validation.py\", line 716, in check_array\n",
      "    raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "ValueError: Found array with dim 3. Estimator expected <= 2.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing...\")\n",
    "pred = best_clf.predict(X_test) \n",
    "accuracy = best_clf.score(X_test, y_test) \n",
    "print(\"Accuracy: %s\" %str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80242b55-2894-4c44-a60d-f0703a7dcaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
