{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9beb49ca-cc9a-496e-b661-d75343827e65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configuration\n",
    "\n",
    "NOTES: The warnings after the import are referred to the fact that Tensorflow 2.x versions are built to directly look for a GPU in the system. The warning can be forgot if you are not going to use the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47857404-2065-4a9b-8032-eca8879ce599",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source myenv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd2d0274-2821-4574-b83e-e4362d1c49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_CHOSEN = 126520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b87314d6-352f-420a-8990-3e8c27743e22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import ipywidgets\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, AveragePooling1D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from livelossplot import PlotLossesKeras\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fcb25-4036-4599-8198-3bc12ddaa395",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76c09d45-1ac2-4361-9106-3ab483d7546f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_path = '/home/helemanc/Desktop/Binary_Model/normalized_audio/crema/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b91e936a-4062-4fdf-80c9-a83ab3525427",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA = main_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0f78d6d7-3316-4924-8f22-2ec7598dbdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "males = [1,\n",
    "5,\n",
    "11,\n",
    "14,\n",
    "15,\n",
    "16,\n",
    "17,\n",
    "19,\n",
    "22,\n",
    "23,\n",
    "26,\n",
    "27,\n",
    "31,\n",
    "32,\n",
    "33,\n",
    "34,\n",
    "35,\n",
    "36,\n",
    "38,\n",
    "39,\n",
    "41,\n",
    "42,\n",
    "44,\n",
    "45,\n",
    "48,\n",
    "50,\n",
    "51,\n",
    "57,\n",
    "59, \n",
    "62, \n",
    "64,\n",
    "65, \n",
    "66,\n",
    "67,\n",
    "68,\n",
    "69,\n",
    "70,\n",
    "71,\n",
    "77, \n",
    "80, \n",
    "81, \n",
    "83, \n",
    "85, \n",
    "86, \n",
    "87,\n",
    "88, \n",
    "90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fc3bd893-a9bc-4e01-a0ff-acddb68b9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "females = [ 2,\n",
    "3,\n",
    "4,\n",
    "6,\n",
    "7,\n",
    "8,\n",
    "9,\n",
    "10,\n",
    "12,\n",
    "13,\n",
    "18,\n",
    "20,\n",
    "21,\n",
    "24,\n",
    "25,\n",
    "28,\n",
    "29,\n",
    "30,\n",
    "37,\n",
    "40,\n",
    "43,\n",
    "46,\n",
    "47,\n",
    "49,\n",
    "52,\n",
    "53,\n",
    "54,\n",
    "55,\n",
    "56, \n",
    "58, \n",
    "60,\n",
    "61,\n",
    "63,\n",
    "72, \n",
    "73, \n",
    "74, \n",
    "75, \n",
    "76, \n",
    "78, \n",
    "79, \n",
    "82, \n",
    "84, \n",
    "89, \n",
    "91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7b82d2f3-c589-497d-b697-873bdd909bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>54</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>28</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>10</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>06</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion_label actors  gender  \\\n",
       "0         angry     54  female   \n",
       "1         angry     28  female   \n",
       "2       sadness     10  female   \n",
       "3       sadness     06  female   \n",
       "4       disgust     21  female   \n",
       "\n",
       "                                                path  \n",
       "0  /home/helemanc/Desktop/Binary_Model/normalized...  \n",
       "1  /home/helemanc/Desktop/Binary_Model/normalized...  \n",
       "2  /home/helemanc/Desktop/Binary_Model/normalized...  \n",
       "3  /home/helemanc/Desktop/Binary_Model/normalized...  \n",
       "4  /home/helemanc/Desktop/Binary_Model/normalized...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_directory_list = os.listdir(CREMA)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "actors = []\n",
    "gender = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in crema_directory_list:\n",
    "\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    \n",
    "    # use only high intensity files\n",
    "    if \"HI\" in part[3] :\n",
    "        actor = part[0][2:]\n",
    "        actors.append(actor)\n",
    "        if int(actor) in males:\n",
    "            gender.append('male')\n",
    "        else: \n",
    "            gender.append('female')\n",
    "    \n",
    "        # storing file paths\n",
    "        file_path.append(CREMA + file)\n",
    "        if part[2] == 'SAD':\n",
    "            file_emotion.append('sadness')\n",
    "        elif part[2] == 'ANG':\n",
    "            file_emotion.append('angry')\n",
    "        elif part[2] == 'DIS':\n",
    "            file_emotion.append('disgust')\n",
    "        elif part[2] == 'FEA':\n",
    "            file_emotion.append('fear')\n",
    "        elif part[2] == 'HAP':\n",
    "            file_emotion.append('happy')\n",
    "        elif part[2] == 'NEU':\n",
    "            file_emotion.append('neutral')\n",
    "        else:\n",
    "            file_emotion.append('Unknown')\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['emotion_label'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['path'])\n",
    "actors_df = pd.DataFrame(actors, columns=['actors'])\n",
    "gender_df = pd.DataFrame(gender, columns=['gender'])                      \n",
    "Crema_df = pd.concat([emotion_df, actors_df, gender_df, path_df], axis=1)\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "91f1344d-9f53-4935-a653-57fdc2b56451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 4)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crema_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34e2d6e4-28cf-426e-b690-e57c059654ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_files = {}\n",
    "\n",
    "for index, row in Crema_df.iterrows():\n",
    "    actor = row['actors']\n",
    "    if actor not in actor_files.keys(): \n",
    "        actor_files[actor] = 1\n",
    "    else: \n",
    "        actor_files[actor]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "48a1136e-76b6-4b16-a437-4ce814456df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'54': 5,\n",
       " '28': 5,\n",
       " '10': 5,\n",
       " '06': 5,\n",
       " '21': 5,\n",
       " '31': 5,\n",
       " '01': 5,\n",
       " '41': 5,\n",
       " '55': 5,\n",
       " '75': 5,\n",
       " '70': 5,\n",
       " '42': 5,\n",
       " '02': 5,\n",
       " '39': 5,\n",
       " '19': 5,\n",
       " '24': 5,\n",
       " '33': 5,\n",
       " '40': 5,\n",
       " '20': 5,\n",
       " '64': 5,\n",
       " '90': 5,\n",
       " '29': 5,\n",
       " '52': 5,\n",
       " '89': 5,\n",
       " '81': 5,\n",
       " '30': 5,\n",
       " '12': 5,\n",
       " '03': 5,\n",
       " '11': 5,\n",
       " '32': 5,\n",
       " '34': 5,\n",
       " '04': 5,\n",
       " '57': 5,\n",
       " '66': 5,\n",
       " '53': 5,\n",
       " '16': 5,\n",
       " '73': 5,\n",
       " '37': 5,\n",
       " '76': 5,\n",
       " '47': 5,\n",
       " '83': 5,\n",
       " '50': 5,\n",
       " '48': 5,\n",
       " '59': 5,\n",
       " '79': 5,\n",
       " '15': 5,\n",
       " '71': 5,\n",
       " '07': 5,\n",
       " '36': 5,\n",
       " '45': 5,\n",
       " '49': 5,\n",
       " '84': 5,\n",
       " '68': 5,\n",
       " '13': 5,\n",
       " '38': 5,\n",
       " '05': 5,\n",
       " '51': 5,\n",
       " '69': 5,\n",
       " '26': 5,\n",
       " '85': 5,\n",
       " '58': 5,\n",
       " '25': 5,\n",
       " '87': 5,\n",
       " '61': 5,\n",
       " '77': 5,\n",
       " '18': 5,\n",
       " '44': 5,\n",
       " '65': 5,\n",
       " '72': 5,\n",
       " '56': 5,\n",
       " '14': 5,\n",
       " '27': 5,\n",
       " '74': 5,\n",
       " '78': 5,\n",
       " '63': 5,\n",
       " '43': 5,\n",
       " '60': 5,\n",
       " '62': 5,\n",
       " '67': 5,\n",
       " '35': 5,\n",
       " '86': 5,\n",
       " '46': 5,\n",
       " '09': 5,\n",
       " '91': 5,\n",
       " '82': 5,\n",
       " '08': 5,\n",
       " '23': 5,\n",
       " '22': 5}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "05b8a37d-1f24-4927-b7af-7e05df374094",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_males = 0 \n",
    "count_females = 0 \n",
    "male_list = []\n",
    "for index, row in Crema_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if gender == 'male':\n",
    "        count_males +=1\n",
    "        if actor not in male_list: \n",
    "            male_list.append(actor)\n",
    "    else: \n",
    "        count_females +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a4735c85-5f15-468b-948a-87a19b0ae742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 220)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_males, count_females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cfa5a856-4024-4927-add0-11a6beba5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in CREMA_df.iterrows(): \n",
    "    if row['actors'] == '17': \n",
    "        print(\"Elements not removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "13a2f5a8-ff7a-4850-b1a6-322f0fb6cd31",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_males = 0 \n",
    "count_females = 0 \n",
    "male_list = []\n",
    "female_list = []\n",
    "for index, row in Crema_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if gender == 'male':\n",
    "        count_males +=1\n",
    "        if actor not in male_list: \n",
    "            male_list.append(actor)\n",
    "    else: \n",
    "        count_females +=1\n",
    "        if actor not in female_list: \n",
    "            female_list.append(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7e59caba-3e57-46ae-b8c1-61620c0a89d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 220)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_males, count_females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "633be86d-70a3-4843-99b3-f49447a6b3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "719cb59c-59db-4a3e-89d7-3a7168a3c96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "96f26ec3-c77c-4a4e-90ca-09e6a40a103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_train = []\n",
    "CREMA_val = []\n",
    "CREMA_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4fda7dd-17d4-4f13-bf4b-6ffc32db197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "females_train = random.sample(female_list, 32)\n",
    "males_train = random.sample(male_list, 32)\n",
    "\n",
    "# remove the elements assigned to train \n",
    "for element in females_train:\n",
    "    if element in female_list:\n",
    "        female_list.remove(element)\n",
    "        \n",
    "for element in males_train:\n",
    "    if element in male_list:\n",
    "        male_list.remove(element)\n",
    "\n",
    "         \n",
    "females_val = random.sample(female_list, 6) \n",
    "males_val = random.sample(male_list, 6) \n",
    "\n",
    "# remove the elements assigned to val\n",
    "for element in females_val:\n",
    "    if element in female_list:\n",
    "        female_list.remove(element)\n",
    "        \n",
    "for element in males_val:\n",
    "    if element in male_list:\n",
    "        male_list.remove(element)\n",
    "        \n",
    "females_test = random.sample(female_list, 6) \n",
    "males_test = random.sample(male_list, 6)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ebaf80a3-8672-4ead-a56a-214bc0d6d1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['25',\n",
       "  '12',\n",
       "  '21',\n",
       "  '58',\n",
       "  '78',\n",
       "  '75',\n",
       "  '06',\n",
       "  '74',\n",
       "  '54',\n",
       "  '55',\n",
       "  '82',\n",
       "  '20',\n",
       "  '84',\n",
       "  '56',\n",
       "  '61',\n",
       "  '60',\n",
       "  '13',\n",
       "  '52',\n",
       "  '28',\n",
       "  '63',\n",
       "  '18',\n",
       "  '46',\n",
       "  '79',\n",
       "  '24',\n",
       "  '30',\n",
       "  '40',\n",
       "  '89',\n",
       "  '08',\n",
       "  '91',\n",
       "  '43',\n",
       "  '03',\n",
       "  '73'],\n",
       " ['70',\n",
       "  '27',\n",
       "  '44',\n",
       "  '22',\n",
       "  '59',\n",
       "  '35',\n",
       "  '62',\n",
       "  '26',\n",
       "  '87',\n",
       "  '77',\n",
       "  '81',\n",
       "  '23',\n",
       "  '39',\n",
       "  '05',\n",
       "  '85',\n",
       "  '41',\n",
       "  '48',\n",
       "  '51',\n",
       "  '15',\n",
       "  '33',\n",
       "  '32',\n",
       "  '65',\n",
       "  '50',\n",
       "  '45',\n",
       "  '68',\n",
       "  '01',\n",
       "  '38',\n",
       "  '34',\n",
       "  '86',\n",
       "  '57',\n",
       "  '42',\n",
       "  '71'],\n",
       " ['72', '37', '04', '53', '76', '02'],\n",
       " ['14', '67', '11', '83', '66', '16'],\n",
       " ['10', '09', '07', '47', '49', '29'],\n",
       " ['36', '19', '64', '31', '69', '90'])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "females_train, males_train, females_val, males_val, females_test, males_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8fd71543-288a-4d2f-a2ef-5052a2bf6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = females_train + males_train \n",
    "val = females_val + males_val \n",
    "test = females_test + males_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8d190771-4f87-4ec2-a095-5da297940388",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_df = Crema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4d729ec9-5ec9-49e4-aeb5-35d374d9e292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, row in CREMA_df.iterrows(): \n",
    "    gender = row['gender']\n",
    "    actor = row['actors']\n",
    "    if actor in train: \n",
    "        CREMA_train.append(row)\n",
    "    elif actor in val: \n",
    "        CREMA_val.append(row)\n",
    "    else:\n",
    "        CREMA_test.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b156d57-0475-4eac-a983-63e4de452039",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_train = pd.DataFrame(CREMA_train) \n",
    "CREMA_val = pd.DataFrame(CREMA_val) \n",
    "CREMA_test = pd.DataFrame(CREMA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "86831353-3b0d-406c-bd7b-1abd6487a964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 4), (60, 4), (60, 4))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREMA_train.shape, CREMA_val.shape, CREMA_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c31de786-edc1-4cde-b150-dea5241ba93b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>actors</th>\n",
       "      <th>gender</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>54</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>28</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>06</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>happy</td>\n",
       "      <td>01</td>\n",
       "      <td>male</td>\n",
       "      <td>/home/helemanc/Desktop/Binary_Model/normalized...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion_label actors  gender  \\\n",
       "0         angry     54  female   \n",
       "1         angry     28  female   \n",
       "3       sadness     06  female   \n",
       "4       disgust     21  female   \n",
       "6         happy     01    male   \n",
       "\n",
       "                                                path  \n",
       "0  /home/helemanc/Desktop/Binary_Model/normalized...  \n",
       "1  /home/helemanc/Desktop/Binary_Model/normalized...  \n",
       "3  /home/helemanc/Desktop/Binary_Model/normalized...  \n",
       "4  /home/helemanc/Desktop/Binary_Model/normalized...  \n",
       "6  /home/helemanc/Desktop/Binary_Model/normalized...  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREMA_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a3562be5-845e-4eeb-8afd-64604415bc24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = CREMA_train.reset_index(drop=True) \n",
    "df_val = CREMA_val.reset_index(drop=True) \n",
    "df_test = CREMA_test.reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a51318-8ef2-467d-93b2-22eff441cabc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f3a0cfa-fb0b-43c6-b9f9-7a57d24793d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'sadness', 'disgust', 'happy', 'fear'], dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['emotion_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d614cb1b-2876-44c7-9390-f4f09e8c6630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Emotions distribution')\n",
    "plt.hist(df_train['emotion_label'])\n",
    "# plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4cae2ff8-349b-4f6c-b7de-ab6688591844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Emotions distribution')\n",
    "plt.hist(df_val['emotion_label'])\n",
    "# plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b4828ae6-e644-47c0-a9b2-f7eb8c7efd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Emotions distribution')\n",
    "plt.hist(df_test['emotion_label'])\n",
    "# plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c08dbf4b-1f57-410f-9c07-aacb9b4faba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 4)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ec6b3-d60f-44a2-aaa9-c32337dc1672",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8067b8df-62af-49e8-8e2b-d12af2fac586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(df):\n",
    "    X = []\n",
    "    for i in tqdm(df['path']): \n",
    "        X.append(librosa.load(i, res_type='kaiser_fast', sr=16000))\n",
    "    return X\n",
    "\n",
    "def extract_samples(X): \n",
    "    samples = []\n",
    "    for ind,i in enumerate(X):\n",
    "        samples.append(i[0])\n",
    "    return samples \n",
    "\n",
    "def extract_labels(df): \n",
    "    labels = df['emotion_label'].copy()\n",
    "    return labels \n",
    "\n",
    "def compute_lengths(samples): \n",
    "    lengths = [len(x) for x in samples]\n",
    "    return lengths \n",
    "\n",
    "def check_outliers(lengths):\n",
    "    # outliers\n",
    "    lengths = np.array(lengths)\n",
    "    print((lengths > 300000).sum())\n",
    "    new_lengths = lengths[lengths < 300000]\n",
    "    return new_lengths \n",
    "\n",
    "def compute_mean_length(lengths): \n",
    "    return lengths.mean()\n",
    "\n",
    "def cut_and_pad(samples, labels, length_chosen = LENGTH_CHOSEN): \n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    count = 0 \n",
    "    for ind,i in enumerate(samples):\n",
    "        if i.shape[0] < 300000:\n",
    "            if i.shape[0] > length_chosen:\n",
    "                new = i[:length_chosen]\n",
    "                X_new.append(new)\n",
    "            elif i.shape[0] < length_chosen:\n",
    "                new = np.pad(i,math.ceil((length_chosen-i.shape[0])/2), mode='median')\n",
    "                X_new.append(new)\n",
    "            else:\n",
    "                X_new.append(i)\n",
    "            y_new.append(labels[count])\n",
    "        count+=1\n",
    "    \n",
    "    return X_new, y_new\n",
    "\n",
    "# Data Augmentation \n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "# Data Augmentation \n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "    \n",
    "def compute_mfccs(samples): \n",
    "    mfccs = []\n",
    "    for i in tqdm(samples):\n",
    "        mfcc = librosa.feature.mfcc(y=i, sr=16000, n_mfcc=13)\n",
    "        mfcc = mfcc.T\n",
    "        mfcc = np.array(mfcc)\n",
    "        mfccs.append(mfcc[:, 1:])\n",
    "    mfccs = np.array(mfccs)\n",
    "    return mfccs\n",
    "\n",
    "def compute_mfccs_augmentation(samples, labels): \n",
    "    mfccs = []\n",
    "    counter = 0 \n",
    "    for i in tqdm(samples):\n",
    "\n",
    "       # Weiner Filtering on original noise \n",
    "        samples_weiner = scipy.signal.wiener(i)\n",
    "        is_fin = np.isfinite(samples_weiner).all()\n",
    "\n",
    "\n",
    "        # Data Augmentation - Noise \n",
    "        noise_audio = noise(samples_weiner)\n",
    "\n",
    "        # Data Augmentation - Pitch \n",
    "        pitch_audio = pitch(samples_weiner, sampling_rate=16000)\n",
    "\n",
    "\n",
    "        # Data Augmentation -  pitch + noise \n",
    "        pn = pitch(noise_audio, sampling_rate = 16000)\n",
    "\n",
    "\n",
    "        if is_fin: \n",
    "          # MFCC\n",
    "\n",
    "          mfcc = librosa.feature.mfcc(y=i, sr=16000, n_mfcc=13)\n",
    "          mfcc = mfcc.T\n",
    "          mfccs.append(mfcc[:, 1:])\n",
    "\n",
    "          mfcc_augmented = librosa.feature.mfcc(y=samples_weiner, sr=16000, n_mfcc=13)\n",
    "          mfcc_augmented = mfcc_augmented.T\n",
    "          mfccs.append(mfcc_augmented[:, 1:])\n",
    "\n",
    "          mfcc_augmented_pitch = librosa.feature.mfcc(y=noise_audio, sr=16000, n_mfcc=13)\n",
    "          mfcc_augmented_pitch = mfcc_augmented_pitch.T\n",
    "          mfccs.append(mfcc_augmented_pitch[:, 1:])\n",
    "\n",
    "          mfcc_augmented_p = librosa.feature.mfcc(y=pitch_audio, sr=16000, n_mfcc=13)\n",
    "          mfcc_augmented_p = mfcc_augmented_p.T\n",
    "          mfccs.append(mfcc_augmented_p[:, 1:]) \n",
    "\n",
    "          mfcc_augmented_pn = librosa.feature.mfcc(y=pn, sr=16000, n_mfcc=13)\n",
    "          mfcc_augmented_pn = mfcc_augmented_pn.T\n",
    "          mfccs.append(mfcc_augmented_pn[:, 1:]) \n",
    "    \n",
    "    mfccs = np.array(mfccs)\n",
    "    \n",
    "    # Copy labels \n",
    "    y_prov = []\n",
    "    y = labels \n",
    "    for i in range(len(y)): \n",
    "      y_prov.append(y[i])\n",
    "      y_prov.append(y[i])\n",
    "      y_prov.append(y[i])\n",
    "      y_prov.append(y[i])\n",
    "      y_prov.append(y[i])\n",
    "    y = np.asarray(y_prov)\n",
    "\n",
    "    return mfccs, y \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d1627-19c7-4518-ab9d-fbfd010a2a2a",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bffe2f-9fc4-43ab-aa80-ed27e5824e0c",
   "metadata": {},
   "source": [
    "### Load samples and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1d0165d2-012e-4450-9015-08495da6aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 4417.67it/s]\n"
     ]
    }
   ],
   "source": [
    "load_train = load_files(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5641710a-8a89-4f43-9a52-d8667ec07df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = extract_samples(load_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "15b0a17d-1524-4a95-9675-c86e8084ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = extract_labels(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4feb28e-7b16-4c1e-9f2e-c17ae83cbf54",
   "metadata": {},
   "source": [
    "### Decide length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9d18fada-2ad5-4c83-8700-5b9830a81ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = compute_lengths(samples_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3b7643fa-1054-4025-92b0-128eb10cd45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "new_lengths = check_outliers(lengths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3468daff-1597-4227-b51c-c7944ed12ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_length = compute_mean_length(new_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6d1627dc-e927-46f2-b7bf-66647e6f8997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38324.953125"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a248f94-247c-4920-b112-60cd8ef78f41",
   "metadata": {},
   "source": [
    "### Cut and Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9dfbd9e1-ae0d-436d-bfa6-183a8d405530",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train, labels_train = cut_and_pad(samples_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a0922a50-57e7-481b-8023-e693c8fca809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,) (320,)\n"
     ]
    }
   ],
   "source": [
    "samples_train = np.array(samples_train)\n",
    "labels_train = np.array(labels_train)\n",
    "print(samples_train.shape, labels_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0444b7a-04ba-4e9d-bb60-07f088adb34d",
   "metadata": {},
   "source": [
    "### Feature Extraction - Without Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7d0f121c-90e2-4e0f-9602-04630ac404c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 320/320 [00:05<00:00, 59.18it/s]\n"
     ]
    }
   ],
   "source": [
    "mfccs_train = compute_mfccs(samples_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "579e8132-25e4-4b62-ba92-e48b3ceeba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 248, 12)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f7b87-e836-4a3d-bbfa-2c7a54e44f63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ee281-2c95-49a8-951e-a7aaca6b762e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4f0ba2f8-0340-4f8a-90f3-2f904bd2f305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 3206.82it/s]\n"
     ]
    }
   ],
   "source": [
    "load_val = load_files(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "59ebf1c4-3a8e-409c-b519-1d1935803a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_val = extract_samples(load_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "be0a6dde-ea61-4156-90dd-fb2091335a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_val = extract_labels(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c4043d-89ea-4a87-8bcd-205d79b93b76",
   "metadata": {},
   "source": [
    "### Cut and Pad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "92cfc06e-2ede-462e-9b2f-70ea01ae9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_val, labels_val = cut_and_pad(samples_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d7eb50aa-9c9c-4329-9983-9522ef6dd628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,) (60,)\n"
     ]
    }
   ],
   "source": [
    "samples_val = np.array(samples_val)\n",
    "labels_val = np.array(labels_val)\n",
    "print(samples_val.shape, labels_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a5782-c8a6-43d8-880e-90e345e71cfe",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c07a2608-156d-414a-aa89-428848c03be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:00<00:00, 64.55it/s]\n"
     ]
    }
   ],
   "source": [
    "mfccs_val = compute_mfccs(samples_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e2deea2f-0f7b-4365-a396-e936922770d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 248, 12)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27467b3-aaf2-4c47-be82-7569647111b7",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16ef33-129b-4f43-9a6b-fceb239f8b7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e720f752-c489-4057-9146-a11a3c3c8ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 2365.12it/s]\n"
     ]
    }
   ],
   "source": [
    "load_test = load_files(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "48a4e953-c18e-44e3-a6d1-33ef8fec1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_test = extract_samples(load_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b3d49c36-647e-4848-87e6-d0d361c63ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_test = extract_labels(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2186414-a156-4acb-9ae1-06529f7481cb",
   "metadata": {},
   "source": [
    "### Cut and Pad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "07f07117-0afc-41f7-82e8-2ef3aebb51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_test, labels_test = cut_and_pad(samples_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ebc3110f-5429-4a4e-994f-f2906baffe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,) (60,)\n"
     ]
    }
   ],
   "source": [
    "samples_test = np.array(samples_test)\n",
    "labels_test = np.array(labels_test)\n",
    "print(samples_test.shape, labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c2d0d-5101-4024-b4c8-6f72f66910a8",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e8d6bf27-eb9d-483d-bb91-3465f1c31636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [00:00<00:00, 61.42it/s]\n"
     ]
    }
   ],
   "source": [
    "mfccs_test = compute_mfccs(samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "971a0732-03f4-44f4-9354-4b3bccaa528c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 248, 12)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a359d-f6ed-460e-a48b-52ca6175fa8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Encode Labels - Binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "15088a4c-11ea-4c05-902f-a49e34f84b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_enc = {'fear':1, 'disgust':1, 'neutral':0, 'calm':0,  'happy':0, 'sadness':1, 'surprise':0, 'angry':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eaa82ae2-e8a0-4d31-903d-9128937002be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.Series(labels_train).replace(emotion_enc)\n",
    "#y_train_aug = pd.Series(labels_train_aug).map(emotion_enc)\n",
    "y_val = pd.Series(labels_val).map(emotion_enc)\n",
    "y_test = pd.Series(labels_test).map(emotion_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15cce79-ae08-4b8a-bf26-7db980afae47",
   "metadata": {},
   "source": [
    "# Train, Val, Test (X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7f500d99-c7dd-4f33-ac59-12881b6f6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mfccs_train\n",
    "#X_train_aug = mfccs_train_aug \n",
    "X_val = mfccs_val\n",
    "X_test = mfccs_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bda52c-e4f3-4cbe-b3ec-9b60a5b5a6e1",
   "metadata": {},
   "source": [
    "# Standard Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e20bee-3bdc-4a0a-92d3-e05e07df0663",
   "metadata": {},
   "source": [
    "## Without Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1f9ba1a4-4a43-4834-ae57-4b1afb4e8345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d04ac-e73b-4691-b1b3-fc57ac01e5c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0c97aff-9c66-4d9b-94d8-22c48cc8f68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:54:04.141551: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-25 14:54:04.141878: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 248, 256)          21760     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 248, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 62, 128)           163968    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 308,737\n",
      "Trainable params: 308,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv1D(256, 7,padding='same',\n",
    "                 input_shape=(248,12), kernel_initializer=tf.keras.initializers.HeNormal(seed=0)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "model.add(layers.Dropout(0.6))\n",
    "\n",
    "model.add(layers.Conv1D(128, 5,padding='same', kernel_initializer=tf.keras.initializers.HeNormal(seed=0)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,  kernel_initializer=tf.keras.initializers.HeNormal(seed=0)))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dc970-6748-4423-8b22-691ff3db58a4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f04923-ffe2-42a6-ae52-e810aef857b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Without Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6766f0f-4e5b-44bd-939e-1c942475cc1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805c6b5-9aea-40e8-8491-4042ce91d6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e95a582f-d779-411c-8523-f9452d9638dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"/home/helemanc/Desktop/Binary_Model/weights/binary_model_l1l2.hdf5\"\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                                 factor=0.5, patience=4, \n",
    "                                                 verbose=1, mode='max', \n",
    "                                                 min_lr=0.00001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=45, \n",
    "                                              verbose=1)\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=weight_path, \n",
    "                                                      save_weights_only=True, \n",
    "                                                      monitor='val_accuracy', \n",
    "                                                      mode='max', \n",
    "                                                      save_best_only=True)\n",
    "# classweight \n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "017f2884-d4c3-43bc-8a9c-6f98d8743485",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50996d4e-6586-486f-9eed-241b40b51ec2",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a802e05-28de-4ae2-a16d-ee343c4fb0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:54:23.723125: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-25 14:54:23.741388: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 6.5920 - accuracy: 0.6174 - val_loss: 0.9007 - val_accuracy: 0.7167\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 1.7802 - accuracy: 0.6468 - val_loss: 0.6884 - val_accuracy: 0.5667\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 1.5292 - accuracy: 0.6131 - val_loss: 0.4243 - val_accuracy: 0.7833\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.1922 - accuracy: 0.6641 - val_loss: 0.4493 - val_accuracy: 0.8167\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.7189 - val_loss: 0.4593 - val_accuracy: 0.8000\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.7418 - val_loss: 0.4950 - val_accuracy: 0.7833\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7775 - val_loss: 0.4800 - val_accuracy: 0.8333\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7461 - val_loss: 0.7069 - val_accuracy: 0.5500\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.6874 - val_loss: 0.3835 - val_accuracy: 0.8667\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.8080 - val_loss: 0.5482 - val_accuracy: 0.6500\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.7290 - val_loss: 0.7065 - val_accuracy: 0.5500\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7376 - val_loss: 0.4285 - val_accuracy: 0.7833\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7572 - val_loss: 0.5083 - val_accuracy: 0.7833\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.7954 - val_loss: 0.4960 - val_accuracy: 0.7833\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.7851 - val_loss: 0.3757 - val_accuracy: 0.8500\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8415 - val_loss: 0.3539 - val_accuracy: 0.8667\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.8363 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7892 - val_loss: 0.4154 - val_accuracy: 0.8167\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7763 - val_loss: 0.3986 - val_accuracy: 0.8000\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8288 - val_loss: 0.4581 - val_accuracy: 0.8167\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.3284 - accuracy: 0.8061 - val_loss: 0.4175 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8131 - val_loss: 0.3728 - val_accuracy: 0.8500\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3068 - accuracy: 0.8637 - val_loss: 0.3671 - val_accuracy: 0.8167\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8494 - val_loss: 0.3705 - val_accuracy: 0.8333\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3140 - accuracy: 0.8624 - val_loss: 0.3773 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3557 - accuracy: 0.8492 - val_loss: 0.3655 - val_accuracy: 0.8333\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.8473 - val_loss: 0.3748 - val_accuracy: 0.8167\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8667 - val_loss: 0.3638 - val_accuracy: 0.8333\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8154 - val_loss: 0.3604 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8232 - val_loss: 0.3569 - val_accuracy: 0.8333\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2517 - accuracy: 0.8825 - val_loss: 0.3598 - val_accuracy: 0.8167\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2692 - accuracy: 0.8759 - val_loss: 0.3623 - val_accuracy: 0.8167\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2162 - accuracy: 0.8876 - val_loss: 0.3507 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.8592 - val_loss: 0.3590 - val_accuracy: 0.8167\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2918 - accuracy: 0.8685 - val_loss: 0.3537 - val_accuracy: 0.8167\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8172 - val_loss: 0.3541 - val_accuracy: 0.8167\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2811 - accuracy: 0.8739 - val_loss: 0.3519 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2357 - accuracy: 0.8975 - val_loss: 0.3465 - val_accuracy: 0.8500\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3015 - accuracy: 0.8576 - val_loss: 0.3495 - val_accuracy: 0.8167\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2664 - accuracy: 0.9134 - val_loss: 0.3494 - val_accuracy: 0.8167\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3014 - accuracy: 0.8320 - val_loss: 0.3509 - val_accuracy: 0.8167\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8389 - val_loss: 0.3524 - val_accuracy: 0.8167\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3589 - accuracy: 0.7973 - val_loss: 0.3536 - val_accuracy: 0.8167\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8534 - val_loss: 0.3496 - val_accuracy: 0.8167\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2537 - accuracy: 0.8864 - val_loss: 0.3475 - val_accuracy: 0.8167\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2906 - accuracy: 0.8735 - val_loss: 0.3455 - val_accuracy: 0.8333\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2462 - accuracy: 0.8687 - val_loss: 0.3452 - val_accuracy: 0.8167\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2837 - accuracy: 0.8780 - val_loss: 0.3446 - val_accuracy: 0.8167\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8927 - val_loss: 0.3509 - val_accuracy: 0.8000\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2380 - accuracy: 0.8493 - val_loss: 0.3428 - val_accuracy: 0.8333\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2523 - accuracy: 0.8801 - val_loss: 0.3389 - val_accuracy: 0.8333\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2380 - accuracy: 0.8683 - val_loss: 0.3338 - val_accuracy: 0.8333\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3214 - accuracy: 0.8811 - val_loss: 0.3400 - val_accuracy: 0.8167\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.8752 - val_loss: 0.3384 - val_accuracy: 0.8333\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8089 - val_loss: 0.3425 - val_accuracy: 0.8167\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.8872 - val_loss: 0.3370 - val_accuracy: 0.8167\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2545 - accuracy: 0.8727 - val_loss: 0.3400 - val_accuracy: 0.8167\n",
      "Epoch 58/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9332 - val_loss: 0.3411 - val_accuracy: 0.8167\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8351 - val_loss: 0.3387 - val_accuracy: 0.8167\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2793 - accuracy: 0.8829 - val_loss: 0.3352 - val_accuracy: 0.8333\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2574 - accuracy: 0.8613 - val_loss: 0.3330 - val_accuracy: 0.8333\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2377 - accuracy: 0.9229 - val_loss: 0.3343 - val_accuracy: 0.8167\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.8806 - val_loss: 0.3380 - val_accuracy: 0.8167\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8386 - val_loss: 0.3414 - val_accuracy: 0.8167\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.8995 - val_loss: 0.3442 - val_accuracy: 0.8167\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3030 - accuracy: 0.8319 - val_loss: 0.3464 - val_accuracy: 0.8167\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2754 - accuracy: 0.8675 - val_loss: 0.3453 - val_accuracy: 0.8167\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2773 - accuracy: 0.8747 - val_loss: 0.3446 - val_accuracy: 0.8167\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.8901 - val_loss: 0.3423 - val_accuracy: 0.8167\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8556 - val_loss: 0.3389 - val_accuracy: 0.8167\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2558 - accuracy: 0.8768 - val_loss: 0.3425 - val_accuracy: 0.8167\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.8794 - val_loss: 0.3464 - val_accuracy: 0.8167\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.8810 - val_loss: 0.3445 - val_accuracy: 0.8167\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3011 - accuracy: 0.8695 - val_loss: 0.3419 - val_accuracy: 0.8167\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2572 - accuracy: 0.8537 - val_loss: 0.3366 - val_accuracy: 0.8167\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2451 - accuracy: 0.8930 - val_loss: 0.3383 - val_accuracy: 0.8167\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8951 - val_loss: 0.3391 - val_accuracy: 0.8167\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.8475 - val_loss: 0.3352 - val_accuracy: 0.8167\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1648 - accuracy: 0.9051 - val_loss: 0.3325 - val_accuracy: 0.8167\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8555 - val_loss: 0.3376 - val_accuracy: 0.8167\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2488 - accuracy: 0.8968 - val_loss: 0.3365 - val_accuracy: 0.8167\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2344 - accuracy: 0.8838 - val_loss: 0.3351 - val_accuracy: 0.8167\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2121 - accuracy: 0.9103 - val_loss: 0.3356 - val_accuracy: 0.8167\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.8886 - val_loss: 0.3332 - val_accuracy: 0.8167\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2391 - accuracy: 0.8677 - val_loss: 0.3321 - val_accuracy: 0.8167\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1998 - accuracy: 0.9074 - val_loss: 0.3321 - val_accuracy: 0.8167\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8863 - val_loss: 0.3335 - val_accuracy: 0.8167\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2645 - accuracy: 0.8551 - val_loss: 0.3379 - val_accuracy: 0.8167\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2204 - accuracy: 0.9016 - val_loss: 0.3360 - val_accuracy: 0.8167\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.8824 - val_loss: 0.3272 - val_accuracy: 0.8167\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.8971 - val_loss: 0.3322 - val_accuracy: 0.8167\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2328 - accuracy: 0.9050 - val_loss: 0.3312 - val_accuracy: 0.8167\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8568 - val_loss: 0.3346 - val_accuracy: 0.8167\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.8382 - val_loss: 0.3287 - val_accuracy: 0.8167\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2510 - accuracy: 0.9104 - val_loss: 0.3301 - val_accuracy: 0.8167\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2800 - accuracy: 0.9060 - val_loss: 0.3291 - val_accuracy: 0.8167\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1954 - accuracy: 0.9162 - val_loss: 0.3255 - val_accuracy: 0.8167\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2391 - accuracy: 0.9202 - val_loss: 0.3275 - val_accuracy: 0.8167\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2069 - accuracy: 0.9081 - val_loss: 0.3255 - val_accuracy: 0.8167\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 0.8471 - val_loss: 0.3279 - val_accuracy: 0.8167\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2415 - accuracy: 0.8911 - val_loss: 0.3259 - val_accuracy: 0.8167\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8559 - val_loss: 0.3290 - val_accuracy: 0.8167\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9161 - val_loss: 0.3295 - val_accuracy: 0.8167\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9274 - val_loss: 0.3275 - val_accuracy: 0.8167\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8755 - val_loss: 0.3290 - val_accuracy: 0.8167\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.8932 - val_loss: 0.3318 - val_accuracy: 0.8000\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1939 - accuracy: 0.9263 - val_loss: 0.3272 - val_accuracy: 0.8000\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1896 - accuracy: 0.9212 - val_loss: 0.3290 - val_accuracy: 0.8000\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2130 - accuracy: 0.9316 - val_loss: 0.3270 - val_accuracy: 0.8000\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1953 - accuracy: 0.9155 - val_loss: 0.3271 - val_accuracy: 0.8000\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9054 - val_loss: 0.3238 - val_accuracy: 0.8000\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1800 - accuracy: 0.9051 - val_loss: 0.3223 - val_accuracy: 0.8167\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2313 - accuracy: 0.8696 - val_loss: 0.3210 - val_accuracy: 0.8167\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8915 - val_loss: 0.3215 - val_accuracy: 0.8167\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3128 - accuracy: 0.8414 - val_loss: 0.3192 - val_accuracy: 0.8167\n",
      "Epoch 116/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2640 - accuracy: 0.8978 - val_loss: 0.3221 - val_accuracy: 0.8167\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.8809 - val_loss: 0.3182 - val_accuracy: 0.8333\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2627 - accuracy: 0.8971 - val_loss: 0.3230 - val_accuracy: 0.8333\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2284 - accuracy: 0.8952 - val_loss: 0.3207 - val_accuracy: 0.8333\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2079 - accuracy: 0.9063 - val_loss: 0.3233 - val_accuracy: 0.8333\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2968 - accuracy: 0.8737 - val_loss: 0.3200 - val_accuracy: 0.8333\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.8804 - val_loss: 0.3241 - val_accuracy: 0.8000\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.8824 - val_loss: 0.3262 - val_accuracy: 0.8000\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.8789 - val_loss: 0.3238 - val_accuracy: 0.8167\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2652 - accuracy: 0.8919 - val_loss: 0.3198 - val_accuracy: 0.8500\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.1883 - accuracy: 0.9196 - val_loss: 0.3200 - val_accuracy: 0.8333\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2811 - accuracy: 0.8836 - val_loss: 0.3213 - val_accuracy: 0.8333\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.3145 - accuracy: 0.8748 - val_loss: 0.3232 - val_accuracy: 0.8333\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 0.2229 - accuracy: 0.8944 - val_loss: 0.3223 - val_accuracy: 0.8333\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.9138 - val_loss: 0.3271 - val_accuracy: 0.8167\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2757 - accuracy: 0.8657 - val_loss: 0.3243 - val_accuracy: 0.8333\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 0.2310 - accuracy: 0.8860 - val_loss: 0.3197 - val_accuracy: 0.8333\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2704 - accuracy: 0.8633 - val_loss: 0.3174 - val_accuracy: 0.8333\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2151 - accuracy: 0.9034 - val_loss: 0.3161 - val_accuracy: 0.8333\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1892 - accuracy: 0.9371 - val_loss: 0.3181 - val_accuracy: 0.8333\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2839 - accuracy: 0.8483 - val_loss: 0.3150 - val_accuracy: 0.8500\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.9326 - val_loss: 0.3144 - val_accuracy: 0.8667\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.9060 - val_loss: 0.3184 - val_accuracy: 0.8333\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.1997 - accuracy: 0.9309 - val_loss: 0.3167 - val_accuracy: 0.8333\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2028 - accuracy: 0.9208 - val_loss: 0.3178 - val_accuracy: 0.8333\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8816 - val_loss: 0.3208 - val_accuracy: 0.8167\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8889 - val_loss: 0.3244 - val_accuracy: 0.8000\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2352 - accuracy: 0.8864 - val_loss: 0.3208 - val_accuracy: 0.8167\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.8537 - val_loss: 0.3206 - val_accuracy: 0.8167\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2369 - accuracy: 0.9146 - val_loss: 0.3199 - val_accuracy: 0.8167\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.1938 - accuracy: 0.8764 - val_loss: 0.3124 - val_accuracy: 0.8333\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2444 - accuracy: 0.8838 - val_loss: 0.3149 - val_accuracy: 0.8167\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9140 - val_loss: 0.3149 - val_accuracy: 0.8167\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.8723 - val_loss: 0.3114 - val_accuracy: 0.8333\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.8862 - val_loss: 0.3089 - val_accuracy: 0.8500\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.8708 - val_loss: 0.3063 - val_accuracy: 0.8500\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1791 - accuracy: 0.9095 - val_loss: 0.3083 - val_accuracy: 0.8333\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.9032 - val_loss: 0.3082 - val_accuracy: 0.8500\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2211 - accuracy: 0.9148 - val_loss: 0.3074 - val_accuracy: 0.8500\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3032 - accuracy: 0.9047 - val_loss: 0.3124 - val_accuracy: 0.8167\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2091 - accuracy: 0.9139 - val_loss: 0.3165 - val_accuracy: 0.8000\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.8825 - val_loss: 0.3128 - val_accuracy: 0.8000\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2682 - accuracy: 0.8660 - val_loss: 0.3087 - val_accuracy: 0.8333\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2677 - accuracy: 0.8751 - val_loss: 0.3124 - val_accuracy: 0.8000\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2929 - accuracy: 0.9057 - val_loss: 0.3187 - val_accuracy: 0.8000\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.8997 - val_loss: 0.3163 - val_accuracy: 0.8000\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2368 - accuracy: 0.8614 - val_loss: 0.3127 - val_accuracy: 0.8000\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8686 - val_loss: 0.3155 - val_accuracy: 0.8000\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2340 - accuracy: 0.8714 - val_loss: 0.3130 - val_accuracy: 0.8000\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2661 - accuracy: 0.8510 - val_loss: 0.3183 - val_accuracy: 0.8000\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.8988 - val_loss: 0.3202 - val_accuracy: 0.8000\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1857 - accuracy: 0.9016 - val_loss: 0.3184 - val_accuracy: 0.8000\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2257 - accuracy: 0.9070 - val_loss: 0.3191 - val_accuracy: 0.8000\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.8676 - val_loss: 0.3200 - val_accuracy: 0.8000\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8394 - val_loss: 0.3206 - val_accuracy: 0.8000\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2475 - accuracy: 0.8947 - val_loss: 0.3232 - val_accuracy: 0.8000\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2124 - accuracy: 0.8990 - val_loss: 0.3163 - val_accuracy: 0.8000\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2132 - accuracy: 0.9129 - val_loss: 0.3140 - val_accuracy: 0.8167\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2542 - accuracy: 0.9147 - val_loss: 0.3169 - val_accuracy: 0.8000\n",
      "Epoch 175/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2032 - accuracy: 0.9263 - val_loss: 0.3158 - val_accuracy: 0.8000\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9356 - val_loss: 0.3151 - val_accuracy: 0.8000\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9337 - val_loss: 0.3144 - val_accuracy: 0.8000\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1512 - accuracy: 0.9361 - val_loss: 0.3146 - val_accuracy: 0.8000\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2625 - accuracy: 0.8947 - val_loss: 0.3176 - val_accuracy: 0.8000\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9146 - val_loss: 0.3125 - val_accuracy: 0.8167\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.9407 - val_loss: 0.3171 - val_accuracy: 0.8000\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1960 - accuracy: 0.9336 - val_loss: 0.3157 - val_accuracy: 0.8000\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2812 - accuracy: 0.9198 - val_loss: 0.3150 - val_accuracy: 0.8000\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.9178 - val_loss: 0.3124 - val_accuracy: 0.8167\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9191 - val_loss: 0.3131 - val_accuracy: 0.8167\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1563 - accuracy: 0.9117 - val_loss: 0.3106 - val_accuracy: 0.8167\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8774 - val_loss: 0.3143 - val_accuracy: 0.8333\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2034 - accuracy: 0.8852 - val_loss: 0.3105 - val_accuracy: 0.8333\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9015 - val_loss: 0.3094 - val_accuracy: 0.8333\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.9041 - val_loss: 0.3131 - val_accuracy: 0.8167\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2710 - accuracy: 0.8866 - val_loss: 0.3102 - val_accuracy: 0.8333\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2471 - accuracy: 0.8918 - val_loss: 0.3091 - val_accuracy: 0.8333\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9302 - val_loss: 0.3073 - val_accuracy: 0.8333\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1402 - accuracy: 0.9407 - val_loss: 0.3069 - val_accuracy: 0.8333\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2274 - accuracy: 0.9024 - val_loss: 0.3114 - val_accuracy: 0.8333\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.1917 - accuracy: 0.9220 - val_loss: 0.3116 - val_accuracy: 0.8333\n",
      "Epoch 00196: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=4, epochs=500, validation_data=(X_val, y_val),\n",
    "           callbacks=[reduce_lr, early_stop, model_checkpoint], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffb781-ceb3-47fd-892e-4f4a70cd16a3",
   "metadata": {},
   "source": [
    "### Plot Training Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de674de6-acb2-429b-b47f-8fe0b42c234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c907d656-03e2-4a60-9314-c263e318b977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01529e-3a7d-47f1-bdd2-24a8751f2cf0",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e7d753-34c0-4ca7-a330-875b49f4d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/home/helemanc/Desktop/Binary_Model/models/binary_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ba078-7eb9-4605-b35a-1f2db5204fda",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c675722-fe56-4715-8682-5ef7ecd37006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = tf.keras.models.load_model(\"/home/helemanc/Desktop/Binary_Model/models/binary_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f600a532-28df-40a4-9e7b-c109baa72538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.353274941444397, 0.8333333134651184]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58ef3599-640e-4b6a-8c88-665a27e940e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58        12\n",
      "           1       0.90      0.90      0.90        48\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.74      0.74      0.74        60\n",
      "weighted avg       0.83      0.83      0.83        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "pred = [1 * (x[0]>=0.50) for x in predictions] #0.5 o 0.52? \n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10e07c-8df4-4ca6-b660-a49f2bc67073",
   "metadata": {},
   "source": [
    "# Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2d5e5-806c-4fbf-9edb-f21c0f72ff27",
   "metadata": {},
   "source": [
    "## Initializer, Batch Size, Learning Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f0bfeb9b-8f28-45f3-8a79-540e07b281cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model( init_mode='glorot_uniform', lr = 0.001):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv1D(256, 5,padding='same',\n",
    "                     input_shape=(248,12), kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "\n",
    "    model.add(layers.Conv1D(128, 5,padding='same', kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, kernel_initializer=init_mode))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr = lr) , \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6fc0c437-b576-4f1b-9ad1-777fe97fa1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_path = \"/home/helemanc/Desktop/Binary_Model/weights/binary_model_l1l2.hdf5\"\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                                                 factor=0.5, patience=4, \n",
    "                                                 verbose=1, mode='max', \n",
    "                                                 min_lr=0.000001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=45, \n",
    "                                              verbose=1, restore_best_weights = True)\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=weight_path, \n",
    "                                                      save_weights_only=True, \n",
    "                                                      monitor='val_accuracy', \n",
    "                                                      mode='max', \n",
    "                                                      save_best_only=True)\n",
    "# classweight \n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8c73fa5c-9ce2-494f-a16d-e6a0f5b28090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 16:26:29.707752: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-30 16:26:29.707960: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-30 16:26:29.762280: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-30 16:26:29.762443: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-30 16:26:29.818979: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-30 16:26:29.819119: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-30 16:26:29.826402: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-30 16:26:29.826537: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-30 16:26:29.863608: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-30 16:26:29.863749: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-30 16:26:29.903987: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-30 16:26:29.903987: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-30 16:26:29.904008: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-30 16:26:29.904320: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-30 16:26:30.103387: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-30 16:26:30.103531: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-08-30 16:26:31.661748: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.662771: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 16:26:31.739524: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-30 16:26:31.739685: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 16:26:31.740111: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:26:31.740506: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.747161: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.748583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 16:26:31.759285: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.760163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 16:26:31.813192: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.814050: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 16:26:31.862416: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-30 16:26:31.862477: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 16:26:31.862847: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:26:31.863146: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.881580: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-30 16:26:31.881874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 16:26:31.885364: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:26:31.885904: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.900471: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-30 16:26:31.900734: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 16:26:31.900996: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:26:31.901300: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.929746: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.930970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 16:26:31.944378: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.946494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 16:26:31.947599: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:26:31.948055: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-30 16:26:31.979008: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:31.979972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 16:26:32.058188: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:26:32.059075: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-30 16:26:32.066496: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-30 16:26:32.066703: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 16:26:32.067030: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:26:32.067496: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:32.080272: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-30 16:26:32.080276: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-30 16:26:32.080309: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 16:26:32.080309: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 16:26:32.080550: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:26:32.080553: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:26:32.080828: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:32.080831: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:32.082057: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:32.082720: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:26:32.083202: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-30 16:26:32.083721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-30 16:26:32.098991: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:26:32.099428: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-30 16:26:32.169979: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-08-30 16:26:32.170284: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (helemanc-Latitude-5410): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 16:26:32.170637: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:26:32.171042: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:26:32.276305: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:26:32.277050: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-30 16:26:32.292811: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:26:32.293743: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-30 16:26:32.306249: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:26:32.306924: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n",
      "2021-08-30 16:26:32.380267: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:26:32.380870: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 - 2s - loss: 0.8222 - accuracy: 0.5540\n",
      "Epoch 1/50\n",
      "14/14 - 2s - loss: 0.7910 - accuracy: 0.6056\n",
      "Epoch 1/50\n",
      "54/54 - 2s - loss: 0.7380 - accuracy: 0.5728\n",
      "Epoch 1/50\n",
      "14/14 - 3s - loss: 0.7551 - accuracy: 0.5654\n",
      "Epoch 1/50\n",
      "14/14 - 3s - loss: 0.9023 - accuracy: 0.5258\n",
      "Epoch 2/50\n",
      "14/14 - 2s - loss: 0.7337 - accuracy: 0.5399\n",
      "Epoch 2/50\n",
      "14/14 - 2s - loss: 0.8391 - accuracy: 0.4977\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 0.8436 - accuracy: 0.4626\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 0.7199 - accuracy: 0.4977\n",
      "Epoch 2/50\n",
      "54/54 - 2s - loss: 0.7004 - accuracy: 0.6056\n",
      "Epoch 1/50\n",
      "14/14 - 4s - loss: 1.0419 - accuracy: 0.5258\n",
      "Epoch 2/50\n",
      "14/14 - 2s - loss: 0.7901 - accuracy: 0.5514\n",
      "Epoch 2/50\n",
      "14/14 - 1s - loss: 0.7680 - accuracy: 0.6338\n",
      "Epoch 3/50\n",
      "14/14 - 2s - loss: 0.7661 - accuracy: 0.5869\n",
      "Epoch 3/50\n",
      "14/14 - 2s - loss: 0.8595 - accuracy: 0.6573\n",
      "Epoch 2/50\n",
      "54/54 - 2s - loss: 0.7007 - accuracy: 0.6355\n",
      "Epoch 2/50\n",
      "54/54 - 2s - loss: 0.6276 - accuracy: 0.7230\n",
      "Epoch 2/50\n",
      "14/14 - 2s - loss: 0.6063 - accuracy: 0.7418\n",
      "Epoch 3/50\n",
      "54/54 - 2s - loss: 0.6792 - accuracy: 0.5822\n",
      "Epoch 3/50\n",
      "14/14 - 2s - loss: 0.7768 - accuracy: 0.5374\n",
      "Epoch 3/50\n",
      "14/14 - 2s - loss: 0.5538 - accuracy: 0.7324\n",
      "Epoch 4/50\n",
      "14/14 - 2s - loss: 0.6670 - accuracy: 0.5869\n",
      "Epoch 4/50\n",
      "14/14 - 2s - loss: 0.8651 - accuracy: 0.4789\n",
      "Epoch 3/50\n",
      "54/54 - 2s - loss: 0.6734 - accuracy: 0.5748\n",
      "Epoch 3/50\n",
      "54/54 - 2s - loss: 0.6465 - accuracy: 0.6479\n",
      "Epoch 3/50\n",
      "14/14 - 2s - loss: 0.5674 - accuracy: 0.6808\n",
      "Epoch 4/50\n",
      "54/54 - 2s - loss: 0.6436 - accuracy: 0.6150\n",
      "Epoch 4/50\n",
      "14/14 - 2s - loss: 0.8495 - accuracy: 0.5701\n",
      "Epoch 5/50\n",
      "14/14 - 1s - loss: 0.6843 - accuracy: 0.5962\n",
      "Epoch 4/50\n",
      "14/14 - 2s - loss: 0.5009 - accuracy: 0.7418\n",
      "Epoch 5/50\n",
      "14/14 - 2s - loss: 0.7435 - accuracy: 0.6385\n",
      "Epoch 4/50\n",
      "14/14 - 2s - loss: 0.4304 - accuracy: 0.7840\n",
      "Epoch 4/50\n",
      "54/54 - 2s - loss: 0.6156 - accuracy: 0.6479\n",
      "Epoch 4/50\n",
      "54/54 - 2s - loss: 0.6365 - accuracy: 0.6495\n",
      "Epoch 5/50\n",
      "14/14 - 1s - loss: 0.7858 - accuracy: 0.5374\n",
      "Epoch 5/50\n",
      "14/14 - 2s - loss: 0.4264 - accuracy: 0.7512\n",
      "Epoch 5/50\n",
      "54/54 - 2s - loss: 0.6699 - accuracy: 0.6197\n",
      "Epoch 6/50\n",
      "14/14 - 2s - loss: 0.7952 - accuracy: 0.5446\n",
      "Epoch 6/50\n",
      "14/14 - 2s - loss: 0.7771 - accuracy: 0.6244\n",
      "Epoch 5/50\n",
      "14/14 - 2s - loss: 0.4207 - accuracy: 0.7746\n",
      "Epoch 5/50\n",
      "54/54 - 2s - loss: 0.7295 - accuracy: 0.5841\n",
      "Epoch 5/50\n",
      "54/54 - 2s - loss: 0.5785 - accuracy: 0.6808\n",
      "Epoch 6/50\n",
      "14/14 - 2s - loss: 0.7645 - accuracy: 0.5140\n",
      "Epoch 6/50\n",
      "14/14 - 2s - loss: 0.5436 - accuracy: 0.7418\n",
      "Epoch 7/50\n",
      "14/14 - 2s - loss: 0.7155 - accuracy: 0.6620\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.6469 - accuracy: 0.6620\n",
      "Epoch 7/50\n",
      "14/14 - 2s - loss: 0.6306 - accuracy: 0.6432\n",
      "Epoch 6/50\n",
      "14/14 - 1s - loss: 0.4302 - accuracy: 0.8216\n",
      "Epoch 7/50\n",
      "14/14 - 2s - loss: 0.6936 - accuracy: 0.5748\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.5660 - accuracy: 0.6479\n",
      "Epoch 8/50\n",
      "14/14 - 1s - loss: 0.7425 - accuracy: 0.5775\n",
      "Epoch 7/50\n",
      "14/14 - 2s - loss: 0.4744 - accuracy: 0.8169\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.6153 - accuracy: 0.6495\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.6164 - accuracy: 0.6385\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 8/50\n",
      "14/14 - 1s - loss: 0.6849 - accuracy: 0.6573\n",
      "Epoch 7/50\n",
      "14/14 - 1s - loss: 0.4012 - accuracy: 0.8498\n",
      "Epoch 8/50\n",
      "14/14 - 2s - loss: 0.7820 - accuracy: 0.6729\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.5491 - accuracy: 0.7746\n",
      "Epoch 9/50\n",
      "14/14 - 2s - loss: 0.6614 - accuracy: 0.6056\n",
      "Epoch 8/50\n",
      "14/14 - 2s - loss: 0.3602 - accuracy: 0.8357\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.5914 - accuracy: 0.6589\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.5821 - accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "14/14 - 1s - loss: 0.6272 - accuracy: 0.7136\n",
      "Epoch 8/50\n",
      "14/14 - 1s - loss: 0.3399 - accuracy: 0.8451\n",
      "Epoch 9/50\n",
      "14/14 - 2s - loss: 0.6634 - accuracy: 0.5280\n",
      "Epoch 9/50\n",
      "14/14 - 2s - loss: 0.3444 - accuracy: 0.8263\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.5801 - accuracy: 0.6995\n",
      "Epoch 10/50\n",
      "14/14 - 2s - loss: 0.6985 - accuracy: 0.6526\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.5987 - accuracy: 0.6262\n",
      "Epoch 9/50\n",
      "14/14 - 1s - loss: 0.3712 - accuracy: 0.7934\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.5651 - accuracy: 0.7324\n",
      "Epoch 10/50\n",
      "14/14 - 2s - loss: 0.6367 - accuracy: 0.6620\n",
      "Epoch 10/50\n",
      "14/14 - 2s - loss: 0.7001 - accuracy: 0.6682\n",
      "Epoch 10/50\n",
      "14/14 - 2s - loss: 0.3353 - accuracy: 0.8545\n",
      "Epoch 11/50\n",
      "14/14 - 2s - loss: 0.6659 - accuracy: 0.6291\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.5419 - accuracy: 0.7559\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.6019 - accuracy: 0.6402\n",
      "Epoch 10/50\n",
      "14/14 - 2s - loss: 0.3329 - accuracy: 0.8404\n",
      "Epoch 11/50\n",
      "14/14 - 2s - loss: 0.5987 - accuracy: 0.6667\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.5545 - accuracy: 0.6573\n",
      "Epoch 11/50\n",
      "14/14 - 2s - loss: 0.7564 - accuracy: 0.6168\n",
      "Epoch 11/50\n",
      "14/14 - 2s - loss: 0.2741 - accuracy: 0.8732\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 12/50\n",
      "14/14 - 2s - loss: 0.6181 - accuracy: 0.6291\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.5714 - accuracy: 0.6761\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.5943 - accuracy: 0.6869\n",
      "Epoch 11/50\n",
      "14/14 - 2s - loss: 0.2765 - accuracy: 0.8732\n",
      "Epoch 12/50\n",
      "14/14 - 2s - loss: 0.5869 - accuracy: 0.6854\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.5932 - accuracy: 0.6761\n",
      "Epoch 12/50\n",
      "14/14 - 1s - loss: 0.6794 - accuracy: 0.6495\n",
      "Epoch 12/50\n",
      "14/14 - 2s - loss: 0.3139 - accuracy: 0.8779\n",
      "Epoch 13/50\n",
      "14/14 - 2s - loss: 0.6336 - accuracy: 0.6573\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.5808 - accuracy: 0.6714\n",
      "Epoch 12/50\n",
      "14/14 - 1s - loss: 0.3449 - accuracy: 0.8498\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.5489 - accuracy: 0.6589\n",
      "Epoch 13/50\n",
      "14/14 - 2s - loss: 0.6275 - accuracy: 0.6714\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 13/50\n",
      "14/14 - 2s - loss: 0.6364 - accuracy: 0.6262\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.5526 - accuracy: 0.7089\n",
      "Epoch 14/50\n",
      "14/14 - 1s - loss: 0.6898 - accuracy: 0.6338\n",
      "Epoch 13/50\n",
      "14/14 - 2s - loss: 0.2305 - accuracy: 0.8967\n",
      "Epoch 13/50\n",
      "14/14 - 2s - loss: 0.2390 - accuracy: 0.8779\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.4968 - accuracy: 0.7465\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.5536 - accuracy: 0.6916\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 14/50\n",
      "14/14 - 2s - loss: 0.6110 - accuracy: 0.6808\n",
      "Epoch 14/50\n",
      "14/14 - 2s - loss: 0.6807 - accuracy: 0.6355\n",
      "Epoch 14/50\n",
      "14/14 - 1s - loss: 0.2531 - accuracy: 0.8920\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.5764 - accuracy: 0.6854\n",
      "Epoch 15/50\n",
      "14/14 - 2s - loss: 0.5770 - accuracy: 0.6620\n",
      "Epoch 14/50\n",
      "14/14 - 1s - loss: 0.3255 - accuracy: 0.8075\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.5087 - accuracy: 0.7465\n",
      "Epoch 15/50\n",
      "14/14 - 1s - loss: 0.6040 - accuracy: 0.6714\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.5198 - accuracy: 0.6869\n",
      "Epoch 15/50\n",
      "14/14 - 2s - loss: 0.6509 - accuracy: 0.6075\n",
      "Epoch 15/50\n",
      "14/14 - 2s - loss: 0.2377 - accuracy: 0.8920\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 16/50\n",
      "14/14 - 2s - loss: 0.6869 - accuracy: 0.5869\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.5299 - accuracy: 0.6995\n",
      "Epoch 15/50\n",
      "14/14 - 2s - loss: 0.2839 - accuracy: 0.8920\n",
      "Epoch 16/50\n",
      "14/14 - 1s - loss: 0.6381 - accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "14/14 - 1s - loss: 0.7150 - accuracy: 0.6121\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.5107 - accuracy: 0.7277\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.5887 - accuracy: 0.7196\n",
      "Epoch 16/50\n",
      "14/14 - 2s - loss: 0.3089 - accuracy: 0.8685\n",
      "Epoch 16/50\n",
      "14/14 - 1s - loss: 0.2760 - accuracy: 0.9014\n",
      "Epoch 17/50\n",
      "14/14 - 2s - loss: 0.6033 - accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.4838 - accuracy: 0.7512\n",
      "Epoch 17/50\n",
      "14/14 - 2s - loss: 0.6348 - accuracy: 0.6714\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 17/50\n",
      "14/14 - 2s - loss: 0.6525 - accuracy: 0.6916\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.5246 - accuracy: 0.7887\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.5303 - accuracy: 0.6776\n",
      "Epoch 17/50\n",
      "14/14 - 2s - loss: 0.1959 - accuracy: 0.9202\n",
      "Epoch 17/50\n",
      "14/14 - 2s - loss: 0.2087 - accuracy: 0.9108\n",
      "Epoch 18/50\n",
      "14/14 - 2s - loss: 0.6214 - accuracy: 0.6385\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.5113 - accuracy: 0.7981\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 18/50\n",
      "14/14 - 2s - loss: 0.6517 - accuracy: 0.6291\n",
      "Epoch 18/50\n",
      "14/14 - 2s - loss: 0.6562 - accuracy: 0.6589\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.4673 - accuracy: 0.7887\n",
      "Epoch 18/50\n",
      "14/14 - 2s - loss: 0.2103 - accuracy: 0.9249\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.4977 - accuracy: 0.7243\n",
      "Epoch 18/50\n",
      "14/14 - 1s - loss: 0.1764 - accuracy: 0.9390\n",
      "Epoch 19/50\n",
      "14/14 - 1s - loss: 0.6624 - accuracy: 0.6479\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.5122 - accuracy: 0.6854\n",
      "Epoch 19/50\n",
      "14/14 - 1s - loss: 0.6820 - accuracy: 0.6526\n",
      "Epoch 19/50\n",
      "14/14 - 2s - loss: 0.6409 - accuracy: 0.5935\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.4764 - accuracy: 0.7465\n",
      "Epoch 19/50\n",
      "14/14 - 1s - loss: 0.1479 - accuracy: 0.9343\n",
      "Epoch 19/50\n",
      "14/14 - 2s - loss: 0.1859 - accuracy: 0.9155\n",
      "Epoch 20/50\n",
      "14/14 - 2s - loss: 0.5742 - accuracy: 0.6714\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.5364 - accuracy: 0.7710\n",
      "Epoch 20/50\n",
      "14/14 - 1s - loss: 0.7133 - accuracy: 0.6573\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.4890 - accuracy: 0.7840\n",
      "Epoch 20/50\n",
      "14/14 - 2s - loss: 0.6619 - accuracy: 0.6308\n",
      "Epoch 20/50\n",
      "14/14 - 1s - loss: 0.1597 - accuracy: 0.9343\n",
      "Epoch 20/50\n",
      "14/14 - 2s - loss: 0.2344 - accuracy: 0.8873\n",
      "Epoch 21/50\n",
      "14/14 - 2s - loss: 0.6219 - accuracy: 0.6901\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.5028 - accuracy: 0.7700\n",
      "Epoch 21/50\n",
      "14/14 - 1s - loss: 0.6834 - accuracy: 0.6338\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.5621 - accuracy: 0.6776\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.5156 - accuracy: 0.7136\n",
      "Epoch 21/50\n",
      "14/14 - 1s - loss: 0.6251 - accuracy: 0.6542\n",
      "Epoch 21/50\n",
      "14/14 - 1s - loss: 0.2483 - accuracy: 0.8779\n",
      "Epoch 21/50\n",
      "14/14 - 2s - loss: 0.2008 - accuracy: 0.9014\n",
      "Epoch 22/50\n",
      "14/14 - 1s - loss: 0.6296 - accuracy: 0.6479\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.5390 - accuracy: 0.7465\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 22/50\n",
      "14/14 - 2s - loss: 0.5980 - accuracy: 0.6714\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.4825 - accuracy: 0.7850\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 22/50\n",
      "14/14 - 2s - loss: 0.6367 - accuracy: 0.6215\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.4603 - accuracy: 0.7746\n",
      "Epoch 22/50\n",
      "14/14 - 1s - loss: 0.1715 - accuracy: 0.9484\n",
      "Epoch 23/50\n",
      "14/14 - 2s - loss: 0.4979 - accuracy: 0.7324\n",
      "Epoch 22/50\n",
      "14/14 - 2s - loss: 0.1653 - accuracy: 0.9484\n",
      "Epoch 23/50\n",
      "14/14 - 2s - loss: 0.6127 - accuracy: 0.6995\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.5030 - accuracy: 0.7136\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.5176 - accuracy: 0.7150\n",
      "Epoch 23/50\n",
      "14/14 - 1s - loss: 0.1659 - accuracy: 0.9671\n",
      "Epoch 23/50\n",
      "14/14 - 2s - loss: 0.5084 - accuracy: 0.6776\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.4654 - accuracy: 0.7700\n",
      "Epoch 24/50\n",
      "14/14 - 1s - loss: 0.6029 - accuracy: 0.6808\n",
      "Epoch 23/50\n",
      "14/14 - 2s - loss: 0.1552 - accuracy: 0.9484\n",
      "Epoch 24/50\n",
      "14/14 - 1s - loss: 0.6119 - accuracy: 0.7042\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.4716 - accuracy: 0.7512\n",
      "Epoch 24/50\n",
      "14/14 - 2s - loss: 0.1405 - accuracy: 0.9624\n",
      "Epoch 24/50\n",
      "14/14 - 2s - loss: 0.6372 - accuracy: 0.6495\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.4836 - accuracy: 0.7944\n",
      "Epoch 25/50\n",
      "14/14 - 1s - loss: 0.5653 - accuracy: 0.7136\n",
      "Epoch 24/50\n",
      "14/14 - 2s - loss: 0.1405 - accuracy: 0.9343\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.4718 - accuracy: 0.7653\n",
      "Epoch 25/50\n",
      "14/14 - 2s - loss: 0.6854 - accuracy: 0.6620\n",
      "Epoch 25/50\n",
      "14/14 - 1s - loss: 0.1897 - accuracy: 0.9202\n",
      "Epoch 25/50\n",
      "14/14 - 2s - loss: 0.5949 - accuracy: 0.6776\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.5173 - accuracy: 0.7371\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.4611 - accuracy: 0.7523\n",
      "Epoch 26/50\n",
      "14/14 - 2s - loss: 0.5902 - accuracy: 0.6714\n",
      "Epoch 25/50\n",
      "14/14 - 2s - loss: 0.1519 - accuracy: 0.9202\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.4807 - accuracy: 0.7606\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 26/50\n",
      "14/14 - 2s - loss: 0.5621 - accuracy: 0.7512\n",
      "Epoch 26/50\n",
      "14/14 - 2s - loss: 0.1871 - accuracy: 0.9061\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 26/50\n",
      "14/14 - 2s - loss: 0.5887 - accuracy: 0.6682\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.5040 - accuracy: 0.7465\n",
      "Epoch 27/50\n",
      "14/14 - 2s - loss: 0.5709 - accuracy: 0.6808\n",
      "Epoch 26/50\n",
      "14/14 - 2s - loss: 0.3030 - accuracy: 0.9014\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.4184 - accuracy: 0.7991\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.5210 - accuracy: 0.7418\n",
      "Epoch 27/50\n",
      "14/14 - 2s - loss: 0.7021 - accuracy: 0.6244\n",
      "Epoch 27/50\n",
      "14/14 - 2s - loss: 0.0725 - accuracy: 0.9671\n",
      "Epoch 27/50\n",
      "14/14 - 2s - loss: 0.6458 - accuracy: 0.6215\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.4622 - accuracy: 0.7840\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/50\n",
      "14/14 - 2s - loss: 0.2529 - accuracy: 0.9155\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 28/50\n",
      "14/14 - 2s - loss: 0.5636 - accuracy: 0.6948\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.4293 - accuracy: 0.7897\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.4364 - accuracy: 0.8028\n",
      "Epoch 28/50\n",
      "14/14 - 2s - loss: 0.6567 - accuracy: 0.6667\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 28/50\n",
      "14/14 - 2s - loss: 0.1003 - accuracy: 0.9437\n",
      "Epoch 28/50\n",
      "14/14 - 2s - loss: 0.6256 - accuracy: 0.6636\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.5408 - accuracy: 0.7230\n",
      "Epoch 28/50\n",
      "14/14 - 2s - loss: 0.1643 - accuracy: 0.9014\n",
      "Epoch 29/50\n",
      "14/14 - 2s - loss: 0.6260 - accuracy: 0.6761\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.4489 - accuracy: 0.7710\n",
      "Epoch 29/50\n",
      "14/14 - 2s - loss: 0.6409 - accuracy: 0.6995\n",
      "Epoch 29/50\n",
      "14/14 - 2s - loss: 0.1035 - accuracy: 0.9531\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.4654 - accuracy: 0.7606\n",
      "Epoch 29/50\n",
      "14/14 - 2s - loss: 0.5944 - accuracy: 0.7056\n",
      "Epoch 29/50\n",
      "14/14 - 1s - loss: 0.1046 - accuracy: 0.9624\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.4747 - accuracy: 0.7559\n",
      "Epoch 30/50\n",
      "14/14 - 2s - loss: 0.6552 - accuracy: 0.6385\n",
      "Epoch 30/50\n",
      "14/14 - 2s - loss: 0.6310 - accuracy: 0.6761\n",
      "Epoch 30/50\n",
      "14/14 - 1s - loss: 0.0627 - accuracy: 0.9765\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.4405 - accuracy: 0.7664\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.4599 - accuracy: 0.7793\n",
      "Epoch 30/50\n",
      "14/14 - 2s - loss: 0.7062 - accuracy: 0.5794\n",
      "Epoch 30/50\n",
      "14/14 - 1s - loss: 0.1235 - accuracy: 0.9296\n",
      "Epoch 31/50\n",
      "14/14 - 2s - loss: 0.6240 - accuracy: 0.6526\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.4954 - accuracy: 0.7606\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 31/50\n",
      "14/14 - 2s - loss: 0.6566 - accuracy: 0.7042\n",
      "Epoch 31/50\n",
      "14/14 - 1s - loss: 0.0746 - accuracy: 0.9437\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.3787 - accuracy: 0.8224\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.4868 - accuracy: 0.7559\n",
      "Epoch 31/50\n",
      "14/14 - 2s - loss: 0.5719 - accuracy: 0.6916\n",
      "Epoch 31/50\n",
      "14/14 - 1s - loss: 0.1136 - accuracy: 0.9765\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 32/50\n",
      "14/14 - 2s - loss: 0.5696 - accuracy: 0.6526\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.5150 - accuracy: 0.7512\n",
      "Epoch 32/50\n",
      "14/14 - 1s - loss: 0.0977 - accuracy: 0.9718\n",
      "Epoch 32/50\n",
      "14/14 - 2s - loss: 0.6258 - accuracy: 0.6901\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.3999 - accuracy: 0.8178\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.4978 - accuracy: 0.7418\n",
      "Epoch 32/50\n",
      "14/14 - 2s - loss: 0.6323 - accuracy: 0.6402\n",
      "Epoch 32/50\n",
      "14/14 - 2s - loss: 0.0732 - accuracy: 0.9624\n",
      "Epoch 33/50\n",
      "14/14 - 2s - loss: 0.6480 - accuracy: 0.6573\n",
      "Epoch 33/50\n",
      "14/14 - 1s - loss: 0.0909 - accuracy: 0.9531\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.4982 - accuracy: 0.7840\n",
      "Epoch 33/50\n",
      "14/14 - 2s - loss: 0.5572 - accuracy: 0.7042\n",
      "Epoch 33/50\n",
      "14/14 - 2s - loss: 0.6006 - accuracy: 0.6636\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.4401 - accuracy: 0.8084\n",
      "Epoch 33/50\n",
      "14/14 - 2s - loss: 0.1175 - accuracy: 0.9531\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.5032 - accuracy: 0.7653\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.6326 - accuracy: 0.7042\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.1745 - accuracy: 0.9343\n",
      "Epoch 34/50\n",
      "14/14 - 2s - loss: 0.7030 - accuracy: 0.6573\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.4635 - accuracy: 0.7606\n",
      "Epoch 34/50\n",
      "14/14 - 1s - loss: 0.0788 - accuracy: 0.9718\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 34/50\n",
      "14/14 - 2s - loss: 0.6600 - accuracy: 0.6262\n",
      "Epoch 35/50\n",
      "14/14 - 1s - loss: 0.6360 - accuracy: 0.6432\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.3673 - accuracy: 0.7944\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.4726 - accuracy: 0.7700\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 35/50\n",
      "14/14 - 2s - loss: 0.0658 - accuracy: 0.9718\n",
      "Epoch 35/50\n",
      "14/14 - 2s - loss: 0.6115 - accuracy: 0.6573\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.4444 - accuracy: 0.7840\n",
      "Epoch 35/50\n",
      "14/14 - 2s - loss: 0.1021 - accuracy: 0.9624\n",
      "Epoch 35/50\n",
      "14/14 - 2s - loss: 0.5792 - accuracy: 0.6822\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 36/50\n",
      "14/14 - 2s - loss: 0.6113 - accuracy: 0.7136\n",
      "Epoch 36/50\n",
      "14/14 - 1s - loss: 0.0810 - accuracy: 0.9812\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.4283 - accuracy: 0.8224\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.5041 - accuracy: 0.7183\n",
      "Epoch 36/50\n",
      "14/14 - 2s - loss: 0.6531 - accuracy: 0.6291\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 36/50\n",
      "14/14 - 2s - loss: 0.0615 - accuracy: 0.9671\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.4815 - accuracy: 0.7840\n",
      "Epoch 37/50\n",
      "14/14 - 1s - loss: 0.5748 - accuracy: 0.6761\n",
      "Epoch 36/50\n",
      "14/14 - 2s - loss: 0.6488 - accuracy: 0.6589\n",
      "Epoch 37/50\n",
      "14/14 - 2s - loss: 0.0638 - accuracy: 0.9624\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.3950 - accuracy: 0.8084\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.4390 - accuracy: 0.7840\n",
      "Epoch 37/50\n",
      "14/14 - 1s - loss: 0.6566 - accuracy: 0.6432\n",
      "Epoch 37/50\n",
      "14/14 - 1s - loss: 0.0766 - accuracy: 0.9624\n",
      "Epoch 37/50\n",
      "14/14 - 1s - loss: 0.6196 - accuracy: 0.6776\n",
      "Epoch 38/50\n",
      "14/14 - 1s - loss: 0.6365 - accuracy: 0.6526\n",
      "Epoch 38/50\n",
      "14/14 - 2s - loss: 0.0542 - accuracy: 0.9718\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.4834 - accuracy: 0.7653\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.3612 - accuracy: 0.8271\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.4579 - accuracy: 0.7793\n",
      "Epoch 38/50\n",
      "14/14 - 1s - loss: 0.0646 - accuracy: 0.9906\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 38/50\n",
      "14/14 - 1s - loss: 0.6152 - accuracy: 0.6215\n",
      "Epoch 38/50\n",
      "14/14 - 2s - loss: 0.6076 - accuracy: 0.6761\n",
      "Epoch 39/50\n",
      "14/14 - 2s - loss: 0.4988 - accuracy: 0.7418\n",
      "Epoch 39/50\n",
      "14/14 - 2s - loss: 0.0255 - accuracy: 0.9953\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.4888 - accuracy: 0.7793\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.3711 - accuracy: 0.8598\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.4731 - accuracy: 0.7418\n",
      "Epoch 39/50\n",
      "14/14 - 1s - loss: 0.0487 - accuracy: 0.9718\n",
      "Epoch 39/50\n",
      "14/14 - 2s - loss: 0.5603 - accuracy: 0.6402\n",
      "Epoch 40/50\n",
      "14/14 - 1s - loss: 0.5783 - accuracy: 0.6995\n",
      "Epoch 39/50\n",
      "14/14 - 2s - loss: 0.6115 - accuracy: 0.6573\n",
      "Epoch 40/50\n",
      "14/14 - 2s - loss: 0.0336 - accuracy: 0.9906\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.5183 - accuracy: 0.7136\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.3533 - accuracy: 0.8598\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.4626 - accuracy: 0.7559\n",
      "Epoch 41/50\n",
      "14/14 - 1s - loss: 0.5378 - accuracy: 0.6948\n",
      "Epoch 40/50\n",
      "14/14 - 2s - loss: 0.0656 - accuracy: 0.9577\n",
      "Epoch 40/50\n",
      "14/14 - 2s - loss: 0.6581 - accuracy: 0.6479\n",
      "Epoch 40/50\n",
      "14/14 - 2s - loss: 0.5914 - accuracy: 0.6355\n",
      "Epoch 41/50\n",
      "14/14 - 2s - loss: 0.0430 - accuracy: 0.9812\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.5189 - accuracy: 0.7465\n",
      "Epoch 41/50\n",
      "14/14 - 1s - loss: 0.6196 - accuracy: 0.6620\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.3665 - accuracy: 0.8411\n",
      "Epoch 42/50\n",
      "14/14 - 1s - loss: 0.6023 - accuracy: 0.6620\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.4532 - accuracy: 0.7700\n",
      "Epoch 41/50\n",
      "14/14 - 2s - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "14/14 - 2s - loss: 0.5398 - accuracy: 0.7103\n",
      "Epoch 42/50\n",
      "14/14 - 2s - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "14/14 - 1s - loss: 0.7466 - accuracy: 0.6620\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.4429 - accuracy: 0.7559\n",
      "Epoch 43/50\n",
      "14/14 - 2s - loss: 0.6433 - accuracy: 0.7277\n",
      "Epoch 42/50\n",
      "14/14 - 2s - loss: 0.0318 - accuracy: 0.9953\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.3693 - accuracy: 0.8084\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.4720 - accuracy: 0.7700\n",
      "Epoch 42/50\n",
      "14/14 - 2s - loss: 0.6821 - accuracy: 0.6729\n",
      "Epoch 43/50\n",
      "14/14 - 2s - loss: 0.0528 - accuracy: 0.9718\n",
      "Epoch 43/50\n",
      "14/14 - 1s - loss: 0.6354 - accuracy: 0.6854\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 44/50\n",
      "14/14 - 1s - loss: 0.6556 - accuracy: 0.6620\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.5127 - accuracy: 0.7653\n",
      "Epoch 43/50\n",
      "14/14 - 2s - loss: 0.0449 - accuracy: 0.9812\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.4638 - accuracy: 0.7840\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.3923 - accuracy: 0.8411\n",
      "Epoch 43/50\n",
      "14/14 - 2s - loss: 0.5903 - accuracy: 0.6495\n",
      "Epoch 44/50\n",
      "14/14 - 1s - loss: 0.0418 - accuracy: 0.9906\n",
      "Epoch 44/50\n",
      "14/14 - 1s - loss: 0.6118 - accuracy: 0.6808\n",
      "Epoch 45/50\n",
      "14/14 - 2s - loss: 0.5538 - accuracy: 0.6479\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.4737 - accuracy: 0.7934\n",
      "Epoch 44/50\n",
      "14/14 - 2s - loss: 0.0314 - accuracy: 0.9906\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.4982 - accuracy: 0.7653\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.3718 - accuracy: 0.8224\n",
      "Epoch 44/50\n",
      "14/14 - 2s - loss: 0.6335 - accuracy: 0.6495\n",
      "Epoch 45/50\n",
      "14/14 - 1s - loss: 0.0515 - accuracy: 0.9812\n",
      "Epoch 45/50\n",
      "14/14 - 2s - loss: 0.6296 - accuracy: 0.6197\n",
      "Epoch 46/50\n",
      "14/14 - 2s - loss: 0.5916 - accuracy: 0.6808\n",
      "Epoch 45/50\n",
      "14/14 - 2s - loss: 0.0255 - accuracy: 0.9953\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.5170 - accuracy: 0.7840\n",
      "Epoch 45/50\n",
      "14/14 - 1s - loss: 0.6079 - accuracy: 0.6449\n",
      "Epoch 41/50\n",
      "54/54 - 2s - loss: 0.4551 - accuracy: 0.8122\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.3141 - accuracy: 0.8598\n",
      "Epoch 46/50\n",
      "14/14 - 2s - loss: 0.0505 - accuracy: 0.9859\n",
      "Epoch 46/50\n",
      "14/14 - 2s - loss: 0.5791 - accuracy: 0.6573\n",
      "Epoch 47/50\n",
      "14/14 - 1s - loss: 0.5924 - accuracy: 0.6948\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 46/50\n",
      "14/14 - 1s - loss: 0.0298 - accuracy: 0.9906\n",
      "Epoch 46/50\n",
      "14/14 - 2s - loss: 0.6330 - accuracy: 0.6355\n",
      "Epoch 41/50\n",
      "54/54 - 2s - loss: 0.4741 - accuracy: 0.7793\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 47/50\n",
      "14/14 - 2s - loss: 0.0402 - accuracy: 0.9812\n",
      "Epoch 47/50\n",
      "14/14 - 2s - loss: 0.5247 - accuracy: 0.6714\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.5220 - accuracy: 0.7700\n",
      "Epoch 41/50\n",
      "54/54 - 2s - loss: 0.3326 - accuracy: 0.8505\n",
      "Epoch 48/50\n",
      "14/14 - 2s - loss: 0.5695 - accuracy: 0.6948\n",
      "Epoch 47/50\n",
      "14/14 - 1s - loss: 0.0248 - accuracy: 0.9906\n",
      "Epoch 48/50\n",
      "14/14 - 1s - loss: 0.5532 - accuracy: 0.7089\n",
      "Epoch 47/50\n",
      "14/14 - 2s - loss: 0.6433 - accuracy: 0.6028\n",
      "Epoch 48/50\n",
      "14/14 - 2s - loss: 0.0291 - accuracy: 0.9906\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.4918 - accuracy: 0.7606\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.4543 - accuracy: 0.7981\n",
      "Epoch 49/50\n",
      "14/14 - 1s - loss: 0.5639 - accuracy: 0.6995\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.3017 - accuracy: 0.8551\n",
      "Epoch 48/50\n",
      "14/14 - 1s - loss: 0.0222 - accuracy: 0.9906\n",
      "Epoch 48/50\n",
      "14/14 - 1s - loss: 0.6217 - accuracy: 0.6589\n",
      "Epoch 49/50\n",
      "14/14 - 2s - loss: 0.6279 - accuracy: 0.6901\n",
      "Epoch 49/50\n",
      "14/14 - 2s - loss: 0.0598 - accuracy: 0.9765\n",
      "Epoch 50/50\n",
      "14/14 - 1s - loss: 0.5580 - accuracy: 0.7183\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.3157 - accuracy: 0.8879\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.4722 - accuracy: 0.7746\n",
      "Epoch 44/50\n",
      "54/54 - 2s - loss: 0.4832 - accuracy: 0.7606\n",
      "Epoch 49/50\n",
      "14/14 - 2s - loss: 0.0438 - accuracy: 0.9906\n",
      "Epoch 49/50\n",
      "14/14 - 1s - loss: 0.6170 - accuracy: 0.6682\n",
      "Epoch 50/50\n",
      "14/14 - 1s - loss: 0.6310 - accuracy: 0.6479\n",
      "Epoch 50/50\n",
      "14/14 - 1s - loss: 0.0588 - accuracy: 0.9812\n",
      "7/7 - 1s - loss: 0.6154 - accuracy: 0.6542\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.4635 - accuracy: 0.7559\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 50/50\n",
      "14/14 - 1s - loss: 0.0204 - accuracy: 0.9953\n",
      "Epoch 44/50\n",
      "54/54 - 2s - loss: 0.3301 - accuracy: 0.8505\n",
      "Epoch 45/50\n",
      "54/54 - 2s - loss: 0.4355 - accuracy: 0.7746\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "7/7 - 1s - loss: 0.4174 - accuracy: 0.8037\n",
      "Epoch 50/50\n",
      "14/14 - 1s - loss: 0.5870 - accuracy: 0.6776\n",
      "7/7 - 1s - loss: 0.5928 - accuracy: 0.6636\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.4853 - accuracy: 0.7793\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.5039 - accuracy: 0.7606\n",
      "7/7 - 1s - loss: 0.4854 - accuracy: 0.7944\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.3172 - accuracy: 0.8551\n",
      "7/7 - 1s - loss: 0.6292 - accuracy: 0.6226\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.5172 - accuracy: 0.7324\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.4611 - accuracy: 0.7653\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.3355 - accuracy: 0.8551\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.4863 - accuracy: 0.7465\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.4596 - accuracy: 0.7840\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.5167 - accuracy: 0.7465\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.2788 - accuracy: 0.8879\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.4126 - accuracy: 0.7700\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.4738 - accuracy: 0.7887\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.2971 - accuracy: 0.8551\n",
      "Epoch 1/50\n",
      "14/14 - 3s - loss: 0.9139 - accuracy: 0.6028\n",
      "Epoch 1/50\n",
      "54/54 - 4s - loss: 0.8575 - accuracy: 0.5352\n",
      "Epoch 50/50\n",
      "54/54 - 2s - loss: 0.4940 - accuracy: 0.7324\n",
      "Epoch 50/50\n",
      "54/54 - 2s - loss: 0.5208 - accuracy: 0.7606\n",
      "Epoch 2/50\n",
      "14/14 - 1s - loss: 0.7878 - accuracy: 0.5374\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.3395 - accuracy: 0.8645\n",
      "Epoch 1/50\n",
      "54/54 - 5s - loss: 0.7488 - accuracy: 0.5634\n",
      "Epoch 2/50\n",
      "54/54 - 2s - loss: 0.6703 - accuracy: 0.6150\n",
      "27/27 - 1s - loss: 0.5959 - accuracy: 0.7383\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 1.6664 - accuracy: 0.5681\n",
      "Epoch 3/50\n",
      "14/14 - 1s - loss: 0.5659 - accuracy: 0.6636\n",
      "27/27 - 1s - loss: 0.6126 - accuracy: 0.6729\n",
      "Epoch 1/50\n",
      "54/54 - 5s - loss: 0.7601 - accuracy: 0.5234\n",
      "Epoch 50/50\n",
      "54/54 - 2s - loss: 0.3101 - accuracy: 0.8645\n",
      "Epoch 2/50\n",
      "54/54 - 2s - loss: 0.6186 - accuracy: 0.7042\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.5851 - accuracy: 0.6479\n",
      "Epoch 3/50\n",
      "54/54 - 2s - loss: 0.6491 - accuracy: 0.5915\n",
      "Epoch 4/50\n",
      "14/14 - 1s - loss: 0.5269 - accuracy: 0.7336\n",
      "27/27 - 0s - loss: 0.5065 - accuracy: 0.7547\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 0.6929 - accuracy: 0.5981\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6717 - accuracy: 0.6150\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.5745 - accuracy: 0.6901\n",
      "Epoch 5/50\n",
      "14/14 - 1s - loss: 0.5270 - accuracy: 0.7103\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.6160 - accuracy: 0.6573\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.6516 - accuracy: 0.6215\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.5762 - accuracy: 0.7277\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.5595 - accuracy: 0.7183\n",
      "Epoch 1/50\n",
      "27/27 - 3s - loss: 1.2263 - accuracy: 0.5634\n",
      "Epoch 6/50\n",
      "14/14 - 1s - loss: 0.4865 - accuracy: 0.7383\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.6004 - accuracy: 0.6714\n",
      "Epoch 4/50\n",
      "54/54 - 2s - loss: 0.6313 - accuracy: 0.6495\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.5819 - accuracy: 0.7277\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.6333 - accuracy: 0.6761\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.4592 - accuracy: 0.7559\n",
      "Epoch 7/50\n",
      "14/14 - 1s - loss: 0.4231 - accuracy: 0.7944\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.5646 - accuracy: 0.7230\n",
      "Epoch 5/50\n",
      "54/54 - 2s - loss: 0.6149 - accuracy: 0.6075\n",
      "Epoch 8/50\n",
      "14/14 - 1s - loss: 0.4189 - accuracy: 0.7850\n",
      "Epoch 3/50\n",
      "27/27 - 2s - loss: 0.4587 - accuracy: 0.7653\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.5651 - accuracy: 0.6854\n",
      "Epoch 6/50\n",
      "27/27 - 2s - loss: 0.5334 - accuracy: 0.7606\n",
      "Epoch 1/50\n",
      "27/27 - 5s - loss: 1.4171 - accuracy: 0.5561\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 0.7781 - accuracy: 0.5352\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.6355 - accuracy: 0.6948\n",
      "Epoch 9/50\n",
      "14/14 - 1s - loss: 0.4103 - accuracy: 0.8318\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.5900 - accuracy: 0.6589\n",
      "Epoch 7/50\n",
      "27/27 - 2s - loss: 0.4435 - accuracy: 0.7700\n",
      "Epoch 4/50\n",
      "27/27 - 2s - loss: 0.6235 - accuracy: 0.7042\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.5103 - accuracy: 0.7371\n",
      "Epoch 2/50\n",
      "27/27 - 2s - loss: 0.7657 - accuracy: 0.5187\n",
      "Epoch 2/50\n",
      "27/27 - 2s - loss: 0.6771 - accuracy: 0.5258\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.5149 - accuracy: 0.7418\n",
      "Epoch 10/50\n",
      "14/14 - 2s - loss: 0.3500 - accuracy: 0.7944\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.4447 - accuracy: 0.7793\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.5660 - accuracy: 0.6869\n",
      "Epoch 5/50\n",
      "27/27 - 2s - loss: 0.4788 - accuracy: 0.7606\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.4950 - accuracy: 0.7512\n",
      "Epoch 3/50\n",
      "27/27 - 2s - loss: 0.6548 - accuracy: 0.6808\n",
      "Epoch 3/50\n",
      "27/27 - 2s - loss: 0.5854 - accuracy: 0.7103\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.5702 - accuracy: 0.6901\n",
      "Epoch 11/50\n",
      "14/14 - 1s - loss: 0.3885 - accuracy: 0.8318\n",
      "Epoch 9/50\n",
      "27/27 - 2s - loss: 0.5767 - accuracy: 0.7793\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.5554 - accuracy: 0.7056\n",
      "Epoch 6/50\n",
      "27/27 - 2s - loss: 0.5473 - accuracy: 0.7700\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.5240 - accuracy: 0.7512\n",
      "Epoch 4/50\n",
      "27/27 - 2s - loss: 0.6248 - accuracy: 0.6215\n",
      "Epoch 4/50\n",
      "27/27 - 2s - loss: 0.6275 - accuracy: 0.6009\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.4846 - accuracy: 0.7512\n",
      "Epoch 12/50\n",
      "14/14 - 2s - loss: 0.2934 - accuracy: 0.8738\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.3588 - accuracy: 0.8404\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.5389 - accuracy: 0.7056\n",
      "Epoch 7/50\n",
      "27/27 - 2s - loss: 0.3889 - accuracy: 0.7934\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.4697 - accuracy: 0.7653\n",
      "Epoch 5/50\n",
      "27/27 - 2s - loss: 0.6192 - accuracy: 0.6573\n",
      "Epoch 5/50\n",
      "27/27 - 2s - loss: 0.5551 - accuracy: 0.7009\n",
      "Epoch 13/50\n",
      "14/14 - 2s - loss: 0.3200 - accuracy: 0.8879\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.4697 - accuracy: 0.8075\n",
      "Epoch 11/50\n",
      "27/27 - 2s - loss: 0.4113 - accuracy: 0.8216\n",
      "Epoch 8/50\n",
      "27/27 - 2s - loss: 0.4619 - accuracy: 0.7606\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.5571 - accuracy: 0.6822\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.4109 - accuracy: 0.8169\n",
      "Epoch 6/50\n",
      "27/27 - 2s - loss: 0.5154 - accuracy: 0.7430\n",
      "Epoch 6/50\n",
      "27/27 - 2s - loss: 0.5931 - accuracy: 0.6620\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.4199 - accuracy: 0.8310\n",
      "Epoch 14/50\n",
      "14/14 - 2s - loss: 0.2770 - accuracy: 0.8692\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.4356 - accuracy: 0.7934\n",
      "Epoch 9/50\n",
      "27/27 - 2s - loss: 0.3953 - accuracy: 0.8169\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.4962 - accuracy: 0.7523\n",
      "Epoch 7/50\n",
      "27/27 - 2s - loss: 0.5545 - accuracy: 0.7418\n",
      "Epoch 7/50\n",
      "27/27 - 2s - loss: 0.4693 - accuracy: 0.7477\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.3904 - accuracy: 0.8169\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.4660 - accuracy: 0.8028\n",
      "Epoch 15/50\n",
      "14/14 - 2s - loss: 0.2624 - accuracy: 0.9065\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.3555 - accuracy: 0.8263\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.4674 - accuracy: 0.7230\n",
      "Epoch 8/50\n",
      "27/27 - 2s - loss: 0.5367 - accuracy: 0.7277\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.4314 - accuracy: 0.7897\n",
      "Epoch 8/50\n",
      "27/27 - 2s - loss: 0.3876 - accuracy: 0.8411\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.4355 - accuracy: 0.7981\n",
      "Epoch 14/50\n",
      "27/27 - 2s - loss: 0.3465 - accuracy: 0.8451\n",
      "Epoch 16/50\n",
      "14/14 - 2s - loss: 0.2676 - accuracy: 0.8738\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.4284 - accuracy: 0.7887\n",
      "Epoch 11/50\n",
      "27/27 - 2s - loss: 0.3679 - accuracy: 0.8028\n",
      "Epoch 9/50\n",
      "27/27 - 2s - loss: 0.5835 - accuracy: 0.7230\n",
      "Epoch 9/50\n",
      "27/27 - 2s - loss: 0.3849 - accuracy: 0.7757\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.5133 - accuracy: 0.7523\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.4605 - accuracy: 0.7559\n",
      "Epoch 15/50\n",
      "27/27 - 2s - loss: 0.3275 - accuracy: 0.8592\n",
      "Epoch 17/50\n",
      "14/14 - 2s - loss: 0.2700 - accuracy: 0.8925\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.4129 - accuracy: 0.7981\n",
      "Epoch 12/50\n",
      "27/27 - 2s - loss: 0.3453 - accuracy: 0.8404\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.4903 - accuracy: 0.7371\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.4941 - accuracy: 0.8364\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.4756 - accuracy: 0.7477\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.4326 - accuracy: 0.7700\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.2785 - accuracy: 0.8826\n",
      "Epoch 18/50\n",
      "14/14 - 2s - loss: 0.2020 - accuracy: 0.9206\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.4142 - accuracy: 0.7981\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.3155 - accuracy: 0.8685\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.5104 - accuracy: 0.7418\n",
      "Epoch 11/50\n",
      "27/27 - 2s - loss: 0.5181 - accuracy: 0.7757\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.3665 - accuracy: 0.8169\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.4535 - accuracy: 0.7850\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.2768 - accuracy: 0.9014\n",
      "Epoch 19/50\n",
      "14/14 - 2s - loss: 0.1108 - accuracy: 0.9533\n",
      "Epoch 14/50\n",
      "27/27 - 2s - loss: 0.2358 - accuracy: 0.8685\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.4150 - accuracy: 0.8075\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 12/50\n",
      "27/27 - 2s - loss: 0.5106 - accuracy: 0.7653\n",
      "Epoch 12/50\n",
      "27/27 - 2s - loss: 0.3412 - accuracy: 0.8318\n",
      "Epoch 20/50\n",
      "14/14 - 1s - loss: 0.2179 - accuracy: 0.9252\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.4653 - accuracy: 0.7617\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.2410 - accuracy: 0.8920\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.4019 - accuracy: 0.8122\n",
      "Epoch 15/50\n",
      "27/27 - 2s - loss: 0.2576 - accuracy: 0.8826\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.4945 - accuracy: 0.7042\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.4151 - accuracy: 0.7700\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.2526 - accuracy: 0.8692\n",
      "Epoch 21/50\n",
      "14/14 - 2s - loss: 0.1951 - accuracy: 0.9019\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.2924 - accuracy: 0.9108\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.4402 - accuracy: 0.7897\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.3895 - accuracy: 0.7887\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.3306 - accuracy: 0.9061\n",
      "Epoch 14/50\n",
      "27/27 - 2s - loss: 0.4896 - accuracy: 0.7746\n",
      "Epoch 14/50\n",
      "27/27 - 2s - loss: 0.1853 - accuracy: 0.9299\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.4008 - accuracy: 0.7981\n",
      "Epoch 22/50\n",
      "14/14 - 2s - loss: 0.1580 - accuracy: 0.9112\n",
      "Epoch 20/50\n",
      "27/27 - 2s - loss: 0.2803 - accuracy: 0.8873\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.4173 - accuracy: 0.8037\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.3579 - accuracy: 0.8404\n",
      "Epoch 15/50\n",
      "27/27 - 2s - loss: 0.4518 - accuracy: 0.7559\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.2982 - accuracy: 0.8873\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.2213 - accuracy: 0.9065\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.3712 - accuracy: 0.8075\n",
      "Epoch 23/50\n",
      "14/14 - 2s - loss: 0.3503 - accuracy: 0.8645\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.2780 - accuracy: 0.8967\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.4420 - accuracy: 0.7991\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.3290 - accuracy: 0.8404\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.3766 - accuracy: 0.8169\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.4797 - accuracy: 0.7700\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.2122 - accuracy: 0.9299\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.3757 - accuracy: 0.8404\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 24/50\n",
      "14/14 - 2s - loss: 0.1977 - accuracy: 0.9252\n",
      "Epoch 22/50\n",
      "27/27 - 2s - loss: 0.4480 - accuracy: 0.8357\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.4346 - accuracy: 0.7570\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.3327 - accuracy: 0.8779\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.3018 - accuracy: 0.8873\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.5060 - accuracy: 0.7700\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.2043 - accuracy: 0.8832\n",
      "Epoch 25/50\n",
      "14/14 - 1s - loss: 0.1066 - accuracy: 0.9346\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.3860 - accuracy: 0.8028\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.4119 - accuracy: 0.8318\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.1702 - accuracy: 0.9249\n",
      "Epoch 20/50\n",
      "27/27 - 2s - loss: 0.1530 - accuracy: 0.9390\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.3186 - accuracy: 0.8545\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.4601 - accuracy: 0.7277\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.1548 - accuracy: 0.9393\n",
      "Epoch 26/50\n",
      "14/14 - 2s - loss: 0.1753 - accuracy: 0.9299\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.3833 - accuracy: 0.8310\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.3702 - accuracy: 0.8084\n",
      "Epoch 24/50\n",
      "27/27 - 2s - loss: 0.2666 - accuracy: 0.8967\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.4584 - accuracy: 0.7934\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.2110 - accuracy: 0.9108\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.1819 - accuracy: 0.9065\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.3321 - accuracy: 0.8638\n",
      "Epoch 27/50\n",
      "14/14 - 2s - loss: 0.1365 - accuracy: 0.9533\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.3572 - accuracy: 0.8263\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.3576 - accuracy: 0.8318\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.1825 - accuracy: 0.9437\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.1315 - accuracy: 0.9720\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.2018 - accuracy: 0.9155\n",
      "Epoch 20/50\n",
      "27/27 - 2s - loss: 0.4775 - accuracy: 0.7324\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 28/50\n",
      "14/14 - 2s - loss: 0.1661 - accuracy: 0.9206\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.2949 - accuracy: 0.8638\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.1570 - accuracy: 0.9437\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.3522 - accuracy: 0.8551\n",
      "Epoch 26/50\n",
      "27/27 - 2s - loss: 0.1278 - accuracy: 0.9531\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.1733 - accuracy: 0.9112\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.4383 - accuracy: 0.8122\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.4486 - accuracy: 0.7746\n",
      "Epoch 29/50\n",
      "14/14 - 2s - loss: 0.1156 - accuracy: 0.9439\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.3214 - accuracy: 0.8498\n",
      "Epoch 24/50\n",
      "27/27 - 2s - loss: 0.1752 - accuracy: 0.9014\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.2435 - accuracy: 0.9108\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.3757 - accuracy: 0.8178\n",
      "Epoch 22/50\n",
      "27/27 - 2s - loss: 0.1631 - accuracy: 0.9252\n",
      "Epoch 30/50\n",
      "14/14 - 1s - loss: 0.1441 - accuracy: 0.9346\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.3817 - accuracy: 0.8357\n",
      "Epoch 22/50\n",
      "27/27 - 2s - loss: 0.4624 - accuracy: 0.7653\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.2953 - accuracy: 0.9061\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.1636 - accuracy: 0.9390\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.1987 - accuracy: 0.9155\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.3607 - accuracy: 0.8271\n",
      "Epoch 31/50\n",
      "14/14 - 2s - loss: 0.0671 - accuracy: 0.9766\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.1082 - accuracy: 0.9533\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.4479 - accuracy: 0.7840\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.2920 - accuracy: 0.8685\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.3337 - accuracy: 0.8216\n",
      "Epoch 26/50\n",
      "27/27 - 2s - loss: 0.1760 - accuracy: 0.9296\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.2473 - accuracy: 0.8967\n",
      "Epoch 32/50\n",
      "14/14 - 2s - loss: 0.1045 - accuracy: 0.9533\n",
      "Epoch 24/50\n",
      "27/27 - 2s - loss: 0.1049 - accuracy: 0.9673\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.3252 - accuracy: 0.8551\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 24/50\n",
      "27/27 - 2s - loss: 0.4457 - accuracy: 0.7793\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.2833 - accuracy: 0.8873\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.3396 - accuracy: 0.8451\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/50\n",
      "27/27 - 2s - loss: 0.0816 - accuracy: 0.9531\n",
      "Epoch 33/50\n",
      "14/14 - 1s - loss: 0.0766 - accuracy: 0.9626\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.1324 - accuracy: 0.9579\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.2517 - accuracy: 0.8967\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.3517 - accuracy: 0.8318\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.4521 - accuracy: 0.7653\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.3327 - accuracy: 0.8592\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.3390 - accuracy: 0.8592\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.2461 - accuracy: 0.9249\n",
      "Epoch 34/50\n",
      "14/14 - 2s - loss: 0.0780 - accuracy: 0.9673\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.0788 - accuracy: 0.9673\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.2119 - accuracy: 0.9343\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.3615 - accuracy: 0.8178\n",
      "Epoch 26/50\n",
      "27/27 - 2s - loss: 0.4593 - accuracy: 0.7465\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.3309 - accuracy: 0.8404\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.3255 - accuracy: 0.9014\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.1045 - accuracy: 0.9718\n",
      "Epoch 35/50\n",
      "14/14 - 2s - loss: 0.0469 - accuracy: 0.9907\n",
      "Epoch 27/50\n",
      "27/27 - 2s - loss: 0.0773 - accuracy: 0.9860\n",
      "Epoch 32/50\n",
      "27/27 - 2s - loss: 0.1833 - accuracy: 0.9296\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.3007 - accuracy: 0.8972\n",
      "Epoch 27/50\n",
      "27/27 - 2s - loss: 0.4476 - accuracy: 0.8075\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.2646 - accuracy: 0.8779\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.3488 - accuracy: 0.8216\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.0864 - accuracy: 0.9531\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.0934 - accuracy: 0.9533\n",
      "Epoch 36/50\n",
      "14/14 - 2s - loss: 0.0785 - accuracy: 0.9766\n",
      "Epoch 33/50\n",
      "27/27 - 2s - loss: 0.1560 - accuracy: 0.9577\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.3211 - accuracy: 0.8411\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.4213 - accuracy: 0.8075\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.3271 - accuracy: 0.8545\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.2966 - accuracy: 0.8545\n",
      "Epoch 37/50\n",
      "14/14 - 1s - loss: 0.0599 - accuracy: 0.9439\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.1206 - accuracy: 0.9531\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.1326 - accuracy: 0.9299\n",
      "Epoch 34/50\n",
      "27/27 - 2s - loss: 0.1540 - accuracy: 0.9108\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.3991 - accuracy: 0.8357\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.3387 - accuracy: 0.8318\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.2647 - accuracy: 0.8826\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.3532 - accuracy: 0.8404\n",
      "Epoch 38/50\n",
      "14/14 - 2s - loss: 0.1022 - accuracy: 0.9860\n",
      "Epoch 32/50\n",
      "27/27 - 2s - loss: 0.1552 - accuracy: 0.9202\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.1058 - accuracy: 0.9626\n",
      "Epoch 35/50\n",
      "27/27 - 2s - loss: 0.0990 - accuracy: 0.9671\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.4411 - accuracy: 0.7981\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.3176 - accuracy: 0.8598\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.2533 - accuracy: 0.9108\n",
      "Epoch 39/50\n",
      "14/14 - 2s - loss: 0.0696 - accuracy: 0.9720\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.3795 - accuracy: 0.8075\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.1310 - accuracy: 0.9486\n",
      "Epoch 33/50\n",
      "27/27 - 2s - loss: 0.0875 - accuracy: 0.9812\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.0882 - accuracy: 0.9531\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.3860 - accuracy: 0.8357\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.3123 - accuracy: 0.8832\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 40/50\n",
      "14/14 - 1s - loss: 0.0657 - accuracy: 0.9860\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/50\n",
      "27/27 - 1s - loss: 0.1245 - accuracy: 0.9346\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.3263 - accuracy: 0.8732\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.2355 - accuracy: 0.9108\n",
      "Epoch 34/50\n",
      "27/27 - 2s - loss: 0.1118 - accuracy: 0.9624\n",
      "Epoch 37/50\n",
      "27/27 - 2s - loss: 0.1471 - accuracy: 0.9484\n",
      "Epoch 32/50\n",
      "27/27 - 2s - loss: 0.4408 - accuracy: 0.7887\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.2973 - accuracy: 0.8692\n",
      "Epoch 33/50\n",
      "27/27 - 2s - loss: 0.0940 - accuracy: 0.9626\n",
      "Epoch 41/50\n",
      "14/14 - 2s - loss: 0.0660 - accuracy: 0.9766\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.2857 - accuracy: 0.8826\n",
      "Epoch 38/50\n",
      "27/27 - 2s - loss: 0.0947 - accuracy: 0.9390\n",
      "Epoch 35/50\n",
      "27/27 - 2s - loss: 0.0627 - accuracy: 0.9671\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.3187 - accuracy: 0.8545\n",
      "Epoch 33/50\n",
      "27/27 - 2s - loss: 0.4422 - accuracy: 0.7934\n",
      "Epoch 42/50\n",
      "14/14 - 1s - loss: 0.0660 - accuracy: 0.9720\n",
      "Epoch 34/50\n",
      "27/27 - 2s - loss: 0.0937 - accuracy: 0.9533\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.2651 - accuracy: 0.8873\n",
      "Epoch 39/50\n",
      "27/27 - 2s - loss: 0.0654 - accuracy: 0.9671\n",
      "Epoch 36/50\n",
      "27/27 - 2s - loss: 0.0869 - accuracy: 0.9624\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.3146 - accuracy: 0.8318\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.3568 - accuracy: 0.8169\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 34/50\n",
      "27/27 - 2s - loss: 0.4160 - accuracy: 0.7700\n",
      "Epoch 35/50\n",
      "27/27 - 2s - loss: 0.0999 - accuracy: 0.9673\n",
      "Epoch 43/50\n",
      "14/14 - 2s - loss: 0.0770 - accuracy: 0.9720\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 40/50\n",
      "27/27 - 1s - loss: 0.0835 - accuracy: 0.9671\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.2643 - accuracy: 0.8732\n",
      "Epoch 37/50\n",
      "27/27 - 2s - loss: 0.1048 - accuracy: 0.9531\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.3320 - accuracy: 0.8785\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.3405 - accuracy: 0.8169\n",
      "Epoch 35/50\n",
      "27/27 - 2s - loss: 0.4209 - accuracy: 0.8216\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 44/50\n",
      "14/14 - 2s - loss: 0.0382 - accuracy: 0.9813\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 36/50\n",
      "27/27 - 2s - loss: 0.0609 - accuracy: 0.9720\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.0786 - accuracy: 0.9531\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.2743 - accuracy: 0.8826\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/50\n",
      "27/27 - 2s - loss: 0.0848 - accuracy: 0.9624\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.2678 - accuracy: 0.8925\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.3321 - accuracy: 0.8545\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.1245 - accuracy: 0.9533\n",
      "Epoch 36/50\n",
      "27/27 - 2s - loss: 0.4385 - accuracy: 0.7887\n",
      "Epoch 45/50\n",
      "14/14 - 2s - loss: 0.0474 - accuracy: 0.9907\n",
      "Epoch 42/50\n",
      "27/27 - 2s - loss: 0.0607 - accuracy: 0.9718\n",
      "Epoch 39/50\n",
      "27/27 - 2s - loss: 0.1189 - accuracy: 0.9718\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.2768 - accuracy: 0.8826\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.2814 - accuracy: 0.8692\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.4374 - accuracy: 0.7840\n",
      "Epoch 38/50\n",
      "27/27 - 2s - loss: 0.0822 - accuracy: 0.9579\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.3559 - accuracy: 0.8498\n",
      "Epoch 46/50\n",
      "14/14 - 2s - loss: 0.0954 - accuracy: 0.9673\n",
      "Epoch 43/50\n",
      "27/27 - 2s - loss: 0.0746 - accuracy: 0.9718\n",
      "Epoch 40/50\n",
      "27/27 - 2s - loss: 0.0827 - accuracy: 0.9624\n",
      "Epoch 41/50\n",
      "54/54 - 2s - loss: 0.2733 - accuracy: 0.8967\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.4320 - accuracy: 0.8169\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.2638 - accuracy: 0.8925\n",
      "Epoch 39/50\n",
      "27/27 - 2s - loss: 0.0887 - accuracy: 0.9579\n",
      "Epoch 41/50\n",
      "54/54 - 2s - loss: 0.3583 - accuracy: 0.8404\n",
      "Epoch 47/50\n",
      "14/14 - 2s - loss: 0.0530 - accuracy: 0.9626\n",
      "Epoch 44/50\n",
      "27/27 - 2s - loss: 0.0602 - accuracy: 0.9765\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.0609 - accuracy: 0.9906\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.2941 - accuracy: 0.8779\n",
      "Epoch 39/50\n",
      "27/27 - 2s - loss: 0.4577 - accuracy: 0.8028\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 40/50\n",
      "27/27 - 2s - loss: 0.0761 - accuracy: 0.9626\n",
      "Epoch 41/50\n",
      "54/54 - 2s - loss: 0.2892 - accuracy: 0.8832\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.3576 - accuracy: 0.8404\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 48/50\n",
      "14/14 - 2s - loss: 0.0775 - accuracy: 0.9626\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.0778 - accuracy: 0.9812\n",
      "Epoch 42/50\n",
      "27/27 - 2s - loss: 0.0590 - accuracy: 0.9812\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.2897 - accuracy: 0.8779\n",
      "Epoch 40/50\n",
      "27/27 - 1s - loss: 0.4631 - accuracy: 0.7840\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.3104 - accuracy: 0.8598\n",
      "Epoch 49/50\n",
      "14/14 - 2s - loss: 0.1018 - accuracy: 0.9626\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.0642 - accuracy: 0.9766\n",
      "Epoch 46/50\n",
      "27/27 - 2s - loss: 0.0760 - accuracy: 0.9718\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.3549 - accuracy: 0.8216\n",
      "Epoch 43/50\n",
      "27/27 - 2s - loss: 0.0379 - accuracy: 0.9859\n",
      "Epoch 44/50\n",
      "54/54 - 2s - loss: 0.2925 - accuracy: 0.8685\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.4508 - accuracy: 0.7981\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.0807 - accuracy: 0.9813\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.3169 - accuracy: 0.8692\n",
      "Epoch 47/50\n",
      "27/27 - 2s - loss: 0.0803 - accuracy: 0.9765\n",
      "Epoch 50/50\n",
      "14/14 - 2s - loss: 0.0483 - accuracy: 0.9720\n",
      "Epoch 44/50\n",
      "54/54 - 2s - loss: 0.3072 - accuracy: 0.8592\n",
      "Epoch 44/50\n",
      "27/27 - 2s - loss: 0.0635 - accuracy: 0.9859\n",
      "Epoch 45/50\n",
      "54/54 - 2s - loss: 0.2189 - accuracy: 0.9014\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 42/50\n",
      "27/27 - 2s - loss: 0.4099 - accuracy: 0.7887\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.0561 - accuracy: 0.9765\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.2982 - accuracy: 0.8785\n",
      "Epoch 43/50\n",
      "27/27 - 2s - loss: 0.0810 - accuracy: 0.9813\n",
      "7/7 - 1s - loss: 0.6339 - accuracy: 0.7736\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.3290 - accuracy: 0.8263\n",
      "Epoch 45/50\n",
      "27/27 - 2s - loss: 0.0320 - accuracy: 0.9953\n",
      "Epoch 46/50\n",
      "54/54 - 2s - loss: 0.2535 - accuracy: 0.8826\n",
      "Epoch 43/50\n",
      "27/27 - 2s - loss: 0.4360 - accuracy: 0.7793\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 44/50\n",
      "27/27 - 2s - loss: 0.0867 - accuracy: 0.9720\n",
      "Epoch 49/50\n",
      "27/27 - 2s - loss: 0.1131 - accuracy: 0.9577\n",
      "Epoch 45/50\n",
      "54/54 - 2s - loss: 0.2826 - accuracy: 0.9019\n",
      "Epoch 46/50\n",
      "54/54 - 2s - loss: 0.3564 - accuracy: 0.8357\n",
      "Epoch 46/50\n",
      "27/27 - 2s - loss: 0.0304 - accuracy: 0.9953\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.0634 - accuracy: 0.9718\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 47/50\n",
      "54/54 - 2s - loss: 0.2523 - accuracy: 0.8826\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.4189 - accuracy: 0.8404\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.0764 - accuracy: 0.9626\n",
      "Epoch 46/50\n",
      "54/54 - 2s - loss: 0.2898 - accuracy: 0.8785\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.3638 - accuracy: 0.8310\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.0435 - accuracy: 0.9859\n",
      "14/14 - 1s - loss: 0.4635 - accuracy: 0.7664\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.4327 - accuracy: 0.7840\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.0559 - accuracy: 0.9907\n",
      "Epoch 48/50\n",
      "54/54 - 2s - loss: 0.2955 - accuracy: 0.8685\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.3130 - accuracy: 0.8318\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.3564 - accuracy: 0.8310\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.0528 - accuracy: 0.9671\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.3943 - accuracy: 0.8169\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.1089 - accuracy: 0.9439\n",
      "Epoch 49/50\n",
      "54/54 - 2s - loss: 0.2527 - accuracy: 0.8920\n",
      "Epoch 48/50\n",
      "54/54 - 2s - loss: 0.2536 - accuracy: 0.8832\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.3428 - accuracy: 0.8826\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.4323 - accuracy: 0.7840\n",
      "Epoch 49/50\n",
      "27/27 - 2s - loss: 0.0354 - accuracy: 0.9812\n",
      "Epoch 1/50\n",
      "27/27 - 5s - loss: 0.7319 - accuracy: 0.6056\n",
      "Epoch 48/50\n",
      "27/27 - 2s - loss: 0.0858 - accuracy: 0.9626\n",
      "Epoch 49/50\n",
      "54/54 - 2s - loss: 0.2710 - accuracy: 0.8972\n",
      "Epoch 50/50\n",
      "54/54 - 2s - loss: 0.2876 - accuracy: 0.8873\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.2992 - accuracy: 0.8873\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.0287 - accuracy: 0.9859\n",
      "Epoch 2/50\n",
      "27/27 - 2s - loss: 0.6461 - accuracy: 0.6761\n",
      "Epoch 48/50\n",
      "27/27 - 2s - loss: 0.4310 - accuracy: 0.7746\n",
      "Epoch 49/50\n",
      "27/27 - 2s - loss: 0.0702 - accuracy: 0.9720\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.3136 - accuracy: 0.8551\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.6381 - accuracy: 0.6901\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "27/27 - 1s - loss: 0.5091 - accuracy: 0.7383\n",
      "14/14 - 1s - loss: 0.4602 - accuracy: 0.8411\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.4180 - accuracy: 0.7606\n",
      "27/27 - 1s - loss: 0.4915 - accuracy: 0.7547\n",
      "27/27 - 1s - loss: 0.5292 - accuracy: 0.7570\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.0569 - accuracy: 0.9766\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.4146 - accuracy: 0.7981\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.6392 - accuracy: 0.5962\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "14/14 - 1s - loss: 0.6256 - accuracy: 0.7642\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 0.7349 - accuracy: 0.5327\n",
      "14/14 - 1s - loss: 0.5601 - accuracy: 0.7196\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.5434 - accuracy: 0.7371\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.7448 - accuracy: 0.5140\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.5507 - accuracy: 0.7042\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.7021 - accuracy: 0.5654\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.5698 - accuracy: 0.6761\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 1.5286 - accuracy: 0.5701\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 1.0997 - accuracy: 0.5070\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.6618 - accuracy: 0.6308\n",
      "Epoch 1/50\n",
      "27/27 - 3s - loss: 2.4452 - accuracy: 0.5962\n",
      "Epoch 8/50\n",
      "27/27 - 2s - loss: 0.4861 - accuracy: 0.7606\n",
      "Epoch 1/50\n",
      "54/54 - 5s - loss: 1.6766 - accuracy: 0.5822\n",
      "Epoch 2/50\n",
      "54/54 - 2s - loss: 0.8108 - accuracy: 0.5561\n",
      "Epoch 1/50\n",
      "27/27 - 3s - loss: 2.5766 - accuracy: 0.5607\n",
      "Epoch 2/50\n",
      "54/54 - 2s - loss: 1.1207 - accuracy: 0.6056\n",
      "Epoch 5/50\n",
      "27/27 - 2s - loss: 0.6104 - accuracy: 0.6963\n",
      "Epoch 2/50\n",
      "27/27 - 2s - loss: 0.8135 - accuracy: 0.5962\n",
      "Epoch 1/50\n",
      "27/27 - 5s - loss: 2.5712 - accuracy: 0.6197\n",
      "Epoch 9/50\n",
      "27/27 - 2s - loss: 0.5284 - accuracy: 0.7136\n",
      "Epoch 2/50\n",
      "54/54 - 2s - loss: 0.6947 - accuracy: 0.6291\n",
      "Epoch 2/50\n",
      "27/27 - 2s - loss: 0.7016 - accuracy: 0.6636\n",
      "Epoch 3/50\n",
      "54/54 - 2s - loss: 0.6892 - accuracy: 0.6495\n",
      "Epoch 3/50\n",
      "54/54 - 2s - loss: 0.5419 - accuracy: 0.7371\n",
      "Epoch 6/50\n",
      "27/27 - 2s - loss: 0.5850 - accuracy: 0.6869\n",
      "Epoch 2/50\n",
      "27/27 - 2s - loss: 1.5210 - accuracy: 0.6338\n",
      "Epoch 3/50\n",
      "27/27 - 2s - loss: 0.7929 - accuracy: 0.6009\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.5155 - accuracy: 0.7136\n",
      "Epoch 4/50\n",
      "54/54 - 2s - loss: 0.6892 - accuracy: 0.6495\n",
      "Epoch 3/50\n",
      "54/54 - 2s - loss: 0.5724 - accuracy: 0.6948\n",
      "Epoch 3/50\n",
      "27/27 - 2s - loss: 0.6921 - accuracy: 0.6542\n",
      "Epoch 4/50\n",
      "54/54 - 2s - loss: 0.5312 - accuracy: 0.8028\n",
      "Epoch 3/50\n",
      "27/27 - 2s - loss: 0.9862 - accuracy: 0.6620\n",
      "Epoch 7/50\n",
      "27/27 - 2s - loss: 0.5539 - accuracy: 0.6168\n",
      "Epoch 4/50\n",
      "27/27 - 2s - loss: 0.6372 - accuracy: 0.6385\n",
      "Epoch 11/50\n",
      "27/27 - 2s - loss: 0.5164 - accuracy: 0.7653\n",
      "Epoch 4/50\n",
      "27/27 - 2s - loss: 0.7305 - accuracy: 0.6620\n",
      "Epoch 5/50\n",
      "54/54 - 2s - loss: 0.6011 - accuracy: 0.7196\n",
      "Epoch 4/50\n",
      "27/27 - 2s - loss: 0.6082 - accuracy: 0.6869\n",
      "Epoch 8/50\n",
      "27/27 - 2s - loss: 0.6281 - accuracy: 0.7290\n",
      "Epoch 4/50\n",
      "54/54 - 2s - loss: 0.6721 - accuracy: 0.6479\n",
      "Epoch 5/50\n",
      "27/27 - 2s - loss: 0.6526 - accuracy: 0.6338\n",
      "Epoch 5/50\n",
      "54/54 - 2s - loss: 0.7312 - accuracy: 0.6808\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.4464 - accuracy: 0.7700\n",
      "Epoch 9/50\n",
      "27/27 - 2s - loss: 0.6147 - accuracy: 0.6542\n",
      "Epoch 5/50\n",
      "27/27 - 2s - loss: 0.5947 - accuracy: 0.6729\n",
      "Epoch 5/50\n",
      "27/27 - 2s - loss: 0.6286 - accuracy: 0.6948\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.6945 - accuracy: 0.6075\n",
      "Epoch 6/50\n",
      "27/27 - 2s - loss: 0.6549 - accuracy: 0.6761\n",
      "Epoch 5/50\n",
      "54/54 - 2s - loss: 0.6937 - accuracy: 0.6761\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.5111 - accuracy: 0.7793\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.4731 - accuracy: 0.8075\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.6404 - accuracy: 0.7606\n",
      "Epoch 6/50\n",
      "27/27 - 2s - loss: 0.6236 - accuracy: 0.6869\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.5355 - accuracy: 0.6636\n",
      "Epoch 6/50\n",
      "27/27 - 2s - loss: 0.5221 - accuracy: 0.7465\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.5434 - accuracy: 0.7196\n",
      "Epoch 6/50\n",
      "54/54 - 2s - loss: 0.6277 - accuracy: 0.7230\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.3829 - accuracy: 0.8216\n",
      "Epoch 14/50\n",
      "27/27 - 2s - loss: 0.4881 - accuracy: 0.7465\n",
      "Epoch 11/50\n",
      "27/27 - 2s - loss: 0.5617 - accuracy: 0.6729\n",
      "Epoch 7/50\n",
      "27/27 - 2s - loss: 0.6264 - accuracy: 0.6682\n",
      "Epoch 7/50\n",
      "27/27 - 2s - loss: 0.5732 - accuracy: 0.7371\n",
      "Epoch 8/50\n",
      "27/27 - 2s - loss: 0.5797 - accuracy: 0.6995\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.5328 - accuracy: 0.6916\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.4123 - accuracy: 0.8216\n",
      "Epoch 7/50\n",
      "54/54 - 2s - loss: 0.5736 - accuracy: 0.7277\n",
      "Epoch 15/50\n",
      "27/27 - 2s - loss: 0.4292 - accuracy: 0.7746\n",
      "Epoch 12/50\n",
      "27/27 - 2s - loss: 0.4973 - accuracy: 0.7477\n",
      "Epoch 8/50\n",
      "27/27 - 2s - loss: 0.4802 - accuracy: 0.7746\n",
      "Epoch 8/50\n",
      "27/27 - 2s - loss: 0.6150 - accuracy: 0.7243\n",
      "Epoch 9/50\n",
      "27/27 - 2s - loss: 0.6231 - accuracy: 0.7136\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.5496 - accuracy: 0.7477\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.5157 - accuracy: 0.7700\n",
      "Epoch 8/50\n",
      "54/54 - 2s - loss: 0.4914 - accuracy: 0.7653\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.4627 - accuracy: 0.7653\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.5336 - accuracy: 0.7944\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.5651 - accuracy: 0.6822\n",
      "Epoch 9/50\n",
      "27/27 - 2s - loss: 0.4767 - accuracy: 0.7746\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.4667 - accuracy: 0.7512\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.4390 - accuracy: 0.8037\n",
      "Epoch 9/50\n",
      "54/54 - 2s - loss: 0.4401 - accuracy: 0.7934\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.4487 - accuracy: 0.8216\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.4034 - accuracy: 0.8451\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.4610 - accuracy: 0.6822\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.6042 - accuracy: 0.7710\n",
      "Epoch 10/50\n",
      "27/27 - 2s - loss: 0.3987 - accuracy: 0.8357\n",
      "Epoch 11/50\n",
      "27/27 - 2s - loss: 0.5489 - accuracy: 0.7887\n",
      "Epoch 10/50\n",
      "54/54 - 2s - loss: 0.4849 - accuracy: 0.7840\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.6247 - accuracy: 0.7710\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.4222 - accuracy: 0.7934\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.4283 - accuracy: 0.8310\n",
      "Epoch 15/50\n",
      "27/27 - 2s - loss: 0.5279 - accuracy: 0.7570\n",
      "Epoch 11/50\n",
      "27/27 - 2s - loss: 0.5767 - accuracy: 0.6916\n",
      "Epoch 11/50\n",
      "27/27 - 2s - loss: 0.4642 - accuracy: 0.8028\n",
      "Epoch 12/50\n",
      "27/27 - 2s - loss: 0.4868 - accuracy: 0.7136\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.4279 - accuracy: 0.7606\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.5713 - accuracy: 0.6916\n",
      "Epoch 11/50\n",
      "54/54 - 2s - loss: 0.4280 - accuracy: 0.8075\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.2569 - accuracy: 0.8873\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.4706 - accuracy: 0.7196\n",
      "Epoch 12/50\n",
      "27/27 - 2s - loss: 0.3756 - accuracy: 0.7944\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.4293 - accuracy: 0.7746\n",
      "Epoch 12/50\n",
      "27/27 - 2s - loss: 0.5104 - accuracy: 0.7512\n",
      "Epoch 20/50\n",
      "27/27 - 2s - loss: 0.3923 - accuracy: 0.8451\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.4868 - accuracy: 0.7570\n",
      "Epoch 12/50\n",
      "54/54 - 2s - loss: 0.3641 - accuracy: 0.8122\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.2924 - accuracy: 0.8732\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.6148 - accuracy: 0.7804\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.4401 - accuracy: 0.7944\n",
      "Epoch 14/50\n",
      "27/27 - 2s - loss: 0.4601 - accuracy: 0.8075\n",
      "Epoch 13/50\n",
      "27/27 - 2s - loss: 0.3462 - accuracy: 0.8451\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.3908 - accuracy: 0.8404\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.4385 - accuracy: 0.7850\n",
      "Epoch 13/50\n",
      "54/54 - 2s - loss: 0.4722 - accuracy: 0.7700\n",
      "Epoch 14/50\n",
      "27/27 - 2s - loss: 0.4989 - accuracy: 0.7757\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.2461 - accuracy: 0.9014\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.4432 - accuracy: 0.8178\n",
      "Epoch 15/50\n",
      "27/27 - 2s - loss: 0.3635 - accuracy: 0.8592\n",
      "Epoch 14/50\n",
      "27/27 - 2s - loss: 0.3432 - accuracy: 0.8498\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.3687 - accuracy: 0.8084\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 22/50\n",
      "27/27 - 2s - loss: 0.3412 - accuracy: 0.8357\n",
      "Epoch 14/50\n",
      "54/54 - 2s - loss: 0.2966 - accuracy: 0.8920\n",
      "Epoch 15/50\n",
      "27/27 - 2s - loss: 0.4672 - accuracy: 0.7664\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.2595 - accuracy: 0.8732\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.4714 - accuracy: 0.7336\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.5101 - accuracy: 0.7793\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.4184 - accuracy: 0.8122\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.3951 - accuracy: 0.8169\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.3936 - accuracy: 0.7991\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.2752 - accuracy: 0.8925\n",
      "Epoch 15/50\n",
      "54/54 - 2s - loss: 0.4180 - accuracy: 0.8310\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.2088 - accuracy: 0.9061\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.4963 - accuracy: 0.7653\n",
      "Epoch 20/50\n",
      "27/27 - 2s - loss: 0.4660 - accuracy: 0.7243\n",
      "Epoch 16/50\n",
      "27/27 - 2s - loss: 0.2700 - accuracy: 0.8873\n",
      "Epoch 24/50\n",
      "27/27 - 2s - loss: 0.3845 - accuracy: 0.8357\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.3852 - accuracy: 0.8178\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.2120 - accuracy: 0.9206\n",
      "Epoch 16/50\n",
      "54/54 - 2s - loss: 0.3570 - accuracy: 0.8498\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.3830 - accuracy: 0.8498\n",
      "Epoch 17/50\n",
      "27/27 - 2s - loss: 0.3679 - accuracy: 0.8638\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.4293 - accuracy: 0.8178\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.2078 - accuracy: 0.9108\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.4833 - accuracy: 0.7897\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.3490 - accuracy: 0.8075\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.3501 - accuracy: 0.8271\n",
      "Epoch 17/50\n",
      "54/54 - 2s - loss: 0.3904 - accuracy: 0.8310\n",
      "Epoch 18/50\n",
      "27/27 - 2s - loss: 0.3222 - accuracy: 0.8357\n",
      "Epoch 22/50\n",
      "27/27 - 2s - loss: 0.4330 - accuracy: 0.8364\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.1833 - accuracy: 0.9249\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.3879 - accuracy: 0.8451\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.3917 - accuracy: 0.8224\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 26/50\n",
      "27/27 - 2s - loss: 0.3200 - accuracy: 0.8310\n",
      "Epoch 18/50\n",
      "54/54 - 2s - loss: 0.3031 - accuracy: 0.8592\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.2431 - accuracy: 0.8879\n",
      "Epoch 19/50\n",
      "27/27 - 2s - loss: 0.3480 - accuracy: 0.8216\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 20/50\n",
      "27/27 - 2s - loss: 0.3421 - accuracy: 0.8075\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.4143 - accuracy: 0.7991\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.1717 - accuracy: 0.9296\n",
      "Epoch 27/50\n",
      "27/27 - 2s - loss: 0.3239 - accuracy: 0.8685\n",
      "Epoch 20/50\n",
      "27/27 - 2s - loss: 0.3178 - accuracy: 0.8364\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 19/50\n",
      "54/54 - 2s - loss: 0.2379 - accuracy: 0.9014\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.3816 - accuracy: 0.8216\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.2538 - accuracy: 0.9065\n",
      "Epoch 20/50\n",
      "27/27 - 2s - loss: 0.4139 - accuracy: 0.8357\n",
      "Epoch 24/50\n",
      "27/27 - 2s - loss: 0.4045 - accuracy: 0.7991\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.2119 - accuracy: 0.9061\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.3491 - accuracy: 0.8592\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.3124 - accuracy: 0.8645\n",
      "Epoch 20/50\n",
      "54/54 - 2s - loss: 0.2197 - accuracy: 0.8920\n",
      "Epoch 22/50\n",
      "27/27 - 2s - loss: 0.2741 - accuracy: 0.8638\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 21/50\n",
      "27/27 - 2s - loss: 0.2672 - accuracy: 0.8873\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.1917 - accuracy: 0.9159\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.3792 - accuracy: 0.7850\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.1747 - accuracy: 0.9202\n",
      "Epoch 22/50\n",
      "27/27 - 2s - loss: 0.2815 - accuracy: 0.8692\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.3410 - accuracy: 0.8075\n",
      "Epoch 22/50\n",
      "27/27 - 2s - loss: 0.2068 - accuracy: 0.8967\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.2182 - accuracy: 0.9437\n",
      "Epoch 21/50\n",
      "54/54 - 2s - loss: 0.2041 - accuracy: 0.9202\n",
      "Epoch 26/50\n",
      "27/27 - 2s - loss: 0.4379 - accuracy: 0.7897\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.2591 - accuracy: 0.8832\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.3333 - accuracy: 0.8364\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.3367 - accuracy: 0.8451\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.1670 - accuracy: 0.9343\n",
      "Epoch 24/50\n",
      "27/27 - 2s - loss: 0.2454 - accuracy: 0.9061\n",
      "Epoch 23/50\n",
      "27/27 - 2s - loss: 0.3274 - accuracy: 0.8592\n",
      "Epoch 22/50\n",
      "54/54 - 2s - loss: 0.2048 - accuracy: 0.9061\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 27/50\n",
      "27/27 - 2s - loss: 0.3740 - accuracy: 0.8178\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.1938 - accuracy: 0.9252\n",
      "Epoch 24/50\n",
      "27/27 - 2s - loss: 0.3184 - accuracy: 0.8879\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.3583 - accuracy: 0.8638\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.1428 - accuracy: 0.9390\n",
      "Epoch 24/50\n",
      "27/27 - 1s - loss: 0.2096 - accuracy: 0.9108\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.2930 - accuracy: 0.8732\n",
      "Epoch 23/50\n",
      "54/54 - 2s - loss: 0.1706 - accuracy: 0.9296\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.2091 - accuracy: 0.9065\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.4092 - accuracy: 0.7804\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.2954 - accuracy: 0.8645\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 32/50\n",
      "27/27 - 2s - loss: 0.3237 - accuracy: 0.8310\n",
      "Epoch 25/50\n",
      "27/27 - 2s - loss: 0.2033 - accuracy: 0.8967\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.1754 - accuracy: 0.9202\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.2231 - accuracy: 0.9249\n",
      "Epoch 24/50\n",
      "54/54 - 2s - loss: 0.1592 - accuracy: 0.9202\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.4078 - accuracy: 0.8131\n",
      "Epoch 33/50\n",
      "27/27 - 2s - loss: 0.3563 - accuracy: 0.8357\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.1565 - accuracy: 0.9252\n",
      "Epoch 26/50\n",
      "27/27 - 2s - loss: 0.2447 - accuracy: 0.8972\n",
      "Epoch 26/50\n",
      "27/27 - 2s - loss: 0.1793 - accuracy: 0.9343\n",
      "Epoch 27/50\n",
      "27/27 - 2s - loss: 0.3002 - accuracy: 0.8545\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.1659 - accuracy: 0.9390\n",
      "Epoch 25/50\n",
      "54/54 - 2s - loss: 0.1762 - accuracy: 0.9390\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.3752 - accuracy: 0.8271\n",
      "Epoch 27/50\n",
      "27/27 - 2s - loss: 0.2448 - accuracy: 0.9112\n",
      "Epoch 34/50\n",
      "27/27 - 2s - loss: 0.3327 - accuracy: 0.8357\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.1786 - accuracy: 0.9299\n",
      "Epoch 27/50\n",
      "27/27 - 2s - loss: 0.2827 - accuracy: 0.9202\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.3377 - accuracy: 0.8779\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.1376 - accuracy: 0.9343\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.3566 - accuracy: 0.8364\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.2686 - accuracy: 0.8925\n",
      "Epoch 26/50\n",
      "54/54 - 2s - loss: 0.1585 - accuracy: 0.9484\n",
      "Epoch 35/50\n",
      "27/27 - 2s - loss: 0.3412 - accuracy: 0.8545\n",
      "Epoch 28/50\n",
      "27/27 - 2s - loss: 0.1749 - accuracy: 0.9249\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.2026 - accuracy: 0.9112\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.2323 - accuracy: 0.8873\n",
      "Epoch 32/50\n",
      "27/27 - 1s - loss: 0.3746 - accuracy: 0.8037\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.1091 - accuracy: 0.9624\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.1872 - accuracy: 0.9159\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 36/50\n",
      "27/27 - 2s - loss: 0.3059 - accuracy: 0.8873\n",
      "Epoch 27/50\n",
      "54/54 - 2s - loss: 0.1446 - accuracy: 0.9437\n",
      "Epoch 29/50\n",
      "27/27 - 2s - loss: 0.2094 - accuracy: 0.9108\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.1227 - accuracy: 0.9486\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.2326 - accuracy: 0.9108\n",
      "Epoch 33/50\n",
      "27/27 - 2s - loss: 0.4101 - accuracy: 0.8458\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.1527 - accuracy: 0.9437\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.3002 - accuracy: 0.8972\n",
      "Epoch 37/50\n",
      "27/27 - 2s - loss: 0.3282 - accuracy: 0.8404\n",
      "Epoch 28/50\n",
      "54/54 - 2s - loss: 0.1613 - accuracy: 0.9155\n",
      "Epoch 30/50\n",
      "27/27 - 2s - loss: 0.1267 - accuracy: 0.9484\n",
      "Epoch 34/50\n",
      "27/27 - 2s - loss: 0.3699 - accuracy: 0.8318\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.2099 - accuracy: 0.9202\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.1395 - accuracy: 0.9252\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.2131 - accuracy: 0.9112\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.1931 - accuracy: 0.8967\n",
      "Epoch 38/50\n",
      "27/27 - 2s - loss: 0.3289 - accuracy: 0.8404\n",
      "Epoch 31/50\n",
      "27/27 - 2s - loss: 0.1622 - accuracy: 0.9296\n",
      "Epoch 29/50\n",
      "54/54 - 2s - loss: 0.2047 - accuracy: 0.9249\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/50\n",
      "27/27 - 2s - loss: 0.1826 - accuracy: 0.9296\n",
      "Epoch 35/50\n",
      "27/27 - 2s - loss: 0.3503 - accuracy: 0.8551\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.1588 - accuracy: 0.9159\n",
      "Epoch 32/50\n",
      "27/27 - 2s - loss: 0.2341 - accuracy: 0.9206\n",
      "Epoch 32/50\n",
      "27/27 - 2s - loss: 0.0991 - accuracy: 0.9437\n",
      "Epoch 39/50\n",
      "27/27 - 2s - loss: 0.3184 - accuracy: 0.8592\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.1479 - accuracy: 0.9296\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.1169 - accuracy: 0.9484\n",
      "Epoch 36/50\n",
      "27/27 - 2s - loss: 0.3863 - accuracy: 0.8224\n",
      "Epoch 33/50\n",
      "27/27 - 2s - loss: 0.1924 - accuracy: 0.9108\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.2510 - accuracy: 0.8879\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.1055 - accuracy: 0.9579\n",
      "Epoch 33/50\n",
      "27/27 - 2s - loss: 0.1432 - accuracy: 0.9437\n",
      "Epoch 40/50\n",
      "27/27 - 2s - loss: 0.3067 - accuracy: 0.8638\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.0750 - accuracy: 0.9812\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 31/50\n",
      "54/54 - 2s - loss: 0.1146 - accuracy: 0.9390\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.3858 - accuracy: 0.7991\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.1896 - accuracy: 0.9299\n",
      "Epoch 34/50\n",
      "27/27 - 2s - loss: 0.1512 - accuracy: 0.9437\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.0733 - accuracy: 0.9813\n",
      "Epoch 34/50\n",
      "27/27 - 2s - loss: 0.1333 - accuracy: 0.9718\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.1564 - accuracy: 0.9249\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.3045 - accuracy: 0.8451\n",
      "Epoch 32/50\n",
      "54/54 - 2s - loss: 0.0878 - accuracy: 0.9577\n",
      "Epoch 38/50\n",
      "27/27 - 2s - loss: 0.3652 - accuracy: 0.8411\n",
      "Epoch 35/50\n",
      "27/27 - 2s - loss: 0.2731 - accuracy: 0.8925\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.1752 - accuracy: 0.9343\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.1147 - accuracy: 0.9486\n",
      "Epoch 35/50\n",
      "27/27 - 2s - loss: 0.1542 - accuracy: 0.9202\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.3837 - accuracy: 0.8216\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.1031 - accuracy: 0.9531\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.4012 - accuracy: 0.7897\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 36/50\n",
      "27/27 - 2s - loss: 0.1440 - accuracy: 0.9437\n",
      "Epoch 36/50\n",
      "27/27 - 2s - loss: 0.2326 - accuracy: 0.9159\n",
      "Epoch 33/50\n",
      "54/54 - 2s - loss: 0.0964 - accuracy: 0.9577\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.1229 - accuracy: 0.9439\n",
      "Epoch 36/50\n",
      "27/27 - 2s - loss: 0.1381 - accuracy: 0.9343\n",
      "Epoch 43/50\n",
      "27/27 - 2s - loss: 0.2939 - accuracy: 0.8638\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 40/50\n",
      "27/27 - 2s - loss: 0.3738 - accuracy: 0.8037\n",
      "Epoch 37/50\n",
      "27/27 - 2s - loss: 0.2391 - accuracy: 0.9252\n",
      "Epoch 37/50\n",
      "27/27 - 2s - loss: 0.1301 - accuracy: 0.9531\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.0717 - accuracy: 0.9671\n",
      "Epoch 34/50\n",
      "54/54 - 2s - loss: 0.1604 - accuracy: 0.9343\n",
      "Epoch 37/50\n",
      "27/27 - 2s - loss: 0.1022 - accuracy: 0.9671\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.1313 - accuracy: 0.9673\n",
      "Epoch 44/50\n",
      "27/27 - 2s - loss: 0.3187 - accuracy: 0.8732\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.1830 - accuracy: 0.9155\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.3778 - accuracy: 0.8224\n",
      "Epoch 38/50\n",
      "27/27 - 2s - loss: 0.1778 - accuracy: 0.9206\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.0699 - accuracy: 0.9624\n",
      "Epoch 35/50\n",
      "54/54 - 2s - loss: 0.1034 - accuracy: 0.9624\n",
      "Epoch 38/50\n",
      "27/27 - 2s - loss: 0.1921 - accuracy: 0.9296\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.1510 - accuracy: 0.9252\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 45/50\n",
      "27/27 - 2s - loss: 0.2896 - accuracy: 0.8732\n",
      "Epoch 42/50\n",
      "27/27 - 2s - loss: 0.3731 - accuracy: 0.8364\n",
      "Epoch 39/50\n",
      "27/27 - 2s - loss: 0.1398 - accuracy: 0.9390\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 39/50\n",
      "27/27 - 2s - loss: 0.1644 - accuracy: 0.9393\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.0603 - accuracy: 0.9765\n",
      "Epoch 36/50\n",
      "54/54 - 2s - loss: 0.0815 - accuracy: 0.9671\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 39/50\n",
      "27/27 - 2s - loss: 0.1519 - accuracy: 0.9531\n",
      "Epoch 46/50\n",
      "27/27 - 2s - loss: 0.2992 - accuracy: 0.8826\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.3709 - accuracy: 0.8318\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.1076 - accuracy: 0.9533\n",
      "Epoch 40/50\n",
      "27/27 - 2s - loss: 0.1319 - accuracy: 0.9299\n",
      "Epoch 40/50\n",
      "27/27 - 2s - loss: 0.1955 - accuracy: 0.9155\n",
      "Epoch 40/50\n",
      "27/27 - 2s - loss: 0.0719 - accuracy: 0.9671\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.0546 - accuracy: 0.9718\n",
      "Epoch 37/50\n",
      "54/54 - 2s - loss: 0.0654 - accuracy: 0.9718\n",
      "Epoch 47/50\n",
      "27/27 - 2s - loss: 0.3138 - accuracy: 0.8310\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 44/50\n",
      "27/27 - 2s - loss: 0.4004 - accuracy: 0.8178\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.1540 - accuracy: 0.9486\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.1271 - accuracy: 0.9579\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.1737 - accuracy: 0.8873\n",
      "Epoch 41/50\n",
      "27/27 - 2s - loss: 0.1019 - accuracy: 0.9624\n",
      "Epoch 48/50\n",
      "27/27 - 2s - loss: 0.3636 - accuracy: 0.8779\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.0438 - accuracy: 0.9906\n",
      "Epoch 45/50\n",
      "27/27 - 2s - loss: 0.3782 - accuracy: 0.8458\n",
      "Epoch 38/50\n",
      "54/54 - 2s - loss: 0.1431 - accuracy: 0.9390\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.1018 - accuracy: 0.9579\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.1643 - accuracy: 0.9393\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 42/50\n",
      "27/27 - 2s - loss: 0.1596 - accuracy: 0.9296\n",
      "Epoch 42/50\n",
      "27/27 - 2s - loss: 0.1425 - accuracy: 0.9437\n",
      "Epoch 46/50\n",
      "27/27 - 2s - loss: 0.3425 - accuracy: 0.8364\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 49/50\n",
      "27/27 - 2s - loss: 0.3389 - accuracy: 0.8310\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.0810 - accuracy: 0.9671\n",
      "Epoch 39/50\n",
      "54/54 - 2s - loss: 0.0742 - accuracy: 0.9671\n",
      "Epoch 43/50\n",
      "27/27 - 2s - loss: 0.1409 - accuracy: 0.9252\n",
      "Epoch 43/50\n",
      "27/27 - 2s - loss: 0.1647 - accuracy: 0.9155\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.1054 - accuracy: 0.9486\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 43/50\n",
      "27/27 - 2s - loss: 0.0887 - accuracy: 0.9531\n",
      "Epoch 50/50\n",
      "27/27 - 2s - loss: 0.3287 - accuracy: 0.8545\n",
      "Epoch 47/50\n",
      "27/27 - 2s - loss: 0.3704 - accuracy: 0.8411\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.0929 - accuracy: 0.9671\n",
      "Epoch 40/50\n",
      "54/54 - 2s - loss: 0.0581 - accuracy: 0.9718\n",
      "Epoch 44/50\n",
      "27/27 - 2s - loss: 0.1073 - accuracy: 0.9626\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.1337 - accuracy: 0.9393\n",
      "Epoch 44/50\n",
      "27/27 - 2s - loss: 0.1544 - accuracy: 0.9624\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.1291 - accuracy: 0.9531\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.3611 - accuracy: 0.8364\n",
      "14/14 - 1s - loss: 0.5563 - accuracy: 0.7103\n",
      "Epoch 41/50\n",
      "54/54 - 2s - loss: 0.1077 - accuracy: 0.9531\n",
      "Epoch 41/50\n",
      "54/54 - 2s - loss: 0.0403 - accuracy: 0.9859\n",
      "Epoch 45/50\n",
      "27/27 - 2s - loss: 0.0979 - accuracy: 0.9533\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.0993 - accuracy: 0.9673\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.2142 - accuracy: 0.9249\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.3742 - accuracy: 0.8411\n",
      "Epoch 45/50\n",
      "27/27 - 2s - loss: 0.1296 - accuracy: 0.9343\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.0711 - accuracy: 0.9673\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.0790 - accuracy: 0.9577\n",
      "Epoch 42/50\n",
      "54/54 - 2s - loss: 0.0435 - accuracy: 0.9953\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.3627 - accuracy: 0.8318\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.1584 - accuracy: 0.9249\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.1015 - accuracy: 0.9720\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.1600 - accuracy: 0.9249\n",
      "14/14 - 1s - loss: 0.5277 - accuracy: 0.7547\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.1800 - accuracy: 0.9108\n",
      "Epoch 47/50\n",
      "27/27 - 2s - loss: 0.0913 - accuracy: 0.9813\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.0794 - accuracy: 0.9577\n",
      "Epoch 43/50\n",
      "54/54 - 2s - loss: 0.0300 - accuracy: 0.9859\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.0948 - accuracy: 0.9484\n",
      "Epoch 44/50\n",
      "54/54 - 2s - loss: 0.1004 - accuracy: 0.9720\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.0419 - accuracy: 0.9812\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.1705 - accuracy: 0.9343\n",
      "Epoch 48/50\n",
      "27/27 - 2s - loss: 0.0945 - accuracy: 0.9486\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.0709 - accuracy: 0.9624\n",
      "Epoch 44/50\n",
      "54/54 - 2s - loss: 0.0577 - accuracy: 0.9765\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 45/50\n",
      "54/54 - 2s - loss: 0.0977 - accuracy: 0.9533\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.0764 - accuracy: 0.9671\n",
      "Epoch 1/50\n",
      "27/27 - 5s - loss: 0.9936 - accuracy: 0.4601\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.0802 - accuracy: 0.9859\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 49/50\n",
      "27/27 - 2s - loss: 0.1115 - accuracy: 0.9531\n",
      "Epoch 49/50\n",
      "27/27 - 2s - loss: 0.1031 - accuracy: 0.9766\n",
      "Epoch 45/50\n",
      "54/54 - 2s - loss: 0.0976 - accuracy: 0.9624\n",
      "Epoch 46/50\n",
      "54/54 - 2s - loss: 0.1068 - accuracy: 0.9533\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 0.8099 - accuracy: 0.6291\n",
      "Epoch 46/50\n",
      "54/54 - 2s - loss: 0.0721 - accuracy: 0.9671\n",
      "Epoch 2/50\n",
      "27/27 - 2s - loss: 0.7735 - accuracy: 0.5399\n",
      "Epoch 50/50\n",
      "27/27 - 2s - loss: 0.0600 - accuracy: 0.9718\n",
      "Epoch 50/50\n",
      "27/27 - 2s - loss: 0.1723 - accuracy: 0.9299\n",
      "Epoch 50/50\n",
      "27/27 - 2s - loss: 0.2499 - accuracy: 0.9108\n",
      "Epoch 46/50\n",
      "54/54 - 2s - loss: 0.0972 - accuracy: 0.9531\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.1071 - accuracy: 0.9626\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.6868 - accuracy: 0.6526\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.6771 - accuracy: 0.5869\n",
      "14/14 - 1s - loss: 0.5288 - accuracy: 0.7850\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.0963 - accuracy: 0.9577\n",
      "14/14 - 1s - loss: 0.4416 - accuracy: 0.7850\n",
      "14/14 - 1s - loss: 0.4665 - accuracy: 0.7925\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.1415 - accuracy: 0.9533\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.6562 - accuracy: 0.6808\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.7017 - accuracy: 0.6244\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.0692 - accuracy: 0.9718\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.0705 - accuracy: 0.9812\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.0805 - accuracy: 0.9720\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.6490 - accuracy: 0.5915\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.6053 - accuracy: 0.6573\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.0990 - accuracy: 0.9671\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.0658 - accuracy: 0.9812\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.1101 - accuracy: 0.9486\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.6892 - accuracy: 0.6291\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.6120 - accuracy: 0.6620\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.0582 - accuracy: 0.9906\n",
      "27/27 - 1s - loss: 0.5979 - accuracy: 0.7453\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.0505 - accuracy: 0.9765\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.5560 - accuracy: 0.7465\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.5459 - accuracy: 0.7042\n",
      "27/27 - 0s - loss: 0.5329 - accuracy: 0.7757\n",
      "27/27 - 1s - loss: 0.4927 - accuracy: 0.8037\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.5933 - accuracy: 0.6995\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.5474 - accuracy: 0.7089\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 1.2186 - accuracy: 0.5915\n",
      "Epoch 1/50\n",
      "27/27 - 4s - loss: 1.1161 - accuracy: 0.4626\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.5515 - accuracy: 0.7324\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.4994 - accuracy: 0.7324\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 1.1520 - accuracy: 0.6244\n",
      "Epoch 1/50\n",
      "54/54 - 4s - loss: 1.3334 - accuracy: 0.5446\n",
      "Epoch 2/50\n",
      "27/27 - 1s - loss: 0.8320 - accuracy: 0.6121\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.5580 - accuracy: 0.6995\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.6092 - accuracy: 0.7089\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 1.2728 - accuracy: 0.5164\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 1.2120 - accuracy: 0.5446\n",
      "Epoch 3/50\n",
      "27/27 - 1s - loss: 0.7245 - accuracy: 0.6075\n",
      "Epoch 1/50\n",
      "54/54 - 3s - loss: 1.4798 - accuracy: 0.5234\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.6053 - accuracy: 0.6573\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.5362 - accuracy: 0.7793\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 0.9873 - accuracy: 0.6009\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 0.9486 - accuracy: 0.5775\n",
      "Epoch 4/50\n",
      "27/27 - 1s - loss: 0.6728 - accuracy: 0.5794\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.5443 - accuracy: 0.7606\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.5372 - accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "54/54 - 1s - loss: 1.1647 - accuracy: 0.5421\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.9575 - accuracy: 0.6338\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.5150 - accuracy: 0.7089\n",
      "Epoch 5/50\n",
      "27/27 - 1s - loss: 0.7798 - accuracy: 0.6355\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 1.0391 - accuracy: 0.6009\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.4461 - accuracy: 0.7887\n",
      "Epoch 3/50\n",
      "54/54 - 1s - loss: 1.0423 - accuracy: 0.5888\n",
      "Epoch 6/50\n",
      "27/27 - 1s - loss: 0.8335 - accuracy: 0.4860\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.5375 - accuracy: 0.8075\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 1.0513 - accuracy: 0.6056\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.5176 - accuracy: 0.7418\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.9635 - accuracy: 0.6197\n",
      "Epoch 4/50\n",
      "54/54 - 1s - loss: 1.0486 - accuracy: 0.5748\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.5343 - accuracy: 0.7277\n",
      "Epoch 7/50\n",
      "27/27 - 1s - loss: 0.6555 - accuracy: 0.6168\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.4600 - accuracy: 0.7887\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.8060 - accuracy: 0.6338\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 1.0742 - accuracy: 0.5962\n",
      "Epoch 5/50\n",
      "54/54 - 1s - loss: 0.9586 - accuracy: 0.5794\n",
      "Epoch 8/50\n",
      "27/27 - 1s - loss: 0.6281 - accuracy: 0.6495\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.4467 - accuracy: 0.7653\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.5292 - accuracy: 0.7183\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.7874 - accuracy: 0.6808\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.7248 - accuracy: 0.7136\n",
      "Epoch 6/50\n",
      "54/54 - 1s - loss: 0.7984 - accuracy: 0.6215\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.4816 - accuracy: 0.7606\n",
      "Epoch 9/50\n",
      "27/27 - 1s - loss: 0.4643 - accuracy: 0.7850\n",
      "Epoch 17/50\n",
      "27/27 - 1s - loss: 0.5018 - accuracy: 0.7465\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.7710 - accuracy: 0.6338\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.8885 - accuracy: 0.6338\n",
      "Epoch 7/50\n",
      "54/54 - 1s - loss: 0.8136 - accuracy: 0.6355\n",
      "Epoch 10/50\n",
      "27/27 - 1s - loss: 0.5872 - accuracy: 0.6402\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 17/50\n",
      "27/27 - 1s - loss: 0.4573 - accuracy: 0.7887\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.4680 - accuracy: 0.7840\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.7687 - accuracy: 0.7136\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.7946 - accuracy: 0.6714\n",
      "Epoch 11/50\n",
      "27/27 - 1s - loss: 0.6179 - accuracy: 0.6682\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.4511 - accuracy: 0.7934\n",
      "Epoch 8/50\n",
      "54/54 - 1s - loss: 0.9079 - accuracy: 0.6168\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.4555 - accuracy: 0.7746\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.7359 - accuracy: 0.7230\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.7783 - accuracy: 0.6432\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.4299 - accuracy: 0.7840\n",
      "Epoch 12/50\n",
      "27/27 - 1s - loss: 0.5545 - accuracy: 0.7150\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.4846 - accuracy: 0.7371\n",
      "Epoch 9/50\n",
      "54/54 - 1s - loss: 0.8576 - accuracy: 0.5701\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.7215 - accuracy: 0.6291\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.7635 - accuracy: 0.6432\n",
      "Epoch 13/50\n",
      "27/27 - 1s - loss: 0.5652 - accuracy: 0.7570\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.4750 - accuracy: 0.7887\n",
      "Epoch 21/50\n",
      "27/27 - 1s - loss: 0.4695 - accuracy: 0.8028\n",
      "Epoch 10/50\n",
      "54/54 - 1s - loss: 0.7036 - accuracy: 0.6822\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.7488 - accuracy: 0.6573\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 14/50\n",
      "27/27 - 1s - loss: 0.4669 - accuracy: 0.7150\n",
      "Epoch 21/50\n",
      "27/27 - 1s - loss: 0.4515 - accuracy: 0.7700\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.5950 - accuracy: 0.7089\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.4521 - accuracy: 0.7512\n",
      "Epoch 11/50\n",
      "54/54 - 1s - loss: 0.7219 - accuracy: 0.6121\n",
      "Epoch 15/50\n",
      "27/27 - 1s - loss: 0.4969 - accuracy: 0.7897\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.6379 - accuracy: 0.6901\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.4193 - accuracy: 0.7840\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 23/50\n",
      "27/27 - 1s - loss: 0.4670 - accuracy: 0.7700\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.6475 - accuracy: 0.6995\n",
      "Epoch 12/50\n",
      "54/54 - 1s - loss: 0.8521 - accuracy: 0.6168\n",
      "Epoch 16/50\n",
      "27/27 - 1s - loss: 0.5472 - accuracy: 0.6776\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.6506 - accuracy: 0.6901\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 23/50\n",
      "27/27 - 1s - loss: 0.4270 - accuracy: 0.8028\n",
      "Epoch 24/50\n",
      "27/27 - 1s - loss: 0.4663 - accuracy: 0.7418\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.8475 - accuracy: 0.7183\n",
      "Epoch 13/50\n",
      "54/54 - 1s - loss: 0.8470 - accuracy: 0.5888\n",
      "Epoch 17/50\n",
      "27/27 - 1s - loss: 0.5028 - accuracy: 0.7617\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.4297 - accuracy: 0.7700\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.4765 - accuracy: 0.7887\n",
      "Epoch 24/50\n",
      "27/27 - 1s - loss: 0.4167 - accuracy: 0.8122\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.6796 - accuracy: 0.6573\n",
      "Epoch 14/50\n",
      "54/54 - 1s - loss: 0.6290 - accuracy: 0.7150\n",
      "Epoch 18/50\n",
      "27/27 - 1s - loss: 0.5009 - accuracy: 0.7290\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.4546 - accuracy: 0.7465\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.4414 - accuracy: 0.7746\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.5353 - accuracy: 0.6948\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.6264 - accuracy: 0.7230\n",
      "Epoch 15/50\n",
      "54/54 - 1s - loss: 0.6427 - accuracy: 0.6869\n",
      "Epoch 19/50\n",
      "27/27 - 1s - loss: 0.5164 - accuracy: 0.7570\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.3951 - accuracy: 0.8028\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.4535 - accuracy: 0.7512\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.6805 - accuracy: 0.6808\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.6470 - accuracy: 0.7230\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 20/50\n",
      "27/27 - 1s - loss: 0.4748 - accuracy: 0.6963\n",
      "Epoch 16/50\n",
      "54/54 - 1s - loss: 0.7148 - accuracy: 0.6449\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.3849 - accuracy: 0.8122\n",
      "Epoch 28/50\n",
      "27/27 - 1s - loss: 0.4162 - accuracy: 0.8028\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.5335 - accuracy: 0.7465\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.6446 - accuracy: 0.6995\n",
      "Epoch 21/50\n",
      "27/27 - 1s - loss: 0.4383 - accuracy: 0.8318\n",
      "Epoch 28/50\n",
      "27/27 - 1s - loss: 0.3981 - accuracy: 0.8263\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.4093 - accuracy: 0.8122\n",
      "Epoch 17/50\n",
      "54/54 - 1s - loss: 0.6719 - accuracy: 0.6542\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.6451 - accuracy: 0.6761\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.6406 - accuracy: 0.6995\n",
      "Epoch 22/50\n",
      "27/27 - 1s - loss: 0.4668 - accuracy: 0.7897\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.4429 - accuracy: 0.8028\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.4077 - accuracy: 0.7887\n",
      "Epoch 18/50\n",
      "54/54 - 1s - loss: 0.5907 - accuracy: 0.6916\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.5814 - accuracy: 0.7371\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.6177 - accuracy: 0.7418\n",
      "Epoch 23/50\n",
      "27/27 - 1s - loss: 0.4403 - accuracy: 0.7991\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.4401 - accuracy: 0.7840\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.4138 - accuracy: 0.8028\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.6447 - accuracy: 0.6995\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 19/50\n",
      "54/54 - 1s - loss: 0.6518 - accuracy: 0.6402\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.5146 - accuracy: 0.7559\n",
      "Epoch 24/50\n",
      "27/27 - 1s - loss: 0.4688 - accuracy: 0.7664\n",
      "Epoch 32/50\n",
      "27/27 - 1s - loss: 0.4137 - accuracy: 0.8122\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.3861 - accuracy: 0.7981\n",
      "Epoch 20/50\n",
      "54/54 - 1s - loss: 0.5790 - accuracy: 0.6869\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.5816 - accuracy: 0.6667\n",
      "Epoch 25/50\n",
      "27/27 - 1s - loss: 0.4404 - accuracy: 0.8084\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.5758 - accuracy: 0.7559\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.4120 - accuracy: 0.8216\n",
      "Epoch 32/50\n",
      "27/27 - 1s - loss: 0.3939 - accuracy: 0.8169\n",
      "Epoch 21/50\n",
      "54/54 - 1s - loss: 0.5638 - accuracy: 0.7430\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 26/50\n",
      "27/27 - 1s - loss: 0.4981 - accuracy: 0.7664\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.5886 - accuracy: 0.6995\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.5371 - accuracy: 0.7418\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.4130 - accuracy: 0.7887\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.3959 - accuracy: 0.8310\n",
      "Epoch 22/50\n",
      "54/54 - 1s - loss: 0.5875 - accuracy: 0.6963\n",
      "Epoch 27/50\n",
      "27/27 - 1s - loss: 0.4740 - accuracy: 0.7850\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.5979 - accuracy: 0.7089\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.4308 - accuracy: 0.7512\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.3840 - accuracy: 0.8169\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.3980 - accuracy: 0.8169\n",
      "Epoch 28/50\n",
      "27/27 - 1s - loss: 0.4038 - accuracy: 0.7804\n",
      "Epoch 23/50\n",
      "54/54 - 1s - loss: 0.5655 - accuracy: 0.7103\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.4237 - accuracy: 0.8310\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.4183 - accuracy: 0.8169\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.5620 - accuracy: 0.7089\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.5173 - accuracy: 0.7465\n",
      "Epoch 29/50\n",
      "27/27 - 1s - loss: 0.5036 - accuracy: 0.7523\n",
      "Epoch 24/50\n",
      "54/54 - 1s - loss: 0.6269 - accuracy: 0.7103\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.4088 - accuracy: 0.8216\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.3670 - accuracy: 0.8216\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.6113 - accuracy: 0.6808\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.4941 - accuracy: 0.7559\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 30/50\n",
      "27/27 - 1s - loss: 0.4567 - accuracy: 0.7617\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.3918 - accuracy: 0.8075\n",
      "Epoch 25/50\n",
      "54/54 - 1s - loss: 0.5989 - accuracy: 0.6916\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.3998 - accuracy: 0.8075\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.5047 - accuracy: 0.7653\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.6027 - accuracy: 0.7230\n",
      "Epoch 31/50\n",
      "27/27 - 1s - loss: 0.4248 - accuracy: 0.7710\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.4082 - accuracy: 0.8216\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.3568 - accuracy: 0.8310\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 26/50\n",
      "54/54 - 1s - loss: 0.6051 - accuracy: 0.7103\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.4616 - accuracy: 0.7606\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.5544 - accuracy: 0.7183\n",
      "Epoch 32/50\n",
      "27/27 - 1s - loss: 0.4415 - accuracy: 0.7991\n",
      "Epoch 40/50\n",
      "27/27 - 1s - loss: 0.4312 - accuracy: 0.8122\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.4159 - accuracy: 0.7887\n",
      "Epoch 27/50\n",
      "54/54 - 1s - loss: 0.5194 - accuracy: 0.7290\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.6010 - accuracy: 0.6901\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.4259 - accuracy: 0.7840\n",
      "Epoch 33/50\n",
      "27/27 - 1s - loss: 0.4758 - accuracy: 0.7850\n",
      "Epoch 40/50\n",
      "27/27 - 1s - loss: 0.3918 - accuracy: 0.8028\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 41/50\n",
      "27/27 - 1s - loss: 0.4456 - accuracy: 0.7418\n",
      "Epoch 28/50\n",
      "54/54 - 1s - loss: 0.4814 - accuracy: 0.7710\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.5049 - accuracy: 0.7793\n",
      "Epoch 30/50\n",
      "54/54 - 2s - loss: 0.5152 - accuracy: 0.7465\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 34/50\n",
      "27/27 - 1s - loss: 0.4292 - accuracy: 0.7617\n",
      "Epoch 41/50\n",
      "27/27 - 1s - loss: 0.3770 - accuracy: 0.7746\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.3880 - accuracy: 0.7981\n",
      "Epoch 29/50\n",
      "54/54 - 1s - loss: 0.5336 - accuracy: 0.7617\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.5861 - accuracy: 0.7277\n",
      "Epoch 35/50\n",
      "27/27 - 1s - loss: 0.4554 - accuracy: 0.7757\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.4747 - accuracy: 0.7512\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.3751 - accuracy: 0.8451\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.3987 - accuracy: 0.8122\n",
      "Epoch 30/50\n",
      "54/54 - 1s - loss: 0.4915 - accuracy: 0.7523\n",
      "Epoch 36/50\n",
      "27/27 - 1s - loss: 0.4609 - accuracy: 0.7523\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.5122 - accuracy: 0.7277\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.5811 - accuracy: 0.7324\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.4044 - accuracy: 0.8028\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.3830 - accuracy: 0.8216\n",
      "Epoch 37/50\n",
      "27/27 - 1s - loss: 0.4624 - accuracy: 0.7757\n",
      "Epoch 31/50\n",
      "54/54 - 1s - loss: 0.4783 - accuracy: 0.7664\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.5038 - accuracy: 0.7559\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.3812 - accuracy: 0.8263\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.3966 - accuracy: 0.8122\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.5099 - accuracy: 0.7606\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 38/50\n",
      "27/27 - 1s - loss: 0.5112 - accuracy: 0.7757\n",
      "Epoch 32/50\n",
      "54/54 - 1s - loss: 0.5595 - accuracy: 0.7290\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.4306 - accuracy: 0.7746\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.4847 - accuracy: 0.7653\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.3879 - accuracy: 0.7981\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.6542 - accuracy: 0.7183\n",
      "Epoch 39/50\n",
      "27/27 - 1s - loss: 0.4218 - accuracy: 0.7757\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.4422 - accuracy: 0.7887\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 33/50\n",
      "54/54 - 1s - loss: 0.5417 - accuracy: 0.7336\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.4225 - accuracy: 0.7887\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.5299 - accuracy: 0.7934\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.6111 - accuracy: 0.7512\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.4586 - accuracy: 0.7559\n",
      "Epoch 40/50\n",
      "27/27 - 1s - loss: 0.5229 - accuracy: 0.7383\n",
      "Epoch 34/50\n",
      "54/54 - 1s - loss: 0.4454 - accuracy: 0.7944\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.3505 - accuracy: 0.8357\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.5938 - accuracy: 0.7512\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.5311 - accuracy: 0.7512\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.4563 - accuracy: 0.7981\n",
      "Epoch 41/50\n",
      "27/27 - 1s - loss: 0.5114 - accuracy: 0.7617\n",
      "Epoch 35/50\n",
      "54/54 - 1s - loss: 0.5396 - accuracy: 0.7103\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.3943 - accuracy: 0.7887\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.5128 - accuracy: 0.6808\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.5144 - accuracy: 0.7324\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 42/50\n",
      "27/27 - 1s - loss: 0.4267 - accuracy: 0.8131\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.4385 - accuracy: 0.8075\n",
      "Epoch 36/50\n",
      "54/54 - 1s - loss: 0.4828 - accuracy: 0.7710\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.4195 - accuracy: 0.8122\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.5394 - accuracy: 0.7324\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.5495 - accuracy: 0.7089\n",
      "14/14 - 1s - loss: 0.5882 - accuracy: 0.6449\n",
      "Epoch 43/50\n",
      "27/27 - 1s - loss: 0.4817 - accuracy: 0.7523\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.3866 - accuracy: 0.7887\n",
      "Epoch 37/50\n",
      "54/54 - 1s - loss: 0.5167 - accuracy: 0.7383\n",
      "Epoch 44/50\n",
      "27/27 - 1s - loss: 0.5032 - accuracy: 0.7383\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.4563 - accuracy: 0.7653\n",
      "14/14 - 0s - loss: 0.6047 - accuracy: 0.7009\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.6191 - accuracy: 0.7371\n",
      "Epoch 38/50\n",
      "54/54 - 1s - loss: 0.5613 - accuracy: 0.7103\n",
      "Epoch 45/50\n",
      "27/27 - 1s - loss: 0.4580 - accuracy: 0.7757\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.5054 - accuracy: 0.7981\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.5848 - accuracy: 0.7606\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 39/50\n",
      "54/54 - 1s - loss: 0.4649 - accuracy: 0.7523\n",
      "Epoch 46/50\n",
      "27/27 - 1s - loss: 0.4593 - accuracy: 0.7383\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.4167 - accuracy: 0.7559\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.5044 - accuracy: 0.7418\n",
      "Epoch 47/50\n",
      "27/27 - 1s - loss: 0.4812 - accuracy: 0.7710\n",
      "Epoch 40/50\n",
      "54/54 - 1s - loss: 0.4978 - accuracy: 0.7804\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.4731 - accuracy: 0.7840\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.5188 - accuracy: 0.7277\n",
      "Epoch 48/50\n",
      "27/27 - 1s - loss: 0.4555 - accuracy: 0.7944\n",
      "Epoch 41/50\n",
      "54/54 - 1s - loss: 0.4663 - accuracy: 0.7290\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.5503 - accuracy: 0.7324\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.4233 - accuracy: 0.7793\n",
      "Epoch 49/50\n",
      "27/27 - 1s - loss: 0.4761 - accuracy: 0.7430\n",
      "Epoch 42/50\n",
      "54/54 - 1s - loss: 0.4772 - accuracy: 0.7523\n",
      "Epoch 50/50\n",
      "27/27 - 1s - loss: 0.4854 - accuracy: 0.7757\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.6112 - accuracy: 0.7183\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.4480 - accuracy: 0.7512\n",
      "14/14 - 0s - loss: 0.6110 - accuracy: 0.6132\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 43/50\n",
      "54/54 - 1s - loss: 0.4568 - accuracy: 0.7757\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.4670 - accuracy: 0.7840\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.6656 - accuracy: 0.6761\n",
      "Epoch 44/50\n",
      "54/54 - 1s - loss: 0.5439 - accuracy: 0.7336\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.5512 - accuracy: 0.7371\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.4414 - accuracy: 0.8028\n",
      "Epoch 45/50\n",
      "54/54 - 1s - loss: 0.5380 - accuracy: 0.7617\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.5937 - accuracy: 0.7136\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.4580 - accuracy: 0.7700\n",
      "Epoch 46/50\n",
      "54/54 - 1s - loss: 0.4195 - accuracy: 0.8037\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.4954 - accuracy: 0.7277\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.4508 - accuracy: 0.7512\n",
      "Epoch 47/50\n",
      "54/54 - 1s - loss: 0.4059 - accuracy: 0.7850\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.4492 - accuracy: 0.7793\n",
      "Epoch 49/50\n",
      "54/54 - 1s - loss: 0.6023 - accuracy: 0.7183\n",
      "Epoch 48/50\n",
      "54/54 - 1s - loss: 0.5378 - accuracy: 0.7383\n",
      "27/27 - 0s - loss: 0.6132 - accuracy: 0.6636\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 50/50\n",
      "54/54 - 1s - loss: 0.5271 - accuracy: 0.7371\n",
      "Epoch 49/50\n",
      "54/54 - 0s - loss: 0.5283 - accuracy: 0.7009\n",
      "27/27 - 0s - loss: 0.6230 - accuracy: 0.6542\n",
      "Epoch 50/50\n",
      "54/54 - 0s - loss: 0.4812 - accuracy: 0.7430\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "27/27 - 0s - loss: 0.6415 - accuracy: 0.6415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 16:31:54.721178: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 16:31:54.721766: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-30 16:31:54.949222: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-30 16:31:54.966176: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 - 1s - loss: 0.8370 - accuracy: 0.5781\n",
      "Epoch 2/50\n",
      "20/20 - 0s - loss: 0.7007 - accuracy: 0.6906\n",
      "Epoch 3/50\n",
      "20/20 - 0s - loss: 0.5834 - accuracy: 0.6531\n",
      "Epoch 4/50\n",
      "20/20 - 0s - loss: 0.4804 - accuracy: 0.7781\n",
      "Epoch 5/50\n",
      "20/20 - 0s - loss: 0.4406 - accuracy: 0.7625\n",
      "Epoch 6/50\n",
      "20/20 - 0s - loss: 0.4984 - accuracy: 0.8094\n",
      "Epoch 7/50\n",
      "20/20 - 0s - loss: 0.4205 - accuracy: 0.7688\n",
      "Epoch 8/50\n",
      "20/20 - 0s - loss: 0.4831 - accuracy: 0.7375\n",
      "Epoch 9/50\n",
      "20/20 - 0s - loss: 0.4562 - accuracy: 0.7719\n",
      "Epoch 10/50\n",
      "20/20 - 0s - loss: 0.3969 - accuracy: 0.8000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/50\n",
      "20/20 - 0s - loss: 0.3395 - accuracy: 0.8344\n",
      "Epoch 12/50\n",
      "20/20 - 0s - loss: 0.2679 - accuracy: 0.8687\n",
      "Epoch 13/50\n",
      "20/20 - 0s - loss: 0.2634 - accuracy: 0.8813\n",
      "Epoch 14/50\n",
      "20/20 - 0s - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 15/50\n",
      "20/20 - 0s - loss: 0.2728 - accuracy: 0.8813\n",
      "Epoch 16/50\n",
      "20/20 - 0s - loss: 0.1980 - accuracy: 0.9125\n",
      "Epoch 17/50\n",
      "20/20 - 0s - loss: 0.2455 - accuracy: 0.9031\n",
      "Epoch 18/50\n",
      "20/20 - 0s - loss: 0.2612 - accuracy: 0.9031\n",
      "Epoch 19/50\n",
      "20/20 - 0s - loss: 0.1795 - accuracy: 0.9094\n",
      "Epoch 20/50\n",
      "20/20 - 0s - loss: 0.2022 - accuracy: 0.9281\n",
      "Epoch 21/50\n",
      "20/20 - 0s - loss: 0.2056 - accuracy: 0.9000\n",
      "Epoch 22/50\n",
      "20/20 - 0s - loss: 0.1655 - accuracy: 0.9312\n",
      "Epoch 23/50\n",
      "20/20 - 0s - loss: 0.1478 - accuracy: 0.9438\n",
      "Epoch 24/50\n",
      "20/20 - 0s - loss: 0.1454 - accuracy: 0.9469\n",
      "Epoch 25/50\n",
      "20/20 - 0s - loss: 0.1629 - accuracy: 0.9312\n",
      "Epoch 26/50\n",
      "20/20 - 0s - loss: 0.1214 - accuracy: 0.9438\n",
      "Epoch 27/50\n",
      "20/20 - 0s - loss: 0.1028 - accuracy: 0.9594\n",
      "Epoch 28/50\n",
      "20/20 - 0s - loss: 0.1431 - accuracy: 0.9438\n",
      "Epoch 29/50\n",
      "20/20 - 0s - loss: 0.1339 - accuracy: 0.9469\n",
      "Epoch 30/50\n",
      "20/20 - 0s - loss: 0.1344 - accuracy: 0.9375\n",
      "Epoch 31/50\n",
      "20/20 - 0s - loss: 0.1469 - accuracy: 0.9563\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 32/50\n",
      "20/20 - 0s - loss: 0.1328 - accuracy: 0.9406\n",
      "Epoch 33/50\n",
      "20/20 - 0s - loss: 0.1204 - accuracy: 0.9750\n",
      "Epoch 34/50\n",
      "20/20 - 0s - loss: 0.1248 - accuracy: 0.9500\n",
      "Epoch 35/50\n",
      "20/20 - 0s - loss: 0.0988 - accuracy: 0.9563\n",
      "Epoch 36/50\n",
      "20/20 - 0s - loss: 0.0892 - accuracy: 0.9625\n",
      "Epoch 37/50\n",
      "20/20 - 0s - loss: 0.0904 - accuracy: 0.9625\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 38/50\n",
      "20/20 - 0s - loss: 0.0694 - accuracy: 0.9781\n",
      "Epoch 39/50\n",
      "20/20 - 0s - loss: 0.0942 - accuracy: 0.9656\n",
      "Epoch 40/50\n",
      "20/20 - 0s - loss: 0.0688 - accuracy: 0.9719\n",
      "Epoch 41/50\n",
      "20/20 - 0s - loss: 0.0827 - accuracy: 0.9719\n",
      "Epoch 42/50\n",
      "20/20 - 0s - loss: 0.0672 - accuracy: 0.9781\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 43/50\n",
      "20/20 - 0s - loss: 0.1011 - accuracy: 0.9625\n",
      "Epoch 44/50\n",
      "20/20 - 0s - loss: 0.0464 - accuracy: 0.9812\n",
      "Epoch 45/50\n",
      "20/20 - 0s - loss: 0.0673 - accuracy: 0.9812\n",
      "Epoch 46/50\n",
      "20/20 - 0s - loss: 0.0991 - accuracy: 0.9531\n",
      "Epoch 47/50\n",
      "20/20 - 0s - loss: 0.0696 - accuracy: 0.9812\n",
      "Epoch 48/50\n",
      "20/20 - 0s - loss: 0.0763 - accuracy: 0.9781\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 49/50\n",
      "20/20 - 0s - loss: 0.0562 - accuracy: 0.9719\n",
      "Epoch 50/50\n",
      "20/20 - 0s - loss: 0.0747 - accuracy: 0.9625\n",
      "CPU times: user 1min 29s, sys: 4.37 s, total: 1min 33s\n",
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "#import tensorflow as tf \n",
    "#from tf.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "epochs = 50\n",
    "batch_size = 4 \n",
    "model_CV = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, epochs=epochs, \n",
    "                           batch_size=batch_size, verbose=2)\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'glorot_uniform', 'glorot_normal']\n",
    "batches = [4,8,16]\n",
    "lr = [0.001, 0.0001, 0.00005]\n",
    "\n",
    "param_grid = dict(init_mode=init_mode, lr = lr, batch_size = batches)\n",
    "grid = RandomizedSearchCV(estimator=model_CV, param_distributions=param_grid, n_jobs=-1, cv=KFold(3))\n",
    "grid_result = grid.fit(X_train, y_train, callbacks=[reduce_lr, early_stop], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7d4716fd-ec3e-4022-a7af-64c60e49f8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy for 0.790571908156077 using {'lr': 0.001, 'init_mode': 'uniform', 'batch_size': 16}\n",
      " mean=0.6468, std=0.0175 using {'lr': 5e-05, 'init_mode': 'glorot_uniform', 'batch_size': 16}\n",
      " mean=0.722, std=0.03534 using {'lr': 5e-05, 'init_mode': 'uniform', 'batch_size': 4}\n",
      " mean=0.7906, std=0.0126 using {'lr': 0.001, 'init_mode': 'uniform', 'batch_size': 16}\n",
      " mean=0.75, std=0.008324 using {'lr': 0.0001, 'init_mode': 'uniform', 'batch_size': 4}\n",
      " mean=0.7905, std=0.03578 using {'lr': 0.001, 'init_mode': 'glorot_uniform', 'batch_size': 8}\n",
      " mean=0.7282, std=0.01913 using {'lr': 0.0001, 'init_mode': 'uniform', 'batch_size': 8}\n",
      " mean=0.7749, std=0.02387 using {'lr': 0.001, 'init_mode': 'glorot_normal', 'batch_size': 4}\n",
      " mean=0.7875, std=0.003491 using {'lr': 0.001, 'init_mode': 'lecun_uniform', 'batch_size': 8}\n",
      " mean=0.653, std=0.03627 using {'lr': 0.0001, 'init_mode': 'glorot_normal', 'batch_size': 8}\n",
      " mean=0.6531, std=0.009033 using {'lr': 5e-05, 'init_mode': 'lecun_uniform', 'batch_size': 4}\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27e306-ce0f-4d62-b627-ba1d523f2ea6",
   "metadata": {},
   "source": [
    "## Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5d52e64b-09a5-4679-b74a-2ec918a04ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Accuracy for 0.875 using {'lr': 0.001, 'init_mode': 'lecun_uniform', 'batch_size': 8}\n",
    "def create_model( init_mode='uniform', lr = 0.001):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv1D(256, 5,padding='same',\n",
    "                     input_shape=(248,12), kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "\n",
    "    model.add(layers.Conv1D(128, 5,padding='same', kernel_initializer=init_mode))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, kernel_initializer=init_mode))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr = lr) , \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "06f68ad4-78eb-480c-bede-b47be57edb8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8fd7103d-0265-43ea-a363-5f1556b62e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2c2591a3-542f-40eb-a1ae-129e57430fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bc8bbd68-6145-4813-8a5b-3ae07998632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f45a7463-e7cd-49ed-b97d-dd1e0996aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "833c101c-1008-4047-992a-66aac6be006f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 16:41:00.634773: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-08-30 16:41:00.634857: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-08-30 16:41:00.690918: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4c4809b8-52e9-4135-975b-836ef5acc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', \n",
    "                                                 factor=0.5, patience=4, \n",
    "                                                 verbose=1, mode='max', \n",
    "                                                 min_lr=0.000001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=45, \n",
    "                                              verbose=1, restore_best_weights = True )\n",
    "\n",
    "# classweight \n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {l:c for l,c in zip(np.unique(y_train), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dffe6b2e-1615-4a90-9154-f67a91df0216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/20 [=================>............] - ETA: 0s - loss: 1.3739 - accuracy: 0.5840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 16:41:02.293785: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-08-30 16:41:02.293809: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-08-30 16:41:02.309991: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-08-30 16:41:02.310877: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-08-30 16:41:02.312503: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02\n",
      "2021-08-30 16:41:02.313324: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02/helemanc-Latitude-5410.trace.json.gz\n",
      "2021-08-30 16:41:02.315462: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02\n",
      "2021-08-30 16:41:02.315524: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02/helemanc-Latitude-5410.memory_profile.json.gz\n",
      "2021-08-30 16:41:02.315675: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02Dumped tool data for xplane.pb to logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02/helemanc-Latitude-5410.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02/helemanc-Latitude-5410.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02/helemanc-Latitude-5410.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02/helemanc-Latitude-5410.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/20210830-164100/train/plugins/profile/2021_08_30_16_41_02/helemanc-Latitude-5410.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 25ms/step - loss: 1.2857 - accuracy: 0.5831 - val_loss: 0.6420 - val_accuracy: 0.7333\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.6533 - accuracy: 0.4594 - val_loss: 0.5067 - val_accuracy: 0.8167\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5779 - accuracy: 0.7090 - val_loss: 0.4466 - val_accuracy: 0.8000\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.5547 - accuracy: 0.7058 - val_loss: 0.4282 - val_accuracy: 0.8333\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.4417 - accuracy: 0.7775 - val_loss: 0.3811 - val_accuracy: 0.8500\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.4585 - accuracy: 0.7629 - val_loss: 0.3447 - val_accuracy: 0.8500\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.4975 - accuracy: 0.7818 - val_loss: 0.3924 - val_accuracy: 0.8667\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.4408 - accuracy: 0.7473 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.4317 - accuracy: 0.7857 - val_loss: 0.3661 - val_accuracy: 0.8667\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.3494 - accuracy: 0.8107 - val_loss: 0.5315 - val_accuracy: 0.7500\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.3629 - accuracy: 0.8238 - val_loss: 0.7212 - val_accuracy: 0.7000\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.4240 - accuracy: 0.7590 - val_loss: 0.4121 - val_accuracy: 0.8167\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.3536 - accuracy: 0.8744 - val_loss: 0.3736 - val_accuracy: 0.8333\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.3994 - accuracy: 0.8276 - val_loss: 0.2908 - val_accuracy: 0.8667\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.2557 - accuracy: 0.8936 - val_loss: 0.5424 - val_accuracy: 0.7667\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.3442 - accuracy: 0.8054 - val_loss: 0.4332 - val_accuracy: 0.8333\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2636 - accuracy: 0.9025 - val_loss: 0.4626 - val_accuracy: 0.8167\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2428 - accuracy: 0.9235 - val_loss: 0.4409 - val_accuracy: 0.7833\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.1889 - accuracy: 0.9184 - val_loss: 0.3548 - val_accuracy: 0.8333\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.2215 - accuracy: 0.9248 - val_loss: 0.7010 - val_accuracy: 0.7167\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.4205 - accuracy: 0.8082 - val_loss: 0.2817 - val_accuracy: 0.9167\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1895 - accuracy: 0.9406 - val_loss: 0.3391 - val_accuracy: 0.8667\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2231 - accuracy: 0.8694 - val_loss: 0.2741 - val_accuracy: 0.8500\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.2459 - accuracy: 0.8817 - val_loss: 0.2792 - val_accuracy: 0.8833\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2101 - accuracy: 0.9034 - val_loss: 0.2511 - val_accuracy: 0.8833\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1623 - accuracy: 0.9077 - val_loss: 0.3753 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1927 - accuracy: 0.9309 - val_loss: 0.2620 - val_accuracy: 0.8833\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.2688 - accuracy: 0.9174 - val_loss: 0.2620 - val_accuracy: 0.8833\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1173 - accuracy: 0.9689 - val_loss: 0.3576 - val_accuracy: 0.8667\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1372 - accuracy: 0.9399 - val_loss: 0.2719 - val_accuracy: 0.8667\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1078 - accuracy: 0.9581 - val_loss: 0.3627 - val_accuracy: 0.8333\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1125 - accuracy: 0.9267 - val_loss: 0.3313 - val_accuracy: 0.8500\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1279 - accuracy: 0.9459 - val_loss: 0.2353 - val_accuracy: 0.9000\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0943 - accuracy: 0.9688 - val_loss: 0.3607 - val_accuracy: 0.8333\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.0759 - accuracy: 0.9546 - val_loss: 0.2363 - val_accuracy: 0.8833\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0627 - accuracy: 0.9611 - val_loss: 0.2259 - val_accuracy: 0.9000\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0656 - accuracy: 0.9767 - val_loss: 0.3841 - val_accuracy: 0.8500\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.1588 - accuracy: 0.9201 - val_loss: 0.2117 - val_accuracy: 0.9000\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0797 - accuracy: 0.9646 - val_loss: 0.3484 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.1544 - accuracy: 0.9490 - val_loss: 0.3357 - val_accuracy: 0.8500\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0870 - accuracy: 0.9546 - val_loss: 0.3066 - val_accuracy: 0.8500\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1052 - accuracy: 0.9613 - val_loss: 0.3385 - val_accuracy: 0.8500\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0719 - accuracy: 0.9625 - val_loss: 0.2526 - val_accuracy: 0.9000\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0590 - accuracy: 0.9789 - val_loss: 0.3460 - val_accuracy: 0.8500\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0578 - accuracy: 0.9765 - val_loss: 0.2910 - val_accuracy: 0.8667\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0917 - accuracy: 0.9727 - val_loss: 0.3616 - val_accuracy: 0.8500\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0542 - accuracy: 0.9835 - val_loss: 0.3530 - val_accuracy: 0.8500\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0730 - accuracy: 0.9805 - val_loss: 0.2813 - val_accuracy: 0.8833\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0452 - accuracy: 0.9919 - val_loss: 0.3560 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1107 - accuracy: 0.9581 - val_loss: 0.3161 - val_accuracy: 0.8667\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0540 - accuracy: 0.9740 - val_loss: 0.2630 - val_accuracy: 0.8667\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0696 - accuracy: 0.9805 - val_loss: 0.2704 - val_accuracy: 0.8833\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0750 - accuracy: 0.9648 - val_loss: 0.2607 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0484 - accuracy: 0.9871 - val_loss: 0.2593 - val_accuracy: 0.8833\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0582 - accuracy: 0.9895 - val_loss: 0.2754 - val_accuracy: 0.8833\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0869 - accuracy: 0.9436 - val_loss: 0.2506 - val_accuracy: 0.8833\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0432 - accuracy: 0.9902 - val_loss: 0.2641 - val_accuracy: 0.8833\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0596 - accuracy: 0.9851 - val_loss: 0.2900 - val_accuracy: 0.8667\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0333 - accuracy: 0.9848 - val_loss: 0.2904 - val_accuracy: 0.8667\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0388 - accuracy: 0.9846 - val_loss: 0.2617 - val_accuracy: 0.8833\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.2612 - val_accuracy: 0.8833\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0602 - accuracy: 0.9724 - val_loss: 0.2486 - val_accuracy: 0.8833\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9968 - val_loss: 0.2628 - val_accuracy: 0.8833\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9929 - val_loss: 0.2597 - val_accuracy: 0.8833\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0579 - accuracy: 0.9862 - val_loss: 0.2893 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.2896 - val_accuracy: 0.8667\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0565 - accuracy: 0.9822 - val_loss: 0.2973 - val_accuracy: 0.8667\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0506 - accuracy: 0.9668 - val_loss: 0.2903 - val_accuracy: 0.8667\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0398 - accuracy: 0.9932 - val_loss: 0.2935 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0450 - accuracy: 0.9603 - val_loss: 0.2850 - val_accuracy: 0.8667\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0619 - accuracy: 0.9570 - val_loss: 0.2730 - val_accuracy: 0.8833\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0733 - accuracy: 0.9732 - val_loss: 0.2738 - val_accuracy: 0.8833\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0400 - accuracy: 0.9873 - val_loss: 0.2771 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0512 - accuracy: 0.9814 - val_loss: 0.2765 - val_accuracy: 0.8833\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0431 - accuracy: 0.9876 - val_loss: 0.2759 - val_accuracy: 0.8833\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.2751 - val_accuracy: 0.8833\n",
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0587 - accuracy: 0.9863 - val_loss: 0.2742 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0644 - accuracy: 0.9858 - val_loss: 0.2762 - val_accuracy: 0.8833\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0474 - accuracy: 0.9775 - val_loss: 0.2776 - val_accuracy: 0.8833\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0449 - accuracy: 0.9713 - val_loss: 0.2769 - val_accuracy: 0.8833\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0819 - accuracy: 0.9751 - val_loss: 0.2767 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.2780 - val_accuracy: 0.8833\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.1148 - accuracy: 0.9604 - val_loss: 0.2790 - val_accuracy: 0.8833\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1140 - accuracy: 0.9861 - val_loss: 0.2801 - val_accuracy: 0.8833\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0255 - accuracy: 0.9962 - val_loss: 0.2798 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0567 - accuracy: 0.9806 - val_loss: 0.2802 - val_accuracy: 0.8833\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0514 - accuracy: 0.9833 - val_loss: 0.2805 - val_accuracy: 0.8833\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0825 - accuracy: 0.9799 - val_loss: 0.2816 - val_accuracy: 0.8667\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.2818 - val_accuracy: 0.8667\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0510 - accuracy: 0.9891 - val_loss: 0.2821 - val_accuracy: 0.8667\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0339 - accuracy: 0.9799 - val_loss: 0.2818 - val_accuracy: 0.8667\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0338 - accuracy: 0.9914 - val_loss: 0.2817 - val_accuracy: 0.8667\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0785 - accuracy: 0.9697 - val_loss: 0.2822 - val_accuracy: 0.8667\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0605 - accuracy: 0.9913 - val_loss: 0.2825 - val_accuracy: 0.8667\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0454 - accuracy: 0.9738 - val_loss: 0.2824 - val_accuracy: 0.8667\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0694 - accuracy: 0.9677 - val_loss: 0.2826 - val_accuracy: 0.8667\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0319 - accuracy: 0.9828 - val_loss: 0.2824 - val_accuracy: 0.8667\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0329 - accuracy: 0.9786 - val_loss: 0.2824 - val_accuracy: 0.8667\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0383 - accuracy: 0.9774 - val_loss: 0.2816 - val_accuracy: 0.8667\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0604 - accuracy: 0.9925 - val_loss: 0.2817 - val_accuracy: 0.8667\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0465 - accuracy: 0.9833 - val_loss: 0.2816 - val_accuracy: 0.8667\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0455 - accuracy: 0.9905 - val_loss: 0.2816 - val_accuracy: 0.8667\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0286 - accuracy: 0.9901 - val_loss: 0.2814 - val_accuracy: 0.8667\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0932 - accuracy: 0.9711 - val_loss: 0.2818 - val_accuracy: 0.8667\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0281 - accuracy: 0.9935 - val_loss: 0.2818 - val_accuracy: 0.8667\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0420 - accuracy: 0.9885 - val_loss: 0.2812 - val_accuracy: 0.8667\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0706 - accuracy: 0.9630 - val_loss: 0.2808 - val_accuracy: 0.8667\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0508 - accuracy: 0.9897 - val_loss: 0.2807 - val_accuracy: 0.8667\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0384 - accuracy: 0.9759 - val_loss: 0.2808 - val_accuracy: 0.8667\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0486 - accuracy: 0.9905 - val_loss: 0.2804 - val_accuracy: 0.8667\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.2803 - val_accuracy: 0.8833\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0339 - accuracy: 0.9844 - val_loss: 0.2801 - val_accuracy: 0.8833\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 0.2799 - val_accuracy: 0.8833\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.8833\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0377 - accuracy: 0.9894 - val_loss: 0.2796 - val_accuracy: 0.8833\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0216 - accuracy: 0.9964 - val_loss: 0.2791 - val_accuracy: 0.8833\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0538 - accuracy: 0.9921 - val_loss: 0.2794 - val_accuracy: 0.8833\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0586 - accuracy: 0.9687 - val_loss: 0.2793 - val_accuracy: 0.8833\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0356 - accuracy: 0.9874 - val_loss: 0.2793 - val_accuracy: 0.8833\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0923 - accuracy: 0.9525 - val_loss: 0.2788 - val_accuracy: 0.8833\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0596 - accuracy: 0.9680 - val_loss: 0.2784 - val_accuracy: 0.8833\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00121: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=16, epochs=500, validation_data=(X_val, y_val),\n",
    "           callbacks=[reduce_lr, early_stop, tensorboard_callback], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4cd9cd17-f103-48c3-867c-dd86a7b74800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 31441), started 5:21:24 ago. (Use '!kill 31441' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3e896c64e117dac3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3e896c64e117dac3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "381fa255-44fb-4904-9302-c53cb252f628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5822842121124268, 0.7833333611488342]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "eb7e685d-224f-46c1-81ad-d5de2a837c15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.42      0.43        12\n",
      "           1       0.86      0.88      0.87        48\n",
      "\n",
      "    accuracy                           0.78        60\n",
      "   macro avg       0.66      0.65      0.65        60\n",
      "weighted avg       0.78      0.78      0.78        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "pred = [1 * (x[0]>=0.50) for x in predictions] #0.5 o 0.52? \n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66697433-f3c3-43fb-8b40-fc5e9a1fd158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
